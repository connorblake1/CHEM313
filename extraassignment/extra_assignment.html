<!DOCTYPE html>

<html lang="en">
<head><meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>extra_assignment</title><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script>
<style type="text/css">
    pre { line-height: 125%; }
td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }
span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }
td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }
span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }
.highlight .hll { background-color: var(--jp-cell-editor-active-background) }
.highlight { background: var(--jp-cell-editor-background); color: var(--jp-mirror-editor-variable-color) }
.highlight .c { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment */
.highlight .err { color: var(--jp-mirror-editor-error-color) } /* Error */
.highlight .k { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword */
.highlight .o { color: var(--jp-mirror-editor-operator-color); font-weight: bold } /* Operator */
.highlight .p { color: var(--jp-mirror-editor-punctuation-color) } /* Punctuation */
.highlight .ch { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Hashbang */
.highlight .cm { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Multiline */
.highlight .cp { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Preproc */
.highlight .cpf { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.PreprocFile */
.highlight .c1 { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Single */
.highlight .cs { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Special */
.highlight .kc { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Constant */
.highlight .kd { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Declaration */
.highlight .kn { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Namespace */
.highlight .kp { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Pseudo */
.highlight .kr { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Reserved */
.highlight .kt { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Type */
.highlight .m { color: var(--jp-mirror-editor-number-color) } /* Literal.Number */
.highlight .s { color: var(--jp-mirror-editor-string-color) } /* Literal.String */
.highlight .ow { color: var(--jp-mirror-editor-operator-color); font-weight: bold } /* Operator.Word */
.highlight .pm { color: var(--jp-mirror-editor-punctuation-color) } /* Punctuation.Marker */
.highlight .w { color: var(--jp-mirror-editor-variable-color) } /* Text.Whitespace */
.highlight .mb { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Bin */
.highlight .mf { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Float */
.highlight .mh { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Hex */
.highlight .mi { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Integer */
.highlight .mo { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Oct */
.highlight .sa { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Affix */
.highlight .sb { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Backtick */
.highlight .sc { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Char */
.highlight .dl { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Delimiter */
.highlight .sd { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Doc */
.highlight .s2 { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Double */
.highlight .se { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Escape */
.highlight .sh { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Heredoc */
.highlight .si { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Interpol */
.highlight .sx { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Other */
.highlight .sr { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Regex */
.highlight .s1 { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Single */
.highlight .ss { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Symbol */
.highlight .il { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Integer.Long */
  </style>
<style type="text/css">
/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*
 * Mozilla scrollbar styling
 */

/* use standard opaque scrollbars for most nodes */
[data-jp-theme-scrollbars='true'] {
  scrollbar-color: rgb(var(--jp-scrollbar-thumb-color))
    var(--jp-scrollbar-background-color);
}

/* for code nodes, use a transparent style of scrollbar. These selectors
 * will match lower in the tree, and so will override the above */
[data-jp-theme-scrollbars='true'] .CodeMirror-hscrollbar,
[data-jp-theme-scrollbars='true'] .CodeMirror-vscrollbar {
  scrollbar-color: rgba(var(--jp-scrollbar-thumb-color), 0.5) transparent;
}

/* tiny scrollbar */

.jp-scrollbar-tiny {
  scrollbar-color: rgba(var(--jp-scrollbar-thumb-color), 0.5) transparent;
  scrollbar-width: thin;
}

/* tiny scrollbar */

.jp-scrollbar-tiny::-webkit-scrollbar,
.jp-scrollbar-tiny::-webkit-scrollbar-corner {
  background-color: transparent;
  height: 4px;
  width: 4px;
}

.jp-scrollbar-tiny::-webkit-scrollbar-thumb {
  background: rgba(var(--jp-scrollbar-thumb-color), 0.5);
}

.jp-scrollbar-tiny::-webkit-scrollbar-track:horizontal {
  border-left: 0 solid transparent;
  border-right: 0 solid transparent;
}

.jp-scrollbar-tiny::-webkit-scrollbar-track:vertical {
  border-top: 0 solid transparent;
  border-bottom: 0 solid transparent;
}

/*
 * Lumino
 */

.lm-ScrollBar[data-orientation='horizontal'] {
  min-height: 16px;
  max-height: 16px;
  min-width: 45px;
  border-top: 1px solid #a0a0a0;
}

.lm-ScrollBar[data-orientation='vertical'] {
  min-width: 16px;
  max-width: 16px;
  min-height: 45px;
  border-left: 1px solid #a0a0a0;
}

.lm-ScrollBar-button {
  background-color: #f0f0f0;
  background-position: center center;
  min-height: 15px;
  max-height: 15px;
  min-width: 15px;
  max-width: 15px;
}

.lm-ScrollBar-button:hover {
  background-color: #dadada;
}

.lm-ScrollBar-button.lm-mod-active {
  background-color: #cdcdcd;
}

.lm-ScrollBar-track {
  background: #f0f0f0;
}

.lm-ScrollBar-thumb {
  background: #cdcdcd;
}

.lm-ScrollBar-thumb:hover {
  background: #bababa;
}

.lm-ScrollBar-thumb.lm-mod-active {
  background: #a0a0a0;
}

.lm-ScrollBar[data-orientation='horizontal'] .lm-ScrollBar-thumb {
  height: 100%;
  min-width: 15px;
  border-left: 1px solid #a0a0a0;
  border-right: 1px solid #a0a0a0;
}

.lm-ScrollBar[data-orientation='vertical'] .lm-ScrollBar-thumb {
  width: 100%;
  min-height: 15px;
  border-top: 1px solid #a0a0a0;
  border-bottom: 1px solid #a0a0a0;
}

.lm-ScrollBar[data-orientation='horizontal']
  .lm-ScrollBar-button[data-action='decrement'] {
  background-image: var(--jp-icon-caret-left);
  background-size: 17px;
}

.lm-ScrollBar[data-orientation='horizontal']
  .lm-ScrollBar-button[data-action='increment'] {
  background-image: var(--jp-icon-caret-right);
  background-size: 17px;
}

.lm-ScrollBar[data-orientation='vertical']
  .lm-ScrollBar-button[data-action='decrement'] {
  background-image: var(--jp-icon-caret-up);
  background-size: 17px;
}

.lm-ScrollBar[data-orientation='vertical']
  .lm-ScrollBar-button[data-action='increment'] {
  background-image: var(--jp-icon-caret-down);
  background-size: 17px;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-Widget {
  box-sizing: border-box;
  position: relative;
  overflow: hidden;
}

.lm-Widget.lm-mod-hidden {
  display: none !important;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.lm-AccordionPanel[data-orientation='horizontal'] > .lm-AccordionPanel-title {
  /* Title is rotated for horizontal accordion panel using CSS */
  display: block;
  transform-origin: top left;
  transform: rotate(-90deg) translate(-100%);
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-CommandPalette {
  display: flex;
  flex-direction: column;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.lm-CommandPalette-search {
  flex: 0 0 auto;
}

.lm-CommandPalette-content {
  flex: 1 1 auto;
  margin: 0;
  padding: 0;
  min-height: 0;
  overflow: auto;
  list-style-type: none;
}

.lm-CommandPalette-header {
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}

.lm-CommandPalette-item {
  display: flex;
  flex-direction: row;
}

.lm-CommandPalette-itemIcon {
  flex: 0 0 auto;
}

.lm-CommandPalette-itemContent {
  flex: 1 1 auto;
  overflow: hidden;
}

.lm-CommandPalette-itemShortcut {
  flex: 0 0 auto;
}

.lm-CommandPalette-itemLabel {
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}

.lm-close-icon {
  border: 1px solid transparent;
  background-color: transparent;
  position: absolute;
  z-index: 1;
  right: 3%;
  top: 0;
  bottom: 0;
  margin: auto;
  padding: 7px 0;
  display: none;
  vertical-align: middle;
  outline: 0;
  cursor: pointer;
}
.lm-close-icon:after {
  content: 'X';
  display: block;
  width: 15px;
  height: 15px;
  text-align: center;
  color: #000;
  font-weight: normal;
  font-size: 12px;
  cursor: pointer;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-DockPanel {
  z-index: 0;
}

.lm-DockPanel-widget {
  z-index: 0;
}

.lm-DockPanel-tabBar {
  z-index: 1;
}

.lm-DockPanel-handle {
  z-index: 2;
}

.lm-DockPanel-handle.lm-mod-hidden {
  display: none !important;
}

.lm-DockPanel-handle:after {
  position: absolute;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  content: '';
}

.lm-DockPanel-handle[data-orientation='horizontal'] {
  cursor: ew-resize;
}

.lm-DockPanel-handle[data-orientation='vertical'] {
  cursor: ns-resize;
}

.lm-DockPanel-handle[data-orientation='horizontal']:after {
  left: 50%;
  min-width: 8px;
  transform: translateX(-50%);
}

.lm-DockPanel-handle[data-orientation='vertical']:after {
  top: 50%;
  min-height: 8px;
  transform: translateY(-50%);
}

.lm-DockPanel-overlay {
  z-index: 3;
  box-sizing: border-box;
  pointer-events: none;
}

.lm-DockPanel-overlay.lm-mod-hidden {
  display: none !important;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-Menu {
  z-index: 10000;
  position: absolute;
  white-space: nowrap;
  overflow-x: hidden;
  overflow-y: auto;
  outline: none;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.lm-Menu-content {
  margin: 0;
  padding: 0;
  display: table;
  list-style-type: none;
}

.lm-Menu-item {
  display: table-row;
}

.lm-Menu-item.lm-mod-hidden,
.lm-Menu-item.lm-mod-collapsed {
  display: none !important;
}

.lm-Menu-itemIcon,
.lm-Menu-itemSubmenuIcon {
  display: table-cell;
  text-align: center;
}

.lm-Menu-itemLabel {
  display: table-cell;
  text-align: left;
}

.lm-Menu-itemShortcut {
  display: table-cell;
  text-align: right;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-MenuBar {
  outline: none;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.lm-MenuBar-content {
  margin: 0;
  padding: 0;
  display: flex;
  flex-direction: row;
  list-style-type: none;
}

.lm-MenuBar-item {
  box-sizing: border-box;
}

.lm-MenuBar-itemIcon,
.lm-MenuBar-itemLabel {
  display: inline-block;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-ScrollBar {
  display: flex;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.lm-ScrollBar[data-orientation='horizontal'] {
  flex-direction: row;
}

.lm-ScrollBar[data-orientation='vertical'] {
  flex-direction: column;
}

.lm-ScrollBar-button {
  box-sizing: border-box;
  flex: 0 0 auto;
}

.lm-ScrollBar-track {
  box-sizing: border-box;
  position: relative;
  overflow: hidden;
  flex: 1 1 auto;
}

.lm-ScrollBar-thumb {
  box-sizing: border-box;
  position: absolute;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-SplitPanel-child {
  z-index: 0;
}

.lm-SplitPanel-handle {
  z-index: 1;
}

.lm-SplitPanel-handle.lm-mod-hidden {
  display: none !important;
}

.lm-SplitPanel-handle:after {
  position: absolute;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  content: '';
}

.lm-SplitPanel[data-orientation='horizontal'] > .lm-SplitPanel-handle {
  cursor: ew-resize;
}

.lm-SplitPanel[data-orientation='vertical'] > .lm-SplitPanel-handle {
  cursor: ns-resize;
}

.lm-SplitPanel[data-orientation='horizontal'] > .lm-SplitPanel-handle:after {
  left: 50%;
  min-width: 8px;
  transform: translateX(-50%);
}

.lm-SplitPanel[data-orientation='vertical'] > .lm-SplitPanel-handle:after {
  top: 50%;
  min-height: 8px;
  transform: translateY(-50%);
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-TabBar {
  display: flex;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.lm-TabBar[data-orientation='horizontal'] {
  flex-direction: row;
  align-items: flex-end;
}

.lm-TabBar[data-orientation='vertical'] {
  flex-direction: column;
  align-items: flex-end;
}

.lm-TabBar-content {
  margin: 0;
  padding: 0;
  display: flex;
  flex: 1 1 auto;
  list-style-type: none;
}

.lm-TabBar[data-orientation='horizontal'] > .lm-TabBar-content {
  flex-direction: row;
}

.lm-TabBar[data-orientation='vertical'] > .lm-TabBar-content {
  flex-direction: column;
}

.lm-TabBar-tab {
  display: flex;
  flex-direction: row;
  box-sizing: border-box;
  overflow: hidden;
  touch-action: none; /* Disable native Drag/Drop */
}

.lm-TabBar-tabIcon,
.lm-TabBar-tabCloseIcon {
  flex: 0 0 auto;
}

.lm-TabBar-tabLabel {
  flex: 1 1 auto;
  overflow: hidden;
  white-space: nowrap;
}

.lm-TabBar-tabInput {
  user-select: all;
  width: 100%;
  box-sizing: border-box;
}

.lm-TabBar-tab.lm-mod-hidden {
  display: none !important;
}

.lm-TabBar-addButton.lm-mod-hidden {
  display: none !important;
}

.lm-TabBar.lm-mod-dragging .lm-TabBar-tab {
  position: relative;
}

.lm-TabBar.lm-mod-dragging[data-orientation='horizontal'] .lm-TabBar-tab {
  left: 0;
  transition: left 150ms ease;
}

.lm-TabBar.lm-mod-dragging[data-orientation='vertical'] .lm-TabBar-tab {
  top: 0;
  transition: top 150ms ease;
}

.lm-TabBar.lm-mod-dragging .lm-TabBar-tab.lm-mod-dragging {
  transition: none;
}

.lm-TabBar-tabLabel .lm-TabBar-tabInput {
  user-select: all;
  width: 100%;
  box-sizing: border-box;
  background: inherit;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-TabPanel-tabBar {
  z-index: 1;
}

.lm-TabPanel-stackedPanel {
  z-index: 0;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Collapse {
  display: flex;
  flex-direction: column;
  align-items: stretch;
}

.jp-Collapse-header {
  padding: 1px 12px;
  background-color: var(--jp-layout-color1);
  border-bottom: solid var(--jp-border-width) var(--jp-border-color2);
  color: var(--jp-ui-font-color1);
  cursor: pointer;
  display: flex;
  align-items: center;
  font-size: var(--jp-ui-font-size0);
  font-weight: 600;
  text-transform: uppercase;
  user-select: none;
}

.jp-Collapser-icon {
  height: 16px;
}

.jp-Collapse-header-collapsed .jp-Collapser-icon {
  transform: rotate(-90deg);
  margin: auto 0;
}

.jp-Collapser-title {
  line-height: 25px;
}

.jp-Collapse-contents {
  padding: 0 12px;
  background-color: var(--jp-layout-color1);
  color: var(--jp-ui-font-color1);
  overflow: auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* This file was auto-generated by ensureUiComponents() in @jupyterlab/buildutils */

/**
 * (DEPRECATED) Support for consuming icons as CSS background images
 */

/* Icons urls */

:root {
  --jp-icon-add-above: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPGcgY2xpcC1wYXRoPSJ1cmwoI2NsaXAwXzEzN18xOTQ5MikiPgo8cGF0aCBjbGFzcz0ianAtaWNvbjMiIGQ9Ik00Ljc1IDQuOTMwNjZINi42MjVWNi44MDU2NkM2LjYyNSA3LjAxMTkxIDYuNzkzNzUgNy4xODA2NiA3IDcuMTgwNjZDNy4yMDYyNSA3LjE4MDY2IDcuMzc1IDcuMDExOTEgNy4zNzUgNi44MDU2NlY0LjkzMDY2SDkuMjVDOS40NTYyNSA0LjkzMDY2IDkuNjI1IDQuNzYxOTEgOS42MjUgNC41NTU2NkM5LjYyNSA0LjM0OTQxIDkuNDU2MjUgNC4xODA2NiA5LjI1IDQuMTgwNjZINy4zNzVWMi4zMDU2NkM3LjM3NSAyLjA5OTQxIDcuMjA2MjUgMS45MzA2NiA3IDEuOTMwNjZDNi43OTM3NSAxLjkzMDY2IDYuNjI1IDIuMDk5NDEgNi42MjUgMi4zMDU2NlY0LjE4MDY2SDQuNzVDNC41NDM3NSA0LjE4MDY2IDQuMzc1IDQuMzQ5NDEgNC4zNzUgNC41NTU2NkM0LjM3NSA0Ljc2MTkxIDQuNTQzNzUgNC45MzA2NiA0Ljc1IDQuOTMwNjZaIiBmaWxsPSIjNjE2MTYxIiBzdHJva2U9IiM2MTYxNjEiIHN0cm9rZS13aWR0aD0iMC43Ii8+CjwvZz4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBmaWxsLXJ1bGU9ImV2ZW5vZGQiIGNsaXAtcnVsZT0iZXZlbm9kZCIgZD0iTTExLjUgOS41VjExLjVMMi41IDExLjVWOS41TDExLjUgOS41Wk0xMiA4QzEyLjU1MjMgOCAxMyA4LjQ0NzcyIDEzIDlWMTJDMTMgMTIuNTUyMyAxMi41NTIzIDEzIDEyIDEzTDIgMTNDMS40NDc3MiAxMyAxIDEyLjU1MjMgMSAxMlY5QzEgOC40NDc3MiAxLjQ0NzcxIDggMiA4TDEyIDhaIiBmaWxsPSIjNjE2MTYxIi8+CjxkZWZzPgo8Y2xpcFBhdGggaWQ9ImNsaXAwXzEzN18xOTQ5MiI+CjxyZWN0IGNsYXNzPSJqcC1pY29uMyIgd2lkdGg9IjYiIGhlaWdodD0iNiIgZmlsbD0id2hpdGUiIHRyYW5zZm9ybT0ibWF0cml4KC0xIDAgMCAxIDEwIDEuNTU1NjYpIi8+CjwvY2xpcFBhdGg+CjwvZGVmcz4KPC9zdmc+Cg==);
  --jp-icon-add-below: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPGcgY2xpcC1wYXRoPSJ1cmwoI2NsaXAwXzEzN18xOTQ5OCkiPgo8cGF0aCBjbGFzcz0ianAtaWNvbjMiIGQ9Ik05LjI1IDEwLjA2OTNMNy4zNzUgMTAuMDY5M0w3LjM3NSA4LjE5NDM0QzcuMzc1IDcuOTg4MDkgNy4yMDYyNSA3LjgxOTM0IDcgNy44MTkzNEM2Ljc5Mzc1IDcuODE5MzQgNi42MjUgNy45ODgwOSA2LjYyNSA4LjE5NDM0TDYuNjI1IDEwLjA2OTNMNC43NSAxMC4wNjkzQzQuNTQzNzUgMTAuMDY5MyA0LjM3NSAxMC4yMzgxIDQuMzc1IDEwLjQ0NDNDNC4zNzUgMTAuNjUwNiA0LjU0Mzc1IDEwLjgxOTMgNC43NSAxMC44MTkzTDYuNjI1IDEwLjgxOTNMNi42MjUgMTIuNjk0M0M2LjYyNSAxMi45MDA2IDYuNzkzNzUgMTMuMDY5MyA3IDEzLjA2OTNDNy4yMDYyNSAxMy4wNjkzIDcuMzc1IDEyLjkwMDYgNy4zNzUgMTIuNjk0M0w3LjM3NSAxMC44MTkzTDkuMjUgMTAuODE5M0M5LjQ1NjI1IDEwLjgxOTMgOS42MjUgMTAuNjUwNiA5LjYyNSAxMC40NDQzQzkuNjI1IDEwLjIzODEgOS40NTYyNSAxMC4wNjkzIDkuMjUgMTAuMDY5M1oiIGZpbGw9IiM2MTYxNjEiIHN0cm9rZT0iIzYxNjE2MSIgc3Ryb2tlLXdpZHRoPSIwLjciLz4KPC9nPgo8cGF0aCBjbGFzcz0ianAtaWNvbjMiIGZpbGwtcnVsZT0iZXZlbm9kZCIgY2xpcC1ydWxlPSJldmVub2RkIiBkPSJNMi41IDUuNUwyLjUgMy41TDExLjUgMy41TDExLjUgNS41TDIuNSA1LjVaTTIgN0MxLjQ0NzcyIDcgMSA2LjU1MjI4IDEgNkwxIDNDMSAyLjQ0NzcyIDEuNDQ3NzIgMiAyIDJMMTIgMkMxMi41NTIzIDIgMTMgMi40NDc3MiAxMyAzTDEzIDZDMTMgNi41NTIyOSAxMi41NTIzIDcgMTIgN0wyIDdaIiBmaWxsPSIjNjE2MTYxIi8+CjxkZWZzPgo8Y2xpcFBhdGggaWQ9ImNsaXAwXzEzN18xOTQ5OCI+CjxyZWN0IGNsYXNzPSJqcC1pY29uMyIgd2lkdGg9IjYiIGhlaWdodD0iNiIgZmlsbD0id2hpdGUiIHRyYW5zZm9ybT0ibWF0cml4KDEgMS43NDg0NmUtMDcgMS43NDg0NmUtMDcgLTEgNCAxMy40NDQzKSIvPgo8L2NsaXBQYXRoPgo8L2RlZnM+Cjwvc3ZnPgo=);
  --jp-icon-add: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE5IDEzaC02djZoLTJ2LTZINXYtMmg2VjVoMnY2aDZ2MnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-bell: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE2IDE2IiB2ZXJzaW9uPSIxLjEiPgogICA8cGF0aCBjbGFzcz0ianAtaWNvbjIganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMzMzMzMzIgogICAgICBkPSJtOCAwLjI5Yy0xLjQgMC0yLjcgMC43My0zLjYgMS44LTEuMiAxLjUtMS40IDMuNC0xLjUgNS4yLTAuMTggMi4yLTAuNDQgNC0yLjMgNS4zbDAuMjggMS4zaDVjMC4wMjYgMC42NiAwLjMyIDEuMSAwLjcxIDEuNSAwLjg0IDAuNjEgMiAwLjYxIDIuOCAwIDAuNTItMC40IDAuNi0xIDAuNzEtMS41aDVsMC4yOC0xLjNjLTEuOS0wLjk3LTIuMi0zLjMtMi4zLTUuMy0wLjEzLTEuOC0wLjI2LTMuNy0xLjUtNS4yLTAuODUtMS0yLjItMS44LTMuNi0xLjh6bTAgMS40YzAuODggMCAxLjkgMC41NSAyLjUgMS4zIDAuODggMS4xIDEuMSAyLjcgMS4yIDQuNCAwLjEzIDEuNyAwLjIzIDMuNiAxLjMgNS4yaC0xMGMxLjEtMS42IDEuMi0zLjQgMS4zLTUuMiAwLjEzLTEuNyAwLjMtMy4zIDEuMi00LjQgMC41OS0wLjcyIDEuNi0xLjMgMi41LTEuM3ptLTAuNzQgMTJoMS41Yy0wLjAwMTUgMC4yOCAwLjAxNSAwLjc5LTAuNzQgMC43OS0wLjczIDAuMDAxNi0wLjcyLTAuNTMtMC43NC0wLjc5eiIgLz4KPC9zdmc+Cg==);
  --jp-icon-bug-dot: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjQiIGhlaWdodD0iMjQiIHZpZXdCb3g9IjAgMCAyNCAyNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiPgogICAgICAgIDxwYXRoIGZpbGwtcnVsZT0iZXZlbm9kZCIgY2xpcC1ydWxlPSJldmVub2RkIiBkPSJNMTcuMTkgOEgyMFYxMEgxNy45MUMxNy45NiAxMC4zMyAxOCAxMC42NiAxOCAxMVYxMkgyMFYxNEgxOC41SDE4VjE0LjAyNzVDMTUuNzUgMTQuMjc2MiAxNCAxNi4xODM3IDE0IDE4LjVDMTQgMTkuMjA4IDE0LjE2MzUgMTkuODc3OSAxNC40NTQ5IDIwLjQ3MzlDMTMuNzA2MyAyMC44MTE3IDEyLjg3NTcgMjEgMTIgMjFDOS43OCAyMSA3Ljg1IDE5Ljc5IDYuODEgMThINFYxNkg2LjA5QzYuMDQgMTUuNjcgNiAxNS4zNCA2IDE1VjE0SDRWMTJINlYxMUM2IDEwLjY2IDYuMDQgMTAuMzMgNi4wOSAxMEg0VjhINi44MUM3LjI2IDcuMjIgNy44OCA2LjU1IDguNjIgNi4wNEw3IDQuNDFMOC40MSAzTDEwLjU5IDUuMTdDMTEuMDQgNS4wNiAxMS41MSA1IDEyIDVDMTIuNDkgNSAxMi45NiA1LjA2IDEzLjQyIDUuMTdMMTUuNTkgM0wxNyA0LjQxTDE1LjM3IDYuMDRDMTYuMTIgNi41NSAxNi43NCA3LjIyIDE3LjE5IDhaTTEwIDE2SDE0VjE0SDEwVjE2Wk0xMCAxMkgxNFYxMEgxMFYxMloiIGZpbGw9IiM2MTYxNjEiLz4KICAgICAgICA8cGF0aCBkPSJNMjIgMTguNUMyMiAyMC40MzMgMjAuNDMzIDIyIDE4LjUgMjJDMTYuNTY3IDIyIDE1IDIwLjQzMyAxNSAxOC41QzE1IDE2LjU2NyAxNi41NjcgMTUgMTguNSAxNUMyMC40MzMgMTUgMjIgMTYuNTY3IDIyIDE4LjVaIiBmaWxsPSIjNjE2MTYxIi8+CiAgICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-bug: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik0yMCA4aC0yLjgxYy0uNDUtLjc4LTEuMDctMS40NS0xLjgyLTEuOTZMMTcgNC40MSAxNS41OSAzbC0yLjE3IDIuMTdDMTIuOTYgNS4wNiAxMi40OSA1IDEyIDVjLS40OSAwLS45Ni4wNi0xLjQxLjE3TDguNDEgMyA3IDQuNDFsMS42MiAxLjYzQzcuODggNi41NSA3LjI2IDcuMjIgNi44MSA4SDR2MmgyLjA5Yy0uMDUuMzMtLjA5LjY2LS4wOSAxdjFINHYyaDJ2MWMwIC4zNC4wNC42Ny4wOSAxSDR2MmgyLjgxYzEuMDQgMS43OSAyLjk3IDMgNS4xOSAzczQuMTUtMS4yMSA1LjE5LTNIMjB2LTJoLTIuMDljLjA1LS4zMy4wOS0uNjYuMDktMXYtMWgydi0yaC0ydi0xYzAtLjM0LS4wNC0uNjctLjA5LTFIMjBWOHptLTYgOGgtNHYtMmg0djJ6bTAtNGgtNHYtMmg0djJ6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-build: url(data:image/svg+xml;base64,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);
  --jp-icon-caret-down-empty-thin: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwb2x5Z29uIGNsYXNzPSJzdDEiIHBvaW50cz0iOS45LDEzLjYgMy42LDcuNCA0LjQsNi42IDkuOSwxMi4yIDE1LjQsNi43IDE2LjEsNy40ICIvPgoJPC9nPgo8L3N2Zz4K);
  --jp-icon-caret-down-empty: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik01LjIsNS45TDksOS43bDMuOC0zLjhsMS4yLDEuMmwtNC45LDVsLTQuOS01TDUuMiw1Ljl6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-caret-down: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik01LjIsNy41TDksMTEuMmwzLjgtMy44SDUuMnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-caret-left: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwYXRoIGQ9Ik0xMC44LDEyLjhMNy4xLDlsMy44LTMuOGwwLDcuNkgxMC44eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-caret-right: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik03LjIsNS4yTDEwLjksOWwtMy44LDMuOFY1LjJINy4yeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-caret-up-empty-thin: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwb2x5Z29uIGNsYXNzPSJzdDEiIHBvaW50cz0iMTUuNCwxMy4zIDkuOSw3LjcgNC40LDEzLjIgMy42LDEyLjUgOS45LDYuMyAxNi4xLDEyLjYgIi8+Cgk8L2c+Cjwvc3ZnPgo=);
  --jp-icon-caret-up: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwYXRoIGQ9Ik01LjIsMTAuNUw5LDYuOGwzLjgsMy44SDUuMnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-case-sensitive: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KICA8ZyBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiM0MTQxNDEiPgogICAgPHJlY3QgeD0iMiIgeT0iMiIgd2lkdGg9IjE2IiBoZWlnaHQ9IjE2Ii8+CiAgPC9nPgogIDxnIGNsYXNzPSJqcC1pY29uLWFjY2VudDIiIGZpbGw9IiNGRkYiPgogICAgPHBhdGggZD0iTTcuNiw4aDAuOWwzLjUsOGgtMS4xTDEwLDE0SDZsLTAuOSwySDRMNy42LDh6IE04LDkuMUw2LjQsMTNoMy4yTDgsOS4xeiIvPgogICAgPHBhdGggZD0iTTE2LjYsOS44Yy0wLjIsMC4xLTAuNCwwLjEtMC43LDAuMWMtMC4yLDAtMC40LTAuMS0wLjYtMC4yYy0wLjEtMC4xLTAuMi0wLjQtMC4yLTAuNyBjLTAuMywwLjMtMC42LDAuNS0wLjksMC43Yy0wLjMsMC4xLTAuNywwLjItMS4xLDAuMmMtMC4zLDAtMC41LDAtMC43LTAuMWMtMC4yLTAuMS0wLjQtMC4yLTAuNi0wLjNjLTAuMi0wLjEtMC4zLTAuMy0wLjQtMC41IGMtMC4xLTAuMi0wLjEtMC40LTAuMS0wLjdjMC0wLjMsMC4xLTAuNiwwLjItMC44YzAuMS0wLjIsMC4zLTAuNCwwLjQtMC41QzEyLDcsMTIuMiw2LjksMTIuNSw2LjhjMC4yLTAuMSwwLjUtMC4xLDAuNy0wLjIgYzAuMy0wLjEsMC41LTAuMSwwLjctMC4xYzAuMiwwLDAuNC0wLjEsMC42LTAuMWMwLjIsMCwwLjMtMC4xLDAuNC0wLjJjMC4xLTAuMSwwLjItMC4yLDAuMi0wLjRjMC0xLTEuMS0xLTEuMy0xIGMtMC40LDAtMS40LDAtMS40LDEuMmgtMC45YzAtMC40LDAuMS0wLjcsMC4yLTFjMC4xLTAuMiwwLjMtMC40LDAuNS0wLjZjMC4yLTAuMiwwLjUtMC4zLDAuOC0wLjNDMTMuMyw0LDEzLjYsNCwxMy45LDQgYzAuMywwLDAuNSwwLDAuOCwwLjFjMC4zLDAsMC41LDAuMSwwLjcsMC4yYzAuMiwwLjEsMC40LDAuMywwLjUsMC41QzE2LDUsMTYsNS4yLDE2LDUuNnYyLjljMCwwLjIsMCwwLjQsMCwwLjUgYzAsMC4xLDAuMSwwLjIsMC4zLDAuMmMwLjEsMCwwLjIsMCwwLjMsMFY5Ljh6IE0xNS4yLDYuOWMtMS4yLDAuNi0zLjEsMC4yLTMuMSwxLjRjMCwxLjQsMy4xLDEsMy4xLTAuNVY2Ljl6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-check: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik05IDE2LjE3TDQuODMgMTJsLTEuNDIgMS40MUw5IDE5IDIxIDdsLTEuNDEtMS40MXoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-circle-empty: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyIDJDNi40NyAyIDIgNi40NyAyIDEyczQuNDcgMTAgMTAgMTAgMTAtNC40NyAxMC0xMFMxNy41MyAyIDEyIDJ6bTAgMThjLTQuNDEgMC04LTMuNTktOC04czMuNTktOCA4LTggOCAzLjU5IDggOC0zLjU5IDgtOCA4eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-circle: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPGNpcmNsZSBjeD0iOSIgY3k9IjkiIHI9IjgiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-clear: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8bWFzayBpZD0iZG9udXRIb2xlIj4KICAgIDxyZWN0IHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgZmlsbD0id2hpdGUiIC8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSI4IiBmaWxsPSJibGFjayIvPgogIDwvbWFzaz4KCiAgPGcgY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxyZWN0IGhlaWdodD0iMTgiIHdpZHRoPSIyIiB4PSIxMSIgeT0iMyIgdHJhbnNmb3JtPSJyb3RhdGUoMzE1LCAxMiwgMTIpIi8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSIxMCIgbWFzaz0idXJsKCNkb251dEhvbGUpIi8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-close: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbi1ub25lIGpwLWljb24tc2VsZWN0YWJsZS1pbnZlcnNlIGpwLWljb24zLWhvdmVyIiBmaWxsPSJub25lIj4KICAgIDxjaXJjbGUgY3g9IjEyIiBjeT0iMTIiIHI9IjExIi8+CiAgPC9nPgoKICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIGpwLWljb24tYWNjZW50Mi1ob3ZlciIgZmlsbD0iIzYxNjE2MSI+CiAgICA8cGF0aCBkPSJNMTkgNi40MUwxNy41OSA1IDEyIDEwLjU5IDYuNDEgNSA1IDYuNDEgMTAuNTkgMTIgNSAxNy41OSA2LjQxIDE5IDEyIDEzLjQxIDE3LjU5IDE5IDE5IDE3LjU5IDEzLjQxIDEyeiIvPgogIDwvZz4KCiAgPGcgY2xhc3M9ImpwLWljb24tbm9uZSBqcC1pY29uLWJ1c3kiIGZpbGw9Im5vbmUiPgogICAgPGNpcmNsZSBjeD0iMTIiIGN5PSIxMiIgcj0iNyIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-code-check: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBzaGFwZS1yZW5kZXJpbmc9Imdlb21ldHJpY1ByZWNpc2lvbiI+CiAgICA8cGF0aCBkPSJNNi41OSwzLjQxTDIsOEw2LjU5LDEyLjZMOCwxMS4xOEw0LjgyLDhMOCw0LjgyTDYuNTksMy40MU0xMi40MSwzLjQxTDExLDQuODJMMTQuMTgsOEwxMSwxMS4xOEwxMi40MSwxMi42TDE3LDhMMTIuNDEsMy40MU0yMS41OSwxMS41OUwxMy41LDE5LjY4TDkuODMsMTZMOC40MiwxNy40MUwxMy41LDIyLjVMMjMsMTNMMjEuNTksMTEuNTlaIiAvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-code: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjIiIGhlaWdodD0iMjIiIHZpZXdCb3g9IjAgMCAyOCAyOCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CgkJPHBhdGggZD0iTTExLjQgMTguNkw2LjggMTRMMTEuNCA5LjRMMTAgOEw0IDE0TDEwIDIwTDExLjQgMTguNlpNMTYuNiAxOC42TDIxLjIgMTRMMTYuNiA5LjRMMTggOEwyNCAxNEwxOCAyMEwxNi42IDE4LjZWMTguNloiLz4KCTwvZz4KPC9zdmc+Cg==);
  --jp-icon-collapse-all: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGgKICAgICAgICAgICAgZD0iTTggMmMxIDAgMTEgMCAxMiAwczIgMSAyIDJjMCAxIDAgMTEgMCAxMnMwIDItMiAyQzIwIDE0IDIwIDQgMjAgNFMxMCA0IDYgNGMwLTIgMS0yIDItMnoiIC8+CiAgICAgICAgPHBhdGgKICAgICAgICAgICAgZD0iTTE4IDhjMC0xLTEtMi0yLTJTNSA2IDQgNnMtMiAxLTIgMmMwIDEgMCAxMSAwIDEyczEgMiAyIDJjMSAwIDExIDAgMTIgMHMyLTEgMi0yYzAtMSAwLTExIDAtMTJ6bS0yIDB2MTJINFY4eiIgLz4KICAgICAgICA8cGF0aCBkPSJNNiAxM3YyaDh2LTJ6IiAvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-console: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwMCAyMDAiPgogIDxnIGNsYXNzPSJqcC1jb25zb2xlLWljb24tYmFja2dyb3VuZC1jb2xvciBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiMwMjg4RDEiPgogICAgPHBhdGggZD0iTTIwIDE5LjhoMTYwdjE1OS45SDIweiIvPgogIDwvZz4KICA8ZyBjbGFzcz0ianAtY29uc29sZS1pY29uLWNvbG9yIGpwLWljb24tc2VsZWN0YWJsZS1pbnZlcnNlIiBmaWxsPSIjZmZmIj4KICAgIDxwYXRoIGQ9Ik0xMDUgMTI3LjNoNDB2MTIuOGgtNDB6TTUxLjEgNzdMNzQgOTkuOWwtMjMuMyAyMy4zIDEwLjUgMTAuNSAyMy4zLTIzLjNMOTUgOTkuOSA4NC41IDg5LjQgNjEuNiA2Ni41eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-copy: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTExLjksMUgzLjJDMi40LDEsMS43LDEuNywxLjcsMi41djEwLjJoMS41VjIuNWg4LjdWMXogTTE0LjEsMy45aC04Yy0wLjgsMC0xLjUsMC43LTEuNSwxLjV2MTAuMmMwLDAuOCwwLjcsMS41LDEuNSwxLjVoOCBjMC44LDAsMS41LTAuNywxLjUtMS41VjUuNEMxNS41LDQuNiwxNC45LDMuOSwxNC4xLDMuOXogTTE0LjEsMTUuNWgtOFY1LjRoOFYxNS41eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-copyright: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGVuYWJsZS1iYWNrZ3JvdW5kPSJuZXcgMCAwIDI0IDI0IiBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCI+CiAgPGcgY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik0xMS44OCw5LjE0YzEuMjgsMC4wNiwxLjYxLDEuMTUsMS42MywxLjY2aDEuNzljLTAuMDgtMS45OC0xLjQ5LTMuMTktMy40NS0zLjE5QzkuNjQsNy42MSw4LDksOCwxMi4xNCBjMCwxLjk0LDAuOTMsNC4yNCwzLjg0LDQuMjRjMi4yMiwwLDMuNDEtMS42NSwzLjQ0LTIuOTVoLTEuNzljLTAuMDMsMC41OS0wLjQ1LDEuMzgtMS42MywxLjQ0QzEwLjU1LDE0LjgzLDEwLDEzLjgxLDEwLDEyLjE0IEMxMCw5LjI1LDExLjI4LDkuMTYsMTEuODgsOS4xNHogTTEyLDJDNi40OCwyLDIsNi40OCwyLDEyczQuNDgsMTAsMTAsMTBzMTAtNC40OCwxMC0xMFMxNy41MiwyLDEyLDJ6IE0xMiwyMGMtNC40MSwwLTgtMy41OS04LTggczMuNTktOCw4LThzOCwzLjU5LDgsOFMxNi40MSwyMCwxMiwyMHoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-cut: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTkuNjQgNy42NGMuMjMtLjUuMzYtMS4wNS4zNi0xLjY0IDAtMi4yMS0xLjc5LTQtNC00UzIgMy43OSAyIDZzMS43OSA0IDQgNGMuNTkgMCAxLjE0LS4xMyAxLjY0LS4zNkwxMCAxMmwtMi4zNiAyLjM2QzcuMTQgMTQuMTMgNi41OSAxNCA2IDE0Yy0yLjIxIDAtNCAxLjc5LTQgNHMxLjc5IDQgNCA0IDQtMS43OSA0LTRjMC0uNTktLjEzLTEuMTQtLjM2LTEuNjRMMTIgMTRsNyA3aDN2LTFMOS42NCA3LjY0ek02IDhjLTEuMSAwLTItLjg5LTItMnMuOS0yIDItMiAyIC44OSAyIDItLjkgMi0yIDJ6bTAgMTJjLTEuMSAwLTItLjg5LTItMnMuOS0yIDItMiAyIC44OSAyIDItLjkgMi0yIDJ6bTYtNy41Yy0uMjggMC0uNS0uMjItLjUtLjVzLjIyLS41LjUtLjUuNS4yMi41LjUtLjIyLjUtLjUuNXpNMTkgM2wtNiA2IDIgMiA3LTdWM3oiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-delete: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyNCAyNCIgd2lkdGg9IjE2cHgiIGhlaWdodD0iMTZweCI+CiAgICA8cGF0aCBkPSJNMCAwaDI0djI0SDB6IiBmaWxsPSJub25lIiAvPgogICAgPHBhdGggY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjI2MjYyIiBkPSJNNiAxOWMwIDEuMS45IDIgMiAyaDhjMS4xIDAgMi0uOSAyLTJWN0g2djEyek0xOSA0aC0zLjVsLTEtMWgtNWwtMSAxSDV2MmgxNFY0eiIgLz4KPC9zdmc+Cg==);
  --jp-icon-download: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE5IDloLTRWM0g5djZINWw3IDcgNy03ek01IDE4djJoMTR2LTJINXoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-duplicate: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBmaWxsLXJ1bGU9ImV2ZW5vZGQiIGNsaXAtcnVsZT0iZXZlbm9kZCIgZD0iTTIuNzk5OTggMC44NzVIOC44OTU4MkM5LjIwMDYxIDAuODc1IDkuNDQ5OTggMS4xMzkxNCA5LjQ0OTk4IDEuNDYxOThDOS40NDk5OCAxLjc4NDgyIDkuMjAwNjEgMi4wNDg5NiA4Ljg5NTgyIDIuMDQ4OTZIMy4zNTQxNUMzLjA0OTM2IDIuMDQ4OTYgMi43OTk5OCAyLjMxMzEgMi43OTk5OCAyLjYzNTk0VjkuNjc5NjlDMi43OTk5OCAxMC4wMDI1IDIuNTUwNjEgMTAuMjY2NyAyLjI0NTgyIDEwLjI2NjdDMS45NDEwMyAxMC4yNjY3IDEuNjkxNjUgMTAuMDAyNSAxLjY5MTY1IDkuNjc5NjlWMi4wNDg5NkMxLjY5MTY1IDEuNDAzMjggMi4xOTA0IDAuODc1IDIuNzk5OTggMC44NzVaTTUuMzY2NjUgMTEuOVY0LjU1SDExLjA4MzNWMTEuOUg1LjM2NjY1Wk00LjE0MTY1IDQuMTQxNjdDNC4xNDE2NSAzLjY5MDYzIDQuNTA3MjggMy4zMjUgNC45NTgzMiAzLjMyNUgxMS40OTE3QzExLjk0MjcgMy4zMjUgMTIuMzA4MyAzLjY5MDYzIDEyLjMwODMgNC4xNDE2N1YxMi4zMDgzQzEyLjMwODMgMTIuNzU5NCAxMS45NDI3IDEzLjEyNSAxMS40OTE3IDEzLjEyNUg0Ljk1ODMyQzQuNTA3MjggMTMuMTI1IDQuMTQxNjUgMTIuNzU5NCA0LjE0MTY1IDEyLjMwODNWNC4xNDE2N1oiIGZpbGw9IiM2MTYxNjEiLz4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBkPSJNOS40MzU3NCA4LjI2NTA3SDguMzY0MzFWOS4zMzY1QzguMzY0MzEgOS40NTQzNSA4LjI2Nzg4IDkuNTUwNzggOC4xNTAwMiA5LjU1MDc4QzguMDMyMTcgOS41NTA3OCA3LjkzNTc0IDkuNDU0MzUgNy45MzU3NCA5LjMzNjVWOC4yNjUwN0g2Ljg2NDMxQzYuNzQ2NDUgOC4yNjUwNyA2LjY1MDAyIDguMTY4NjQgNi42NTAwMiA4LjA1MDc4QzYuNjUwMDIgNy45MzI5MiA2Ljc0NjQ1IDcuODM2NSA2Ljg2NDMxIDcuODM2NUg3LjkzNTc0VjYuNzY1MDdDNy45MzU3NCA2LjY0NzIxIDguMDMyMTcgNi41NTA3OCA4LjE1MDAyIDYuNTUwNzhDOC4yNjc4OCA2LjU1MDc4IDguMzY0MzEgNi42NDcyMSA4LjM2NDMxIDYuNzY1MDdWNy44MzY1SDkuNDM1NzRDOS41NTM2IDcuODM2NSA5LjY1MDAyIDcuOTMyOTIgOS42NTAwMiA4LjA1MDc4QzkuNjUwMDIgOC4xNjg2NCA5LjU1MzYgOC4yNjUwNyA5LjQzNTc0IDguMjY1MDdaIiBmaWxsPSIjNjE2MTYxIiBzdHJva2U9IiM2MTYxNjEiIHN0cm9rZS13aWR0aD0iMC41Ii8+Cjwvc3ZnPgo=);
  --jp-icon-edit: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTMgMTcuMjVWMjFoMy43NUwxNy44MSA5Ljk0bC0zLjc1LTMuNzVMMyAxNy4yNXpNMjAuNzEgNy4wNGMuMzktLjM5LjM5LTEuMDIgMC0xLjQxbC0yLjM0LTIuMzRjLS4zOS0uMzktMS4wMi0uMzktMS40MSAwbC0xLjgzIDEuODMgMy43NSAzLjc1IDEuODMtMS44M3oiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-ellipses: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPGNpcmNsZSBjeD0iNSIgY3k9IjEyIiByPSIyIi8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSIyIi8+CiAgICA8Y2lyY2xlIGN4PSIxOSIgY3k9IjEyIiByPSIyIi8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-error: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KPGcgY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjE2MTYxIj48Y2lyY2xlIGN4PSIxMiIgY3k9IjE5IiByPSIyIi8+PHBhdGggZD0iTTEwIDNoNHYxMmgtNHoiLz48L2c+CjxwYXRoIGZpbGw9Im5vbmUiIGQ9Ik0wIDBoMjR2MjRIMHoiLz4KPC9zdmc+Cg==);
  --jp-icon-expand-all: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGgKICAgICAgICAgICAgZD0iTTggMmMxIDAgMTEgMCAxMiAwczIgMSAyIDJjMCAxIDAgMTEgMCAxMnMwIDItMiAyQzIwIDE0IDIwIDQgMjAgNFMxMCA0IDYgNGMwLTIgMS0yIDItMnoiIC8+CiAgICAgICAgPHBhdGgKICAgICAgICAgICAgZD0iTTE4IDhjMC0xLTEtMi0yLTJTNSA2IDQgNnMtMiAxLTIgMmMwIDEgMCAxMSAwIDEyczEgMiAyIDJjMSAwIDExIDAgMTIgMHMyLTEgMi0yYzAtMSAwLTExIDAtMTJ6bS0yIDB2MTJINFY4eiIgLz4KICAgICAgICA8cGF0aCBkPSJNMTEgMTBIOXYzSDZ2MmgzdjNoMnYtM2gzdi0yaC0zeiIgLz4KICAgIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-extension: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIwLjUgMTFIMTlWN2MwLTEuMS0uOS0yLTItMmgtNFYzLjVDMTMgMi4xMiAxMS44OCAxIDEwLjUgMVM4IDIuMTIgOCAzLjVWNUg0Yy0xLjEgMC0xLjk5LjktMS45OSAydjMuOEgzLjVjMS40OSAwIDIuNyAxLjIxIDIuNyAyLjdzLTEuMjEgMi43LTIuNyAyLjdIMlYyMGMwIDEuMS45IDIgMiAyaDMuOHYtMS41YzAtMS40OSAxLjIxLTIuNyAyLjctMi43IDEuNDkgMCAyLjcgMS4yMSAyLjcgMi43VjIySDE3YzEuMSAwIDItLjkgMi0ydi00aDEuNWMxLjM4IDAgMi41LTEuMTIgMi41LTIuNVMyMS44OCAxMSAyMC41IDExeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-fast-forward: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTQgMThsOC41LTZMNCA2djEyem05LTEydjEybDguNS02TDEzIDZ6Ii8+CiAgICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-file-upload: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTkgMTZoNnYtNmg0bC03LTctNyA3aDR6bS00IDJoMTR2Mkg1eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-file: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkuMyA4LjJsLTUuNS01LjVjLS4zLS4zLS43LS41LTEuMi0uNUgzLjljLS44LjEtMS42LjktMS42IDEuOHYxNC4xYzAgLjkuNyAxLjYgMS42IDEuNmgxNC4yYy45IDAgMS42LS43IDEuNi0xLjZWOS40Yy4xLS41LS4xLS45LS40LTEuMnptLTUuOC0zLjNsMy40IDMuNmgtMy40VjQuOXptMy45IDEyLjdINC43Yy0uMSAwLS4yIDAtLjItLjJWNC43YzAtLjIuMS0uMy4yLS4zaDcuMnY0LjRzMCAuOC4zIDEuMWMuMy4zIDEuMS4zIDEuMS4zaDQuM3Y3LjJzLS4xLjItLjIuMnoiLz4KPC9zdmc+Cg==);
  --jp-icon-filter-dot: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiNGRkYiPgogICAgPHBhdGggZD0iTTE0LDEyVjE5Ljg4QzE0LjA0LDIwLjE4IDEzLjk0LDIwLjUgMTMuNzEsMjAuNzFDMTMuMzIsMjEuMSAxMi42OSwyMS4xIDEyLjMsMjAuNzFMMTAuMjksMTguN0MxMC4wNiwxOC40NyA5Ljk2LDE4LjE2IDEwLDE3Ljg3VjEySDkuOTdMNC4yMSw0LjYyQzMuODcsNC4xOSAzLjk1LDMuNTYgNC4zOCwzLjIyQzQuNTcsMy4wOCA0Ljc4LDMgNSwzVjNIMTlWM0MxOS4yMiwzIDE5LjQzLDMuMDggMTkuNjIsMy4yMkMyMC4wNSwzLjU2IDIwLjEzLDQuMTkgMTkuNzksNC42MkwxNC4wMywxMkgxNFoiIC8+CiAgPC9nPgogIDxnIGNsYXNzPSJqcC1pY29uLWRvdCIgZmlsbD0iI0ZGRiI+CiAgICA8Y2lyY2xlIGN4PSIxOCIgY3k9IjE3IiByPSIzIj48L2NpcmNsZT4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-filter-list: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEwIDE4aDR2LTJoLTR2MnpNMyA2djJoMThWNkgzem0zIDdoMTJ2LTJINnYyeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-filter: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiNGRkYiPgogICAgPHBhdGggZD0iTTE0LDEyVjE5Ljg4QzE0LjA0LDIwLjE4IDEzLjk0LDIwLjUgMTMuNzEsMjAuNzFDMTMuMzIsMjEuMSAxMi42OSwyMS4xIDEyLjMsMjAuNzFMMTAuMjksMTguN0MxMC4wNiwxOC40NyA5Ljk2LDE4LjE2IDEwLDE3Ljg3VjEySDkuOTdMNC4yMSw0LjYyQzMuODcsNC4xOSAzLjk1LDMuNTYgNC4zOCwzLjIyQzQuNTcsMy4wOCA0Ljc4LDMgNSwzVjNIMTlWM0MxOS4yMiwzIDE5LjQzLDMuMDggMTkuNjIsMy4yMkMyMC4wNSwzLjU2IDIwLjEzLDQuMTkgMTkuNzksNC42MkwxNC4wMywxMkgxNFoiIC8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-folder-favorite: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMjRweCIgdmlld0JveD0iMCAwIDI0IDI0IiB3aWR0aD0iMjRweCIgZmlsbD0iIzAwMDAwMCI+CiAgPHBhdGggZD0iTTAgMGgyNHYyNEgwVjB6IiBmaWxsPSJub25lIi8+PHBhdGggY2xhc3M9ImpwLWljb24zIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzYxNjE2MSIgZD0iTTIwIDZoLThsLTItMkg0Yy0xLjEgMC0yIC45LTIgMnYxMmMwIDEuMS45IDIgMiAyaDE2YzEuMSAwIDItLjkgMi0yVjhjMC0xLjEtLjktMi0yLTJ6bS0yLjA2IDExTDE1IDE1LjI4IDEyLjA2IDE3bC43OC0zLjMzLTIuNTktMi4yNCAzLjQxLS4yOUwxNSA4bDEuMzQgMy4xNCAzLjQxLjI5LTIuNTkgMi4yNC43OCAzLjMzeiIvPgo8L3N2Zz4K);
  --jp-icon-folder: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTAgNEg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMThjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY4YzAtMS4xLS45LTItMi0yaC04bC0yLTJ6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-home: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMjRweCIgdmlld0JveD0iMCAwIDI0IDI0IiB3aWR0aD0iMjRweCIgZmlsbD0iIzAwMDAwMCI+CiAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPjxwYXRoIGNsYXNzPSJqcC1pY29uMyBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiIGQ9Ik0xMCAyMHYtNmg0djZoNXYtOGgzTDEyIDMgMiAxMmgzdjh6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-html5: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDUxMiA1MTIiPgogIDxwYXRoIGNsYXNzPSJqcC1pY29uMCBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiMwMDAiIGQ9Ik0xMDguNCAwaDIzdjIyLjhoMjEuMlYwaDIzdjY5aC0yM1Y0NmgtMjF2MjNoLTIzLjJNMjA2IDIzaC0yMC4zVjBoNjMuN3YyM0gyMjl2NDZoLTIzbTUzLjUtNjloMjQuMWwxNC44IDI0LjNMMzEzLjIgMGgyNC4xdjY5aC0yM1YzNC44bC0xNi4xIDI0LjgtMTYuMS0yNC44VjY5aC0yMi42bTg5LjItNjloMjN2NDYuMmgzMi42VjY5aC01NS42Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iI2U0NGQyNiIgZD0iTTEwNy42IDQ3MWwtMzMtMzcwLjRoMzYyLjhsLTMzIDM3MC4yTDI1NS43IDUxMiIvPgogIDxwYXRoIGNsYXNzPSJqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiNmMTY1MjkiIGQ9Ik0yNTYgNDgwLjVWMTMxaDE0OC4zTDM3NiA0NDciLz4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1zZWxlY3RhYmxlLWludmVyc2UiIGZpbGw9IiNlYmViZWIiIGQ9Ik0xNDIgMTc2LjNoMTE0djQ1LjRoLTY0LjJsNC4yIDQ2LjVoNjB2NDUuM0gxNTQuNG0yIDIyLjhIMjAybDMuMiAzNi4zIDUwLjggMTMuNnY0Ny40bC05My4yLTI2Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tc2VsZWN0YWJsZS1pbnZlcnNlIiBmaWxsPSIjZmZmIiBkPSJNMzY5LjYgMTc2LjNIMjU1Ljh2NDUuNGgxMDkuNm0tNC4xIDQ2LjVIMjU1Ljh2NDUuNGg1NmwtNS4zIDU5LTUwLjcgMTMuNnY0Ny4ybDkzLTI1LjgiLz4KPC9zdmc+Cg==);
  --jp-icon-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1icmFuZDQganAtaWNvbi1zZWxlY3RhYmxlLWludmVyc2UiIGZpbGw9IiNGRkYiIGQ9Ik0yLjIgMi4yaDE3LjV2MTcuNUgyLjJ6Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tYnJhbmQwIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzNGNTFCNSIgZD0iTTIuMiAyLjJ2MTcuNWgxNy41bC4xLTE3LjVIMi4yem0xMi4xIDIuMmMxLjIgMCAyLjIgMSAyLjIgMi4ycy0xIDIuMi0yLjIgMi4yLTIuMi0xLTIuMi0yLjIgMS0yLjIgMi4yLTIuMnpNNC40IDE3LjZsMy4zLTguOCAzLjMgNi42IDIuMi0zLjIgNC40IDUuNEg0LjR6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-info: url(data:image/svg+xml;base64,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);
  --jp-icon-inspector: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaW5zcGVjdG9yLWljb24tY29sb3IganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMjAgNEg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMThjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY2YzAtMS4xLS45LTItMi0yem0tNSAxNEg0di00aDExdjR6bTAtNUg0VjloMTF2NHptNSA1aC00VjloNHY5eiIvPgo8L3N2Zz4K);
  --jp-icon-json: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtanNvbi1pY29uLWNvbG9yIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iI0Y5QTgyNSI+CiAgICA8cGF0aCBkPSJNMjAuMiAxMS44Yy0xLjYgMC0xLjcuNS0xLjcgMSAwIC40LjEuOS4xIDEuMy4xLjUuMS45LjEgMS4zIDAgMS43LTEuNCAyLjMtMy41IDIuM2gtLjl2LTEuOWguNWMxLjEgMCAxLjQgMCAxLjQtLjggMC0uMyAwLS42LS4xLTEgMC0uNC0uMS0uOC0uMS0xLjIgMC0xLjMgMC0xLjggMS4zLTItMS4zLS4yLTEuMy0uNy0xLjMtMiAwLS40LjEtLjguMS0xLjIuMS0uNC4xLS43LjEtMSAwLS44LS40LS43LTEuNC0uOGgtLjVWNC4xaC45YzIuMiAwIDMuNS43IDMuNSAyLjMgMCAuNC0uMS45LS4xIDEuMy0uMS41LS4xLjktLjEgMS4zIDAgLjUuMiAxIDEuNyAxdjEuOHpNMS44IDEwLjFjMS42IDAgMS43LS41IDEuNy0xIDAtLjQtLjEtLjktLjEtMS4zLS4xLS41LS4xLS45LS4xLTEuMyAwLTEuNiAxLjQtMi4zIDMuNS0yLjNoLjl2MS45aC0uNWMtMSAwLTEuNCAwLTEuNC44IDAgLjMgMCAuNi4xIDEgMCAuMi4xLjYuMSAxIDAgMS4zIDAgMS44LTEuMyAyQzYgMTEuMiA2IDExLjcgNiAxM2MwIC40LS4xLjgtLjEgMS4yLS4xLjMtLjEuNy0uMSAxIDAgLjguMy44IDEuNC44aC41djEuOWgtLjljLTIuMSAwLTMuNS0uNi0zLjUtMi4zIDAtLjQuMS0uOS4xLTEuMy4xLS41LjEtLjkuMS0xLjMgMC0uNS0uMi0xLTEuNy0xdi0xLjl6Ii8+CiAgICA8Y2lyY2xlIGN4PSIxMSIgY3k9IjEzLjgiIHI9IjIuMSIvPgogICAgPGNpcmNsZSBjeD0iMTEiIGN5PSI4LjIiIHI9IjIuMSIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-julia: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDMyNSAzMDAiPgogIDxnIGNsYXNzPSJqcC1icmFuZDAganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjY2IzYzMzIj4KICAgIDxwYXRoIGQ9Ik0gMTUwLjg5ODQzOCAyMjUgQyAxNTAuODk4NDM4IDI2Ni40MjE4NzUgMTE3LjMyMDMxMiAzMDAgNzUuODk4NDM4IDMwMCBDIDM0LjQ3NjU2MiAzMDAgMC44OTg0MzggMjY2LjQyMTg3NSAwLjg5ODQzOCAyMjUgQyAwLjg5ODQzOCAxODMuNTc4MTI1IDM0LjQ3NjU2MiAxNTAgNzUuODk4NDM4IDE1MCBDIDExNy4zMjAzMTIgMTUwIDE1MC44OTg0MzggMTgzLjU3ODEyNSAxNTAuODk4NDM4IDIyNSIvPgogIDwvZz4KICA8ZyBjbGFzcz0ianAtYnJhbmQwIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzM4OTgyNiI+CiAgICA8cGF0aCBkPSJNIDIzNy41IDc1IEMgMjM3LjUgMTE2LjQyMTg3NSAyMDMuOTIxODc1IDE1MCAxNjIuNSAxNTAgQyAxMjEuMDc4MTI1IDE1MCA4Ny41IDExNi40MjE4NzUgODcuNSA3NSBDIDg3LjUgMzMuNTc4MTI1IDEyMS4wNzgxMjUgMCAxNjIuNSAwIEMgMjAzLjkyMTg3NSAwIDIzNy41IDMzLjU3ODEyNSAyMzcuNSA3NSIvPgogIDwvZz4KICA8ZyBjbGFzcz0ianAtYnJhbmQwIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzk1NThiMiI+CiAgICA8cGF0aCBkPSJNIDMyNC4xMDE1NjIgMjI1IEMgMzI0LjEwMTU2MiAyNjYuNDIxODc1IDI5MC41MjM0MzggMzAwIDI0OS4xMDE1NjIgMzAwIEMgMjA3LjY3OTY4OCAzMDAgMTc0LjEwMTU2MiAyNjYuNDIxODc1IDE3NC4xMDE1NjIgMjI1IEMgMTc0LjEwMTU2MiAxODMuNTc4MTI1IDIwNy42Nzk2ODggMTUwIDI0OS4xMDE1NjIgMTUwIEMgMjkwLjUyMzQzOCAxNTAgMzI0LjEwMTU2MiAxODMuNTc4MTI1IDMyNC4xMDE1NjIgMjI1Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-jupyter-favicon: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTUyIiBoZWlnaHQ9IjE2NSIgdmlld0JveD0iMCAwIDE1MiAxNjUiIHZlcnNpb249IjEuMSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgPGcgY2xhc3M9ImpwLWp1cHl0ZXItaWNvbi1jb2xvciIgZmlsbD0iI0YzNzcyNiI+CiAgICA8cGF0aCB0cmFuc2Zvcm09InRyYW5zbGF0ZSgwLjA3ODk0NywgMTEwLjU4MjkyNykiIGQ9Ik03NS45NDIyODQyLDI5LjU4MDQ1NjEgQzQzLjMwMjM5NDcsMjkuNTgwNDU2MSAxNC43OTY3ODMyLDE3LjY1MzQ2MzQgMCwwIEM1LjUxMDgzMjExLDE1Ljg0MDY4MjkgMTUuNzgxNTM4OSwyOS41NjY3NzMyIDI5LjM5MDQ5NDcsMzkuMjc4NDE3MSBDNDIuOTk5Nyw0OC45ODk4NTM3IDU5LjI3MzcsNTQuMjA2NzgwNSA3NS45NjA1Nzg5LDU0LjIwNjc4MDUgQzkyLjY0NzQ1NzksNTQuMjA2NzgwNSAxMDguOTIxNDU4LDQ4Ljk4OTg1MzcgMTIyLjUzMDY2MywzOS4yNzg0MTcxIEMxMzYuMTM5NDUzLDI5LjU2Njc3MzIgMTQ2LjQxMDI4NCwxNS44NDA2ODI5IDE1MS45MjExNTgsMCBDMTM3LjA4Nzg2OCwxNy42NTM0NjM0IDEwOC41ODI1ODksMjkuNTgwNDU2MSA3NS45NDIyODQyLDI5LjU4MDQ1NjEgTDc1Ljk0MjI4NDIsMjkuNTgwNDU2MSBaIiAvPgogICAgPHBhdGggdHJhbnNmb3JtPSJ0cmFuc2xhdGUoMC4wMzczNjgsIDAuNzA0ODc4KSIgZD0iTTc1Ljk3ODQ1NzksMjQuNjI2NDA3MyBDMTA4LjYxODc2MywyNC42MjY0MDczIDEzNy4xMjQ0NTgsMzYuNTUzNDQxNSAxNTEuOTIxMTU4LDU0LjIwNjc4MDUgQzE0Ni40MTAyODQsMzguMzY2MjIyIDEzNi4xMzk0NTMsMjQuNjQwMTMxNyAxMjIuNTMwNjYzLDE0LjkyODQ4NzggQzEwOC45MjE0NTgsNS4yMTY4NDM5IDkyLjY0NzQ1NzksMCA3NS45NjA1Nzg5LDAgQzU5LjI3MzcsMCA0Mi45OTk3LDUuMjE2ODQzOSAyOS4zOTA0OTQ3LDE0LjkyODQ4NzggQzE1Ljc4MTUzODksMjQuNjQwMTMxNyA1LjUxMDgzMjExLDM4LjM2NjIyMiAwLDU0LjIwNjc4MDUgQzE0LjgzMzA4MTYsMzYuNTg5OTI5MyA0My4zMzg1Njg0LDI0LjYyNjQwNzMgNzUuOTc4NDU3OSwyNC42MjY0MDczIEw3NS45Nzg0NTc5LDI0LjYyNjQwNzMgWiIgLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-jupyter: url(data:image/svg+xml;base64,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);
  --jp-icon-jupyterlab-wordmark: url(data:image/svg+xml;base64,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);
  --jp-icon-kernel: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgZmlsbD0iIzYxNjE2MSIgZD0iTTE1IDlIOXY2aDZWOXptLTIgNGgtMnYtMmgydjJ6bTgtMlY5aC0yVjdjMC0xLjEtLjktMi0yLTJoLTJWM2gtMnYyaC0yVjNIOXYySDdjLTEuMSAwLTIgLjktMiAydjJIM3YyaDJ2MkgzdjJoMnYyYzAgMS4xLjkgMiAyIDJoMnYyaDJ2LTJoMnYyaDJ2LTJoMmMxLjEgMCAyLS45IDItMnYtMmgydi0yaC0ydi0yaDJ6bS00IDZIN1Y3aDEwdjEweiIvPgo8L3N2Zz4K);
  --jp-icon-keyboard: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMjAgNUg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMTdjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY3YzAtMS4xLS45LTItMi0yem0tOSAzaDJ2MmgtMlY4em0wIDNoMnYyaC0ydi0yek04IDhoMnYySDhWOHptMCAzaDJ2Mkg4di0yem0tMSAySDV2LTJoMnYyem0wLTNINVY4aDJ2MnptOSA3SDh2LTJoOHYyem0wLTRoLTJ2LTJoMnYyem0wLTNoLTJWOGgydjJ6bTMgM2gtMnYtMmgydjJ6bTAtM2gtMlY4aDJ2MnoiLz4KPC9zdmc+Cg==);
  --jp-icon-launch: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMzIgMzIiIHdpZHRoPSIzMiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik0yNiwyOEg2YTIuMDAyNywyLjAwMjcsMCwwLDEtMi0yVjZBMi4wMDI3LDIuMDAyNywwLDAsMSw2LDRIMTZWNkg2VjI2SDI2VjE2aDJWMjZBMi4wMDI3LDIuMDAyNywwLDAsMSwyNiwyOFoiLz4KICAgIDxwb2x5Z29uIHBvaW50cz0iMjAgMiAyMCA0IDI2LjU4NiA0IDE4IDEyLjU4NiAxOS40MTQgMTQgMjggNS40MTQgMjggMTIgMzAgMTIgMzAgMiAyMCAyIi8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-launcher: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkgMTlINVY1aDdWM0g1YTIgMiAwIDAwLTIgMnYxNGEyIDIgMCAwMDIgMmgxNGMxLjEgMCAyLS45IDItMnYtN2gtMnY3ek0xNCAzdjJoMy41OWwtOS44MyA5LjgzIDEuNDEgMS40MUwxOSA2LjQxVjEwaDJWM2gtN3oiLz4KPC9zdmc+Cg==);
  --jp-icon-line-form: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGZpbGw9IndoaXRlIiBkPSJNNS44OCA0LjEyTDEzLjc2IDEybC03Ljg4IDcuODhMOCAyMmwxMC0xMEw4IDJ6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-link: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTMuOSAxMmMwLTEuNzEgMS4zOS0zLjEgMy4xLTMuMWg0VjdIN2MtMi43NiAwLTUgMi4yNC01IDVzMi4yNCA1IDUgNWg0di0xLjlIN2MtMS43MSAwLTMuMS0xLjM5LTMuMS0zLjF6TTggMTNoOHYtMkg4djJ6bTktNmgtNHYxLjloNGMxLjcxIDAgMy4xIDEuMzkgMy4xIDMuMXMtMS4zOSAzLjEtMy4xIDMuMWgtNFYxN2g0YzIuNzYgMCA1LTIuMjQgNS01cy0yLjI0LTUtNS01eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-list: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiIGQ9Ik0xOSA1djE0SDVWNWgxNG0xLjEtMkgzLjljLS41IDAtLjkuNC0uOS45djE2LjJjMCAuNC40LjkuOS45aDE2LjJjLjQgMCAuOS0uNS45LS45VjMuOWMwLS41LS41LS45LS45LS45ek0xMSA3aDZ2MmgtNlY3em0wIDRoNnYyaC02di0yem0wIDRoNnYyaC02ek03IDdoMnYySDd6bTAgNGgydjJIN3ptMCA0aDJ2Mkg3eiIvPgo8L3N2Zz4K);
  --jp-icon-markdown: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDAganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjN0IxRkEyIiBkPSJNNSAxNC45aDEybC02LjEgNnptOS40LTYuOGMwLTEuMy0uMS0yLjktLjEtNC41LS40IDEuNC0uOSAyLjktMS4zIDQuM2wtMS4zIDQuM2gtMkw4LjUgNy45Yy0uNC0xLjMtLjctMi45LTEtNC4zLS4xIDEuNi0uMSAzLjItLjIgNC42TDcgMTIuNEg0LjhsLjctMTFoMy4zTDEwIDVjLjQgMS4yLjcgMi43IDEgMy45LjMtMS4yLjctMi42IDEtMy45bDEuMi0zLjdoMy4zbC42IDExaC0yLjRsLS4zLTQuMnoiLz4KPC9zdmc+Cg==);
  --jp-icon-move-down: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBkPSJNMTIuNDcxIDcuNTI4OTlDMTIuNzYzMiA3LjIzNjg0IDEyLjc2MzIgNi43NjMxNiAxMi40NzEgNi40NzEwMVY2LjQ3MTAxQzEyLjE3OSA2LjE3OTA1IDExLjcwNTcgNi4xNzg4NCAxMS40MTM1IDYuNDcwNTRMNy43NSAxMC4xMjc1VjEuNzVDNy43NSAxLjMzNTc5IDcuNDE0MjEgMSA3IDFWMUM2LjU4NTc5IDEgNi4yNSAxLjMzNTc5IDYuMjUgMS43NVYxMC4xMjc1TDIuNTk3MjYgNi40NjgyMkMyLjMwMzM4IDYuMTczODEgMS44MjY0MSA2LjE3MzU5IDEuNTMyMjYgNi40Njc3NFY2LjQ2Nzc0QzEuMjM4MyA2Ljc2MTcgMS4yMzgzIDcuMjM4MyAxLjUzMjI2IDcuNTMyMjZMNi4yOTI4OSAxMi4yOTI5QzYuNjgzNDIgMTIuNjgzNCA3LjMxNjU4IDEyLjY4MzQgNy43MDcxMSAxMi4yOTI5TDEyLjQ3MSA3LjUyODk5WiIgZmlsbD0iIzYxNjE2MSIvPgo8L3N2Zz4K);
  --jp-icon-move-up: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBkPSJNMS41Mjg5OSA2LjQ3MTAxQzEuMjM2ODQgNi43NjMxNiAxLjIzNjg0IDcuMjM2ODQgMS41Mjg5OSA3LjUyODk5VjcuNTI4OTlDMS44MjA5NSA3LjgyMDk1IDIuMjk0MjYgNy44MjExNiAyLjU4NjQ5IDcuNTI5NDZMNi4yNSAzLjg3MjVWMTIuMjVDNi4yNSAxMi42NjQyIDYuNTg1NzkgMTMgNyAxM1YxM0M3LjQxNDIxIDEzIDcuNzUgMTIuNjY0MiA3Ljc1IDEyLjI1VjMuODcyNUwxMS40MDI3IDcuNTMxNzhDMTEuNjk2NiA3LjgyNjE5IDEyLjE3MzYgNy44MjY0MSAxMi40Njc3IDcuNTMyMjZWNy41MzIyNkMxMi43NjE3IDcuMjM4MyAxMi43NjE3IDYuNzYxNyAxMi40Njc3IDYuNDY3NzRMNy43MDcxMSAxLjcwNzExQzcuMzE2NTggMS4zMTY1OCA2LjY4MzQyIDEuMzE2NTggNi4yOTI4OSAxLjcwNzExTDEuNTI4OTkgNi40NzEwMVoiIGZpbGw9IiM2MTYxNjEiLz4KPC9zdmc+Cg==);
  --jp-icon-new-folder: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIwIDZoLThsLTItMkg0Yy0xLjExIDAtMS45OS44OS0xLjk5IDJMMiAxOGMwIDEuMTEuODkgMiAyIDJoMTZjMS4xMSAwIDItLjg5IDItMlY4YzAtMS4xMS0uODktMi0yLTJ6bS0xIDhoLTN2M2gtMnYtM2gtM3YtMmgzVjloMnYzaDN2MnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-not-trusted: url(data:image/svg+xml;base64,PHN2ZyBmaWxsPSJub25lIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI1IDI1Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDMgMykiIGQ9Ik0xLjg2MDk0IDExLjQ0MDlDMC44MjY0NDggOC43NzAyNyAwLjg2Mzc3OSA2LjA1NzY0IDEuMjQ5MDcgNC4xOTkzMkMyLjQ4MjA2IDMuOTMzNDcgNC4wODA2OCAzLjQwMzQ3IDUuNjAxMDIgMi44NDQ5QzcuMjM1NDkgMi4yNDQ0IDguODU2NjYgMS41ODE1IDkuOTg3NiAxLjA5NTM5QzExLjA1OTcgMS41ODM0MSAxMi42MDk0IDIuMjQ0NCAxNC4yMTggMi44NDMzOUMxNS43NTAzIDMuNDEzOTQgMTcuMzk5NSAzLjk1MjU4IDE4Ljc1MzkgNC4yMTM4NUMxOS4xMzY0IDYuMDcxNzcgMTkuMTcwOSA4Ljc3NzIyIDE4LjEzOSAxMS40NDA5QzE3LjAzMDMgMTQuMzAzMiAxNC42NjY4IDE3LjE4NDQgOS45OTk5OSAxOC45MzU0QzUuMzMzMTkgMTcuMTg0NCAyLjk2OTY4IDE0LjMwMzIgMS44NjA5NCAxMS40NDA5WiIvPgogICAgPHBhdGggY2xhc3M9ImpwLWljb24yIiBzdHJva2U9IiMzMzMzMzMiIHN0cm9rZS13aWR0aD0iMiIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoOS4zMTU5MiA5LjMyMDMxKSIgZD0iTTcuMzY4NDIgMEwwIDcuMzY0NzkiLz4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDkuMzE1OTIgMTYuNjgzNikgc2NhbGUoMSAtMSkiIGQ9Ik03LjM2ODQyIDBMMCA3LjM2NDc5Ii8+Cjwvc3ZnPgo=);
  --jp-icon-notebook: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtbm90ZWJvb2staWNvbi1jb2xvciBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiNFRjZDMDAiPgogICAgPHBhdGggZD0iTTE4LjcgMy4zdjE1LjRIMy4zVjMuM2gxNS40bTEuNS0xLjVIMS44djE4LjNoMTguM2wuMS0xOC4zeiIvPgogICAgPHBhdGggZD0iTTE2LjUgMTYuNWwtNS40LTQuMy01LjYgNC4zdi0xMWgxMXoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-numbering: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjIiIGhlaWdodD0iMjIiIHZpZXdCb3g9IjAgMCAyOCAyOCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CgkJPHBhdGggZD0iTTQgMTlINlYxOS41SDVWMjAuNUg2VjIxSDRWMjJIN1YxOEg0VjE5Wk01IDEwSDZWNkg0VjdINVYxMFpNNCAxM0g1LjhMNCAxNS4xVjE2SDdWMTVINS4yTDcgMTIuOVYxMkg0VjEzWk05IDdWOUgyM1Y3SDlaTTkgMjFIMjNWMTlIOVYyMVpNOSAxNUgyM1YxM0g5VjE1WiIvPgoJPC9nPgo8L3N2Zz4K);
  --jp-icon-offline-bolt: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyNCAyNCIgd2lkdGg9IjE2Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyIDIuMDJjLTUuNTEgMC05Ljk4IDQuNDctOS45OCA5Ljk4czQuNDcgOS45OCA5Ljk4IDkuOTggOS45OC00LjQ3IDkuOTgtOS45OFMxNy41MSAyLjAyIDEyIDIuMDJ6TTExLjQ4IDIwdi02LjI2SDhMMTMgNHY2LjI2aDMuMzVMMTEuNDggMjB6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-palette: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE4IDEzVjIwSDRWNkg5LjAyQzkuMDcgNS4yOSA5LjI0IDQuNjIgOS41IDRINEMyLjkgNCAyIDQuOSAyIDZWMjBDMiAyMS4xIDIuOSAyMiA0IDIySDE4QzE5LjEgMjIgMjAgMjEuMSAyMCAyMFYxNUwxOCAxM1pNMTkuMyA4Ljg5QzE5Ljc0IDguMTkgMjAgNy4zOCAyMCA2LjVDMjAgNC4wMSAxNy45OSAyIDE1LjUgMkMxMy4wMSAyIDExIDQuMDEgMTEgNi41QzExIDguOTkgMTMuMDEgMTEgMTUuNDkgMTFDMTYuMzcgMTEgMTcuMTkgMTAuNzQgMTcuODggMTAuM0wyMSAxMy40MkwyMi40MiAxMkwxOS4zIDguODlaTTE1LjUgOUMxNC4xMiA5IDEzIDcuODggMTMgNi41QzEzIDUuMTIgMTQuMTIgNCAxNS41IDRDMTYuODggNCAxOCA1LjEyIDE4IDYuNUMxOCA3Ljg4IDE2Ljg4IDkgMTUuNSA5WiIvPgogICAgPHBhdGggZmlsbC1ydWxlPSJldmVub2RkIiBjbGlwLXJ1bGU9ImV2ZW5vZGQiIGQ9Ik00IDZIOS4wMTg5NEM5LjAwNjM5IDYuMTY1MDIgOSA2LjMzMTc2IDkgNi41QzkgOC44MTU3NyAxMC4yMTEgMTAuODQ4NyAxMi4wMzQzIDEySDlWMTRIMTZWMTIuOTgxMUMxNi41NzAzIDEyLjkzNzcgMTcuMTIgMTIuODIwNyAxNy42Mzk2IDEyLjYzOTZMMTggMTNWMjBINFY2Wk04IDhINlYxMEg4VjhaTTYgMTJIOFYxNEg2VjEyWk04IDE2SDZWMThIOFYxNlpNOSAxNkgxNlYxOEg5VjE2WiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-paste: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTE5IDJoLTQuMThDMTQuNC44NCAxMy4zIDAgMTIgMGMtMS4zIDAtMi40Ljg0LTIuODIgMkg1Yy0xLjEgMC0yIC45LTIgMnYxNmMwIDEuMS45IDIgMiAyaDE0YzEuMSAwIDItLjkgMi0yVjRjMC0xLjEtLjktMi0yLTJ6bS03IDBjLjU1IDAgMSAuNDUgMSAxcy0uNDUgMS0xIDEtMS0uNDUtMS0xIC40NS0xIDEtMXptNyAxOEg1VjRoMnYzaDEwVjRoMnYxNnoiLz4KICAgIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-pdf: url(data:image/svg+xml;base64,PHN2ZwogICB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyMiAyMiIgd2lkdGg9IjE2Ij4KICAgIDxwYXRoIHRyYW5zZm9ybT0icm90YXRlKDQ1KSIgY2xhc3M9ImpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iI0ZGMkEyQSIKICAgICAgIGQ9Im0gMjIuMzQ0MzY5LC0zLjAxNjM2NDIgaCA1LjYzODYwNCB2IDEuNTc5MjQzMyBoIC0zLjU0OTIyNyB2IDEuNTA4NjkyOTkgaCAzLjMzNzU3NiBWIDEuNjUwODE1NCBoIC0zLjMzNzU3NiB2IDMuNDM1MjYxMyBoIC0yLjA4OTM3NyB6IG0gLTcuMTM2NDQ0LDEuNTc5MjQzMyB2IDQuOTQzOTU0MyBoIDAuNzQ4OTIgcSAxLjI4MDc2MSwwIDEuOTUzNzAzLC0wLjYzNDk1MzUgMC42NzgzNjksLTAuNjM0OTUzNSAwLjY3ODM2OSwtMS44NDUxNjQxIDAsLTEuMjA0NzgzNTUgLTAuNjcyOTQyLC0xLjgzNDMxMDExIC0wLjY3Mjk0MiwtMC42Mjk1MjY1OSAtMS45NTkxMywtMC42Mjk1MjY1OSB6IG0gLTIuMDg5Mzc3LC0xLjU3OTI0MzMgaCAyLjIwMzM0MyBxIDEuODQ1MTY0LDAgMi43NDYwMzksMC4yNjU5MjA3IDAuOTA2MzAxLDAuMjYwNDkzNyAxLjU1MjEwOCwwLjg5MDAyMDMgMC41Njk4MywwLjU0ODEyMjMgMC44NDY2MDUsMS4yNjQ0ODAwNiAwLjI3Njc3NCwwLjcxNjM1NzgxIDAuMjc2Nzc0LDEuNjIyNjU4OTQgMCwwLjkxNzE1NTEgLTAuMjc2Nzc0LDEuNjM4OTM5OSAtMC4yNzY3NzUsMC43MTYzNTc4IC0wLjg0NjYwNSwxLjI2NDQ4IC0wLjY1MTIzNCwwLjYyOTUyNjYgLTEuNTYyOTYyLDAuODk1NDQ3MyAtMC45MTE3MjgsMC4yNjA0OTM3IC0yLjczNTE4NSwwLjI2MDQ5MzcgaCAtMi4yMDMzNDMgeiBtIC04LjE0NTg1NjUsMCBoIDMuNDY3ODIzIHEgMS41NDY2ODE2LDAgMi4zNzE1Nzg1LDAuNjg5MjIzIDAuODMwMzI0LDAuNjgzNzk2MSAwLjgzMDMyNCwxLjk1MzcwMzE0IDAsMS4yNzUzMzM5NyAtMC44MzAzMjQsMS45NjQ1NTcwNiBRIDkuOTg3MTk2MSwyLjI3NDkxNSA4LjQ0MDUxNDUsMi4yNzQ5MTUgSCA3LjA2MjA2ODQgViA1LjA4NjA3NjcgSCA0Ljk3MjY5MTUgWiBtIDIuMDg5Mzc2OSwxLjUxNDExOTkgdiAyLjI2MzAzOTQzIGggMS4xNTU5NDEgcSAwLjYwNzgxODgsMCAwLjkzODg2MjksLTAuMjkzMDU1NDcgMC4zMzEwNDQxLC0wLjI5ODQ4MjQxIDAuMzMxMDQ0MSwtMC44NDExNzc3MiAwLC0wLjU0MjY5NTMxIC0wLjMzMTA0NDEsLTAuODM1NzUwNzQgLTAuMzMxMDQ0MSwtMC4yOTMwNTU1IC0wLjkzODg2MjksLTAuMjkzMDU1NSB6IgovPgo8L3N2Zz4K);
  --jp-icon-python: url(data:image/svg+xml;base64,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);
  --jp-icon-r-kernel: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMjE5NkYzIiBkPSJNNC40IDIuNWMxLjItLjEgMi45LS4zIDQuOS0uMyAyLjUgMCA0LjEuNCA1LjIgMS4zIDEgLjcgMS41IDEuOSAxLjUgMy41IDAgMi0xLjQgMy41LTIuOSA0LjEgMS4yLjQgMS43IDEuNiAyLjIgMyAuNiAxLjkgMSAzLjkgMS4zIDQuNmgtMy44Yy0uMy0uNC0uOC0xLjctMS4yLTMuN3MtMS4yLTIuNi0yLjYtMi42aC0uOXY2LjRINC40VjIuNXptMy43IDYuOWgxLjRjMS45IDAgMi45LS45IDIuOS0yLjNzLTEtMi4zLTIuOC0yLjNjLS43IDAtMS4zIDAtMS42LjJ2NC41aC4xdi0uMXoiLz4KPC9zdmc+Cg==);
  --jp-icon-react: url(data:image/svg+xml;base64,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);
  --jp-icon-redo: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMjQiIHZpZXdCb3g9IjAgMCAyNCAyNCIgd2lkdGg9IjE2Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgICA8cGF0aCBkPSJNMCAwaDI0djI0SDB6IiBmaWxsPSJub25lIi8+PHBhdGggZD0iTTE4LjQgMTAuNkMxNi41NSA4Ljk5IDE0LjE1IDggMTEuNSA4Yy00LjY1IDAtOC41OCAzLjAzLTkuOTYgNy4yMkwzLjkgMTZjMS4wNS0zLjE5IDQuMDUtNS41IDcuNi01LjUgMS45NSAwIDMuNzMuNzIgNS4xMiAxLjg4TDEzIDE2aDlWN2wtMy42IDMuNnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-refresh: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTkgMTMuNWMtMi40OSAwLTQuNS0yLjAxLTQuNS00LjVTNi41MSA0LjUgOSA0LjVjMS4yNCAwIDIuMzYuNTIgMy4xNyAxLjMzTDEwIDhoNVYzbC0xLjc2IDEuNzZDMTIuMTUgMy42OCAxMC42NiAzIDkgMyA1LjY5IDMgMy4wMSA1LjY5IDMuMDEgOVM1LjY5IDE1IDkgMTVjMi45NyAwIDUuNDMtMi4xNiA1LjktNWgtMS41MmMtLjQ2IDItMi4yNCAzLjUtNC4zOCAzLjV6Ii8+CiAgICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-regex: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KICA8ZyBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiM0MTQxNDEiPgogICAgPHJlY3QgeD0iMiIgeT0iMiIgd2lkdGg9IjE2IiBoZWlnaHQ9IjE2Ii8+CiAgPC9nPgoKICA8ZyBjbGFzcz0ianAtaWNvbi1hY2NlbnQyIiBmaWxsPSIjRkZGIj4KICAgIDxjaXJjbGUgY2xhc3M9InN0MiIgY3g9IjUuNSIgY3k9IjE0LjUiIHI9IjEuNSIvPgogICAgPHJlY3QgeD0iMTIiIHk9IjQiIGNsYXNzPSJzdDIiIHdpZHRoPSIxIiBoZWlnaHQ9IjgiLz4KICAgIDxyZWN0IHg9IjguNSIgeT0iNy41IiB0cmFuc2Zvcm09Im1hdHJpeCgwLjg2NiAtMC41IDAuNSAwLjg2NiAtMi4zMjU1IDcuMzIxOSkiIGNsYXNzPSJzdDIiIHdpZHRoPSI4IiBoZWlnaHQ9IjEiLz4KICAgIDxyZWN0IHg9IjEyIiB5PSI0IiB0cmFuc2Zvcm09Im1hdHJpeCgwLjUgLTAuODY2IDAuODY2IDAuNSAtMC42Nzc5IDE0LjgyNTIpIiBjbGFzcz0ic3QyIiB3aWR0aD0iMSIgaGVpZ2h0PSI4Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-run: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTggNXYxNGwxMS03eiIvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-running: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDUxMiA1MTIiPgogIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICA8cGF0aCBkPSJNMjU2IDhDMTE5IDggOCAxMTkgOCAyNTZzMTExIDI0OCAyNDggMjQ4IDI0OC0xMTEgMjQ4LTI0OFMzOTMgOCAyNTYgOHptOTYgMzI4YzAgOC44LTcuMiAxNi0xNiAxNkgxNzZjLTguOCAwLTE2LTcuMi0xNi0xNlYxNzZjMC04LjggNy4yLTE2IDE2LTE2aDE2MGM4LjggMCAxNiA3LjIgMTYgMTZ2MTYweiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-save: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTE3IDNINWMtMS4xMSAwLTIgLjktMiAydjE0YzAgMS4xLjg5IDIgMiAyaDE0YzEuMSAwIDItLjkgMi0yVjdsLTQtNHptLTUgMTZjLTEuNjYgMC0zLTEuMzQtMy0zczEuMzQtMyAzLTMgMyAxLjM0IDMgMy0xLjM0IDMtMyAzem0zLTEwSDVWNWgxMHY0eiIvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-search: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyLjEsMTAuOWgtMC43bC0wLjItMC4yYzAuOC0wLjksMS4zLTIuMiwxLjMtMy41YzAtMy0yLjQtNS40LTUuNC01LjRTMS44LDQuMiwxLjgsNy4xczIuNCw1LjQsNS40LDUuNCBjMS4zLDAsMi41LTAuNSwzLjUtMS4zbDAuMiwwLjJ2MC43bDQuMSw0LjFsMS4yLTEuMkwxMi4xLDEwLjl6IE03LjEsMTAuOWMtMi4xLDAtMy43LTEuNy0zLjctMy43czEuNy0zLjcsMy43LTMuN3MzLjcsMS43LDMuNywzLjcgUzkuMiwxMC45LDcuMSwxMC45eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-settings: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkuNDMgMTIuOThjLjA0LS4zMi4wNy0uNjQuMDctLjk4cy0uMDMtLjY2LS4wNy0uOThsMi4xMS0xLjY1Yy4xOS0uMTUuMjQtLjQyLjEyLS42NGwtMi0zLjQ2Yy0uMTItLjIyLS4zOS0uMy0uNjEtLjIybC0yLjQ5IDFjLS41Mi0uNC0xLjA4LS43My0xLjY5LS45OGwtLjM4LTIuNjVBLjQ4OC40ODggMCAwMDE0IDJoLTRjLS4yNSAwLS40Ni4xOC0uNDkuNDJsLS4zOCAyLjY1Yy0uNjEuMjUtMS4xNy41OS0xLjY5Ljk4bC0yLjQ5LTFjLS4yMy0uMDktLjQ5IDAtLjYxLjIybC0yIDMuNDZjLS4xMy4yMi0uMDcuNDkuMTIuNjRsMi4xMSAxLjY1Yy0uMDQuMzItLjA3LjY1LS4wNy45OHMuMDMuNjYuMDcuOThsLTIuMTEgMS42NWMtLjE5LjE1LS4yNC40Mi0uMTIuNjRsMiAzLjQ2Yy4xMi4yMi4zOS4zLjYxLjIybDIuNDktMWMuNTIuNCAxLjA4LjczIDEuNjkuOThsLjM4IDIuNjVjLjAzLjI0LjI0LjQyLjQ5LjQyaDRjLjI1IDAgLjQ2LS4xOC40OS0uNDJsLjM4LTIuNjVjLjYxLS4yNSAxLjE3LS41OSAxLjY5LS45OGwyLjQ5IDFjLjIzLjA5LjQ5IDAgLjYxLS4yMmwyLTMuNDZjLjEyLS4yMi4wNy0uNDktLjEyLS42NGwtMi4xMS0xLjY1ek0xMiAxNS41Yy0xLjkzIDAtMy41LTEuNTctMy41LTMuNXMxLjU3LTMuNSAzLjUtMy41IDMuNSAxLjU3IDMuNSAzLjUtMS41NyAzLjUtMy41IDMuNXoiLz4KPC9zdmc+Cg==);
  --jp-icon-share: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTYiIHZpZXdCb3g9IjAgMCAyNCAyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTSAxOCAyIEMgMTYuMzU0OTkgMiAxNSAzLjM1NDk5MDQgMTUgNSBDIDE1IDUuMTkwOTUyOSAxNS4wMjE3OTEgNS4zNzcxMjI0IDE1LjA1NjY0MSA1LjU1ODU5MzggTCA3LjkyMTg3NSA5LjcyMDcwMzEgQyA3LjM5ODUzOTkgOS4yNzc4NTM5IDYuNzMyMDc3MSA5IDYgOSBDIDQuMzU0OTkwNCA5IDMgMTAuMzU0OTkgMyAxMiBDIDMgMTMuNjQ1MDEgNC4zNTQ5OTA0IDE1IDYgMTUgQyA2LjczMjA3NzEgMTUgNy4zOTg1Mzk5IDE0LjcyMjE0NiA3LjkyMTg3NSAxNC4yNzkyOTcgTCAxNS4wNTY2NDEgMTguNDM5NDUzIEMgMTUuMDIxNTU1IDE4LjYyMTUxNCAxNSAxOC44MDgzODYgMTUgMTkgQyAxNSAyMC42NDUwMSAxNi4zNTQ5OSAyMiAxOCAyMiBDIDE5LjY0NTAxIDIyIDIxIDIwLjY0NTAxIDIxIDE5IEMgMjEgMTcuMzU0OTkgMTkuNjQ1MDEgMTYgMTggMTYgQyAxNy4yNjc0OCAxNiAxNi42MDE1OTMgMTYuMjc5MzI4IDE2LjA3ODEyNSAxNi43MjI2NTYgTCA4Ljk0MzM1OTQgMTIuNTU4NTk0IEMgOC45NzgyMDk1IDEyLjM3NzEyMiA5IDEyLjE5MDk1MyA5IDEyIEMgOSAxMS44MDkwNDcgOC45NzgyMDk1IDExLjYyMjg3OCA4Ljk0MzM1OTQgMTEuNDQxNDA2IEwgMTYuMDc4MTI1IDcuMjc5Mjk2OSBDIDE2LjYwMTQ2IDcuNzIyMTQ2MSAxNy4yNjc5MjMgOCAxOCA4IEMgMTkuNjQ1MDEgOCAyMSA2LjY0NTAwOTYgMjEgNSBDIDIxIDMuMzU0OTkwNCAxOS42NDUwMSAyIDE4IDIgeiBNIDE4IDQgQyAxOC41NjQxMjkgNCAxOSA0LjQzNTg3MDYgMTkgNSBDIDE5IDUuNTY0MTI5NCAxOC41NjQxMjkgNiAxOCA2IEMgMTcuNDM1ODcxIDYgMTcgNS41NjQxMjk0IDE3IDUgQyAxNyA0LjQzNTg3MDYgMTcuNDM1ODcxIDQgMTggNCB6IE0gNiAxMSBDIDYuNTY0MTI5NCAxMSA3IDExLjQzNTg3MSA3IDEyIEMgNyAxMi41NjQxMjkgNi41NjQxMjk0IDEzIDYgMTMgQyA1LjQzNTg3MDYgMTMgNSAxMi41NjQxMjkgNSAxMiBDIDUgMTEuNDM1ODcxIDUuNDM1ODcwNiAxMSA2IDExIHogTSAxOCAxOCBDIDE4LjU2NDEyOSAxOCAxOSAxOC40MzU4NzEgMTkgMTkgQyAxOSAxOS41NjQxMjkgMTguNTY0MTI5IDIwIDE4IDIwIEMgMTcuNDM1ODcxIDIwIDE3IDE5LjU2NDEyOSAxNyAxOSBDIDE3IDE4LjQzNTg3MSAxNy40MzU4NzEgMTggMTggMTggeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-spreadsheet: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDEganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNENBRjUwIiBkPSJNMi4yIDIuMnYxNy42aDE3LjZWMi4ySDIuMnptMTUuNCA3LjdoLTUuNVY0LjRoNS41djUuNXpNOS45IDQuNHY1LjVINC40VjQuNGg1LjV6bS01LjUgNy43aDUuNXY1LjVINC40di01LjV6bTcuNyA1LjV2LTUuNWg1LjV2NS41aC01LjV6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-stop: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPgogICAgICAgIDxwYXRoIGQ9Ik02IDZoMTJ2MTJINnoiLz4KICAgIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-tab: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIxIDNIM2MtMS4xIDAtMiAuOS0yIDJ2MTRjMCAxLjEuOSAyIDIgMmgxOGMxLjEgMCAyLS45IDItMlY1YzAtMS4xLS45LTItMi0yem0wIDE2SDNWNWgxMHY0aDh2MTB6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-table-rows: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPgogICAgICAgIDxwYXRoIGQ9Ik0yMSw4SDNWNGgxOFY4eiBNMjEsMTBIM3Y0aDE4VjEweiBNMjEsMTZIM3Y0aDE4VjE2eiIvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-tag: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjgiIGhlaWdodD0iMjgiIHZpZXdCb3g9IjAgMCA0MyAyOCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CgkJPHBhdGggZD0iTTI4LjgzMzIgMTIuMzM0TDMyLjk5OTggMTYuNTAwN0wzNy4xNjY1IDEyLjMzNEgyOC44MzMyWiIvPgoJCTxwYXRoIGQ9Ik0xNi4yMDk1IDIxLjYxMDRDMTUuNjg3MyAyMi4xMjk5IDE0Ljg0NDMgMjIuMTI5OSAxNC4zMjQ4IDIxLjYxMDRMNi45ODI5IDE0LjcyNDVDNi41NzI0IDE0LjMzOTQgNi4wODMxMyAxMy42MDk4IDYuMDQ3ODYgMTMuMDQ4MkM1Ljk1MzQ3IDExLjUyODggNi4wMjAwMiA4LjYxOTQ0IDYuMDY2MjEgNy4wNzY5NUM2LjA4MjgxIDYuNTE0NzcgNi41NTU0OCA2LjA0MzQ3IDcuMTE4MDQgNi4wMzA1NUM5LjA4ODYzIDUuOTg0NzMgMTMuMjYzOCA1LjkzNTc5IDEzLjY1MTggNi4zMjQyNUwyMS43MzY5IDEzLjYzOUMyMi4yNTYgMTQuMTU4NSAyMS43ODUxIDE1LjQ3MjQgMjEuMjYyIDE1Ljk5NDZMMTYuMjA5NSAyMS42MTA0Wk05Ljc3NTg1IDguMjY1QzkuMzM1NTEgNy44MjU2NiA4LjYyMzUxIDcuODI1NjYgOC4xODI4IDguMjY1QzcuNzQzNDYgOC43MDU3MSA3Ljc0MzQ2IDkuNDE3MzMgOC4xODI4IDkuODU2NjdDOC42MjM4MiAxMC4yOTY0IDkuMzM1ODIgMTAuMjk2NCA5Ljc3NTg1IDkuODU2NjdDMTAuMjE1NiA5LjQxNzMzIDEwLjIxNTYgOC43MDUzMyA5Ljc3NTg1IDguMjY1WiIvPgoJPC9nPgo8L3N2Zz4K);
  --jp-icon-terminal: url(data:image/svg+xml;base64,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);
  --jp-icon-text-editor: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtdGV4dC1lZGl0b3ItaWNvbi1jb2xvciBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiIGQ9Ik0xNSAxNUgzdjJoMTJ2LTJ6bTAtOEgzdjJoMTJWN3pNMyAxM2gxOHYtMkgzdjJ6bTAgOGgxOHYtMkgzdjJ6TTMgM3YyaDE4VjNIM3oiLz4KPC9zdmc+Cg==);
  --jp-icon-toc: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik03LDVIMjFWN0g3VjVNNywxM1YxMUgyMVYxM0g3TTQsNC41QTEuNSwxLjUgMCAwLDEgNS41LDZBMS41LDEuNSAwIDAsMSA0LDcuNUExLjUsMS41IDAgMCwxIDIuNSw2QTEuNSwxLjUgMCAwLDEgNCw0LjVNNCwxMC41QTEuNSwxLjUgMCAwLDEgNS41LDEyQTEuNSwxLjUgMCAwLDEgNCwxMy41QTEuNSwxLjUgMCAwLDEgMi41LDEyQTEuNSwxLjUgMCAwLDEgNCwxMC41TTcsMTlWMTdIMjFWMTlIN000LDE2LjVBMS41LDEuNSAwIDAsMSA1LjUsMThBMS41LDEuNSAwIDAsMSA0LDE5LjVBMS41LDEuNSAwIDAsMSAyLjUsMThBMS41LDEuNSAwIDAsMSA0LDE2LjVaIiAvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-tree-view: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPgogICAgICAgIDxwYXRoIGQ9Ik0yMiAxMVYzaC03djNIOVYzSDJ2OGg3VjhoMnYxMGg0djNoN3YtOGgtN3YzaC0yVjhoMnYzeiIvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-trusted: url(data:image/svg+xml;base64,PHN2ZyBmaWxsPSJub25lIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI1Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDIgMykiIGQ9Ik0xLjg2MDk0IDExLjQ0MDlDMC44MjY0NDggOC43NzAyNyAwLjg2Mzc3OSA2LjA1NzY0IDEuMjQ5MDcgNC4xOTkzMkMyLjQ4MjA2IDMuOTMzNDcgNC4wODA2OCAzLjQwMzQ3IDUuNjAxMDIgMi44NDQ5QzcuMjM1NDkgMi4yNDQ0IDguODU2NjYgMS41ODE1IDkuOTg3NiAxLjA5NTM5QzExLjA1OTcgMS41ODM0MSAxMi42MDk0IDIuMjQ0NCAxNC4yMTggMi44NDMzOUMxNS43NTAzIDMuNDEzOTQgMTcuMzk5NSAzLjk1MjU4IDE4Ljc1MzkgNC4yMTM4NUMxOS4xMzY0IDYuMDcxNzcgMTkuMTcwOSA4Ljc3NzIyIDE4LjEzOSAxMS40NDA5QzE3LjAzMDMgMTQuMzAzMiAxNC42NjY4IDE3LjE4NDQgOS45OTk5OSAxOC45MzU0QzUuMzMzMiAxNy4xODQ0IDIuOTY5NjggMTQuMzAzMiAxLjg2MDk0IDExLjQ0MDlaIi8+CiAgICA8cGF0aCBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiMzMzMzMzMiIHN0cm9rZT0iIzMzMzMzMyIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoOCA5Ljg2NzE5KSIgZD0iTTIuODYwMTUgNC44NjUzNUwwLjcyNjU0OSAyLjk5OTU5TDAgMy42MzA0NUwyLjg2MDE1IDYuMTMxNTdMOCAwLjYzMDg3Mkw3LjI3ODU3IDBMMi44NjAxNSA0Ljg2NTM1WiIvPgo8L3N2Zz4K);
  --jp-icon-undo: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyLjUgOGMtMi42NSAwLTUuMDUuOTktNi45IDIuNkwyIDd2OWg5bC0zLjYyLTMuNjJjMS4zOS0xLjE2IDMuMTYtMS44OCA1LjEyLTEuODggMy41NCAwIDYuNTUgMi4zMSA3LjYgNS41bDIuMzctLjc4QzIxLjA4IDExLjAzIDE3LjE1IDggMTIuNSA4eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-user: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTYiIHZpZXdCb3g9IjAgMCAyNCAyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE2IDdhNCA0IDAgMTEtOCAwIDQgNCAwIDAxOCAwek0xMiAxNGE3IDcgMCAwMC03IDdoMTRhNyA3IDAgMDAtNy03eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-users: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjQiIGhlaWdodD0iMjQiIHZlcnNpb249IjEuMSIgdmlld0JveD0iMCAwIDM2IDI0IiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciPgogPGcgY2xhc3M9ImpwLWljb24zIiB0cmFuc2Zvcm09Im1hdHJpeCgxLjczMjcgMCAwIDEuNzMyNyAtMy42MjgyIC4wOTk1NzcpIiBmaWxsPSIjNjE2MTYxIj4KICA8cGF0aCB0cmFuc2Zvcm09Im1hdHJpeCgxLjUsMCwwLDEuNSwwLC02KSIgZD0ibTEyLjE4NiA3LjUwOThjLTEuMDUzNSAwLTEuOTc1NyAwLjU2NjUtMi40Nzg1IDEuNDEwMiAwLjc1MDYxIDAuMzEyNzcgMS4zOTc0IDAuODI2NDggMS44NzMgMS40NzI3aDMuNDg2M2MwLTEuNTkyLTEuMjg4OS0yLjg4MjgtMi44ODA5LTIuODgyOHoiLz4KICA8cGF0aCBkPSJtMjAuNDY1IDIuMzg5NWEyLjE4ODUgMi4xODg1IDAgMCAxLTIuMTg4NCAyLjE4ODUgMi4xODg1IDIuMTg4NSAwIDAgMS0yLjE4ODUtMi4xODg1IDIuMTg4NSAyLjE4ODUgMCAwIDEgMi4xODg1LTIuMTg4NSAyLjE4ODUgMi4xODg1IDAgMCAxIDIuMTg4NCAyLjE4ODV6Ii8+CiAgPHBhdGggdHJhbnNmb3JtPSJtYXRyaXgoMS41LDAsMCwxLjUsMCwtNikiIGQ9Im0zLjU4OTggOC40MjE5Yy0xLjExMjYgMC0yLjAxMzcgMC45MDExMS0yLjAxMzcgMi4wMTM3aDIuODE0NWMwLjI2Nzk3LTAuMzczMDkgMC41OTA3LTAuNzA0MzUgMC45NTg5OC0wLjk3ODUyLTAuMzQ0MzMtMC42MTY4OC0xLjAwMzEtMS4wMzUyLTEuNzU5OC0xLjAzNTJ6Ii8+CiAgPHBhdGggZD0ibTYuOTE1NCA0LjYyM2ExLjUyOTQgMS41Mjk0IDAgMCAxLTEuNTI5NCAxLjUyOTQgMS41Mjk0IDEuNTI5NCAwIDAgMS0xLjUyOTQtMS41Mjk0IDEuNTI5NCAxLjUyOTQgMCAwIDEgMS41Mjk0LTEuNTI5NCAxLjUyOTQgMS41Mjk0IDAgMCAxIDEuNTI5NCAxLjUyOTR6Ii8+CiAgPHBhdGggZD0ibTYuMTM1IDEzLjUzNWMwLTMuMjM5MiAyLjYyNTktNS44NjUgNS44NjUtNS44NjUgMy4yMzkyIDAgNS44NjUgMi42MjU5IDUuODY1IDUuODY1eiIvPgogIDxjaXJjbGUgY3g9IjEyIiBjeT0iMy43Njg1IiByPSIyLjk2ODUiLz4KIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-vega: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbjEganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMjEyMTIxIj4KICAgIDxwYXRoIGQ9Ik0xMC42IDUuNGwyLjItMy4ySDIuMnY3LjNsNC02LjZ6Ii8+CiAgICA8cGF0aCBkPSJNMTUuOCAyLjJsLTQuNCA2LjZMNyA2LjNsLTQuOCA4djUuNWgxNy42VjIuMmgtNHptLTcgMTUuNEg1LjV2LTQuNGgzLjN2NC40em00LjQgMEg5LjhWOS44aDMuNHY3Ljh6bTQuNCAwaC0zLjRWNi41aDMuNHYxMS4xeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-word: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KIDxnIGNsYXNzPSJqcC1pY29uMiIgZmlsbD0iIzQxNDE0MSI+CiAgPHJlY3QgeD0iMiIgeT0iMiIgd2lkdGg9IjE2IiBoZWlnaHQ9IjE2Ii8+CiA8L2c+CiA8ZyBjbGFzcz0ianAtaWNvbi1hY2NlbnQyIiB0cmFuc2Zvcm09InRyYW5zbGF0ZSguNDMgLjA0MDEpIiBmaWxsPSIjZmZmIj4KICA8cGF0aCBkPSJtNC4xNCA4Ljc2cTAuMDY4Mi0xLjg5IDIuNDItMS44OSAxLjE2IDAgMS42OCAwLjQyIDAuNTY3IDAuNDEgMC41NjcgMS4xNnYzLjQ3cTAgMC40NjIgMC41MTQgMC40NjIgMC4xMDMgMCAwLjItMC4wMjMxdjAuNzE0cS0wLjM5OSAwLjEwMy0wLjY1MSAwLjEwMy0wLjQ1MiAwLTAuNjkzLTAuMjItMC4yMzEtMC4yLTAuMjg0LTAuNjYyLTAuOTU2IDAuODcyLTIgMC44NzItMC45MDMgMC0xLjQ3LTAuNDcyLTAuNTI1LTAuNDcyLTAuNTI1LTEuMjYgMC0wLjI2MiAwLjA0NTItMC40NzIgMC4wNTY3LTAuMjIgMC4xMTYtMC4zNzggMC4wNjgyLTAuMTY4IDAuMjMxLTAuMzA0IDAuMTU4LTAuMTQ3IDAuMjYyLTAuMjQyIDAuMTE2LTAuMDkxNCAwLjM2OC0wLjE2OCAwLjI2Mi0wLjA5MTQgMC4zOTktMC4xMjYgMC4xMzYtMC4wNDUyIDAuNDcyLTAuMTAzIDAuMzM2LTAuMDU3OCAwLjUwNC0wLjA3OTggMC4xNTgtMC4wMjMxIDAuNTY3LTAuMDc5OCAwLjU1Ni0wLjA2ODIgMC43NzctMC4yMjEgMC4yMi0wLjE1MiAwLjIyLTAuNDQxdi0wLjI1MnEwLTAuNDMtMC4zNTctMC42NjItMC4zMzYtMC4yMzEtMC45NzYtMC4yMzEtMC42NjIgMC0wLjk5OCAwLjI2Mi0wLjMzNiAwLjI1Mi0wLjM5OSAwLjc5OHptMS44OSAzLjY4cTAuNzg4IDAgMS4yNi0wLjQxIDAuNTA0LTAuNDIgMC41MDQtMC45MDN2LTEuMDVxLTAuMjg0IDAuMTM2LTAuODYxIDAuMjMxLTAuNTY3IDAuMDkxNC0wLjk4NyAwLjE1OC0wLjQyIDAuMDY4Mi0wLjc2NiAwLjMyNi0wLjMzNiAwLjI1Mi0wLjMzNiAwLjcwNHQwLjMwNCAwLjcwNCAwLjg2MSAwLjI1MnoiIHN0cm9rZS13aWR0aD0iMS4wNSIvPgogIDxwYXRoIGQ9Im0xMCA0LjU2aDAuOTQ1djMuMTVxMC42NTEtMC45NzYgMS44OS0wLjk3NiAxLjE2IDAgMS44OSAwLjg0IDAuNjgyIDAuODQgMC42ODIgMi4zMSAwIDEuNDctMC43MDQgMi40Mi0wLjcwNCAwLjg4Mi0xLjg5IDAuODgyLTEuMjYgMC0xLjg5LTEuMDJ2MC43NjZoLTAuODV6bTIuNjIgMy4wNHEtMC43NDYgMC0xLjE2IDAuNjQtMC40NTIgMC42My0wLjQ1MiAxLjY4IDAgMS4wNSAwLjQ1MiAxLjY4dDEuMTYgMC42M3EwLjc3NyAwIDEuMjYtMC42MyAwLjQ5NC0wLjY0IDAuNDk0LTEuNjggMC0xLjA1LTAuNDcyLTEuNjgtMC40NjItMC42NC0xLjI2LTAuNjR6IiBzdHJva2Utd2lkdGg9IjEuMDUiLz4KICA8cGF0aCBkPSJtMi43MyAxNS44IDEzLjYgMC4wMDgxYzAuMDA2OSAwIDAtMi42IDAtMi42IDAtMC4wMDc4LTEuMTUgMC0xLjE1IDAtMC4wMDY5IDAtMC4wMDgzIDEuNS0wLjAwODMgMS41LTJlLTMgLTAuMDAxNC0xMS4zLTAuMDAxNC0xMS4zLTAuMDAxNGwtMC4wMDU5Mi0xLjVjMC0wLjAwNzgtMS4xNyAwLjAwMTMtMS4xNyAwLjAwMTN6IiBzdHJva2Utd2lkdGg9Ii45NzUiLz4KIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-yaml: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbi1jb250cmFzdDIganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjRDgxQjYwIj4KICAgIDxwYXRoIGQ9Ik03LjIgMTguNnYtNS40TDMgNS42aDMuM2wxLjQgMy4xYy4zLjkuNiAxLjYgMSAyLjUuMy0uOC42LTEuNiAxLTIuNWwxLjQtMy4xaDMuNGwtNC40IDcuNnY1LjVsLTIuOS0uMXoiLz4KICAgIDxjaXJjbGUgY2xhc3M9InN0MCIgY3g9IjE3LjYiIGN5PSIxNi41IiByPSIyLjEiLz4KICAgIDxjaXJjbGUgY2xhc3M9InN0MCIgY3g9IjE3LjYiIGN5PSIxMSIgcj0iMi4xIi8+CiAgPC9nPgo8L3N2Zz4K);
}

/* Icon CSS class declarations */

.jp-AddAboveIcon {
  background-image: var(--jp-icon-add-above);
}

.jp-AddBelowIcon {
  background-image: var(--jp-icon-add-below);
}

.jp-AddIcon {
  background-image: var(--jp-icon-add);
}

.jp-BellIcon {
  background-image: var(--jp-icon-bell);
}

.jp-BugDotIcon {
  background-image: var(--jp-icon-bug-dot);
}

.jp-BugIcon {
  background-image: var(--jp-icon-bug);
}

.jp-BuildIcon {
  background-image: var(--jp-icon-build);
}

.jp-CaretDownEmptyIcon {
  background-image: var(--jp-icon-caret-down-empty);
}

.jp-CaretDownEmptyThinIcon {
  background-image: var(--jp-icon-caret-down-empty-thin);
}

.jp-CaretDownIcon {
  background-image: var(--jp-icon-caret-down);
}

.jp-CaretLeftIcon {
  background-image: var(--jp-icon-caret-left);
}

.jp-CaretRightIcon {
  background-image: var(--jp-icon-caret-right);
}

.jp-CaretUpEmptyThinIcon {
  background-image: var(--jp-icon-caret-up-empty-thin);
}

.jp-CaretUpIcon {
  background-image: var(--jp-icon-caret-up);
}

.jp-CaseSensitiveIcon {
  background-image: var(--jp-icon-case-sensitive);
}

.jp-CheckIcon {
  background-image: var(--jp-icon-check);
}

.jp-CircleEmptyIcon {
  background-image: var(--jp-icon-circle-empty);
}

.jp-CircleIcon {
  background-image: var(--jp-icon-circle);
}

.jp-ClearIcon {
  background-image: var(--jp-icon-clear);
}

.jp-CloseIcon {
  background-image: var(--jp-icon-close);
}

.jp-CodeCheckIcon {
  background-image: var(--jp-icon-code-check);
}

.jp-CodeIcon {
  background-image: var(--jp-icon-code);
}

.jp-CollapseAllIcon {
  background-image: var(--jp-icon-collapse-all);
}

.jp-ConsoleIcon {
  background-image: var(--jp-icon-console);
}

.jp-CopyIcon {
  background-image: var(--jp-icon-copy);
}

.jp-CopyrightIcon {
  background-image: var(--jp-icon-copyright);
}

.jp-CutIcon {
  background-image: var(--jp-icon-cut);
}

.jp-DeleteIcon {
  background-image: var(--jp-icon-delete);
}

.jp-DownloadIcon {
  background-image: var(--jp-icon-download);
}

.jp-DuplicateIcon {
  background-image: var(--jp-icon-duplicate);
}

.jp-EditIcon {
  background-image: var(--jp-icon-edit);
}

.jp-EllipsesIcon {
  background-image: var(--jp-icon-ellipses);
}

.jp-ErrorIcon {
  background-image: var(--jp-icon-error);
}

.jp-ExpandAllIcon {
  background-image: var(--jp-icon-expand-all);
}

.jp-ExtensionIcon {
  background-image: var(--jp-icon-extension);
}

.jp-FastForwardIcon {
  background-image: var(--jp-icon-fast-forward);
}

.jp-FileIcon {
  background-image: var(--jp-icon-file);
}

.jp-FileUploadIcon {
  background-image: var(--jp-icon-file-upload);
}

.jp-FilterDotIcon {
  background-image: var(--jp-icon-filter-dot);
}

.jp-FilterIcon {
  background-image: var(--jp-icon-filter);
}

.jp-FilterListIcon {
  background-image: var(--jp-icon-filter-list);
}

.jp-FolderFavoriteIcon {
  background-image: var(--jp-icon-folder-favorite);
}

.jp-FolderIcon {
  background-image: var(--jp-icon-folder);
}

.jp-HomeIcon {
  background-image: var(--jp-icon-home);
}

.jp-Html5Icon {
  background-image: var(--jp-icon-html5);
}

.jp-ImageIcon {
  background-image: var(--jp-icon-image);
}

.jp-InfoIcon {
  background-image: var(--jp-icon-info);
}

.jp-InspectorIcon {
  background-image: var(--jp-icon-inspector);
}

.jp-JsonIcon {
  background-image: var(--jp-icon-json);
}

.jp-JuliaIcon {
  background-image: var(--jp-icon-julia);
}

.jp-JupyterFaviconIcon {
  background-image: var(--jp-icon-jupyter-favicon);
}

.jp-JupyterIcon {
  background-image: var(--jp-icon-jupyter);
}

.jp-JupyterlabWordmarkIcon {
  background-image: var(--jp-icon-jupyterlab-wordmark);
}

.jp-KernelIcon {
  background-image: var(--jp-icon-kernel);
}

.jp-KeyboardIcon {
  background-image: var(--jp-icon-keyboard);
}

.jp-LaunchIcon {
  background-image: var(--jp-icon-launch);
}

.jp-LauncherIcon {
  background-image: var(--jp-icon-launcher);
}

.jp-LineFormIcon {
  background-image: var(--jp-icon-line-form);
}

.jp-LinkIcon {
  background-image: var(--jp-icon-link);
}

.jp-ListIcon {
  background-image: var(--jp-icon-list);
}

.jp-MarkdownIcon {
  background-image: var(--jp-icon-markdown);
}

.jp-MoveDownIcon {
  background-image: var(--jp-icon-move-down);
}

.jp-MoveUpIcon {
  background-image: var(--jp-icon-move-up);
}

.jp-NewFolderIcon {
  background-image: var(--jp-icon-new-folder);
}

.jp-NotTrustedIcon {
  background-image: var(--jp-icon-not-trusted);
}

.jp-NotebookIcon {
  background-image: var(--jp-icon-notebook);
}

.jp-NumberingIcon {
  background-image: var(--jp-icon-numbering);
}

.jp-OfflineBoltIcon {
  background-image: var(--jp-icon-offline-bolt);
}

.jp-PaletteIcon {
  background-image: var(--jp-icon-palette);
}

.jp-PasteIcon {
  background-image: var(--jp-icon-paste);
}

.jp-PdfIcon {
  background-image: var(--jp-icon-pdf);
}

.jp-PythonIcon {
  background-image: var(--jp-icon-python);
}

.jp-RKernelIcon {
  background-image: var(--jp-icon-r-kernel);
}

.jp-ReactIcon {
  background-image: var(--jp-icon-react);
}

.jp-RedoIcon {
  background-image: var(--jp-icon-redo);
}

.jp-RefreshIcon {
  background-image: var(--jp-icon-refresh);
}

.jp-RegexIcon {
  background-image: var(--jp-icon-regex);
}

.jp-RunIcon {
  background-image: var(--jp-icon-run);
}

.jp-RunningIcon {
  background-image: var(--jp-icon-running);
}

.jp-SaveIcon {
  background-image: var(--jp-icon-save);
}

.jp-SearchIcon {
  background-image: var(--jp-icon-search);
}

.jp-SettingsIcon {
  background-image: var(--jp-icon-settings);
}

.jp-ShareIcon {
  background-image: var(--jp-icon-share);
}

.jp-SpreadsheetIcon {
  background-image: var(--jp-icon-spreadsheet);
}

.jp-StopIcon {
  background-image: var(--jp-icon-stop);
}

.jp-TabIcon {
  background-image: var(--jp-icon-tab);
}

.jp-TableRowsIcon {
  background-image: var(--jp-icon-table-rows);
}

.jp-TagIcon {
  background-image: var(--jp-icon-tag);
}

.jp-TerminalIcon {
  background-image: var(--jp-icon-terminal);
}

.jp-TextEditorIcon {
  background-image: var(--jp-icon-text-editor);
}

.jp-TocIcon {
  background-image: var(--jp-icon-toc);
}

.jp-TreeViewIcon {
  background-image: var(--jp-icon-tree-view);
}

.jp-TrustedIcon {
  background-image: var(--jp-icon-trusted);
}

.jp-UndoIcon {
  background-image: var(--jp-icon-undo);
}

.jp-UserIcon {
  background-image: var(--jp-icon-user);
}

.jp-UsersIcon {
  background-image: var(--jp-icon-users);
}

.jp-VegaIcon {
  background-image: var(--jp-icon-vega);
}

.jp-WordIcon {
  background-image: var(--jp-icon-word);
}

.jp-YamlIcon {
  background-image: var(--jp-icon-yaml);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/**
 * (DEPRECATED) Support for consuming icons as CSS background images
 */

.jp-Icon,
.jp-MaterialIcon {
  background-position: center;
  background-repeat: no-repeat;
  background-size: 16px;
  min-width: 16px;
  min-height: 16px;
}

.jp-Icon-cover {
  background-position: center;
  background-repeat: no-repeat;
  background-size: cover;
}

/**
 * (DEPRECATED) Support for specific CSS icon sizes
 */

.jp-Icon-16 {
  background-size: 16px;
  min-width: 16px;
  min-height: 16px;
}

.jp-Icon-18 {
  background-size: 18px;
  min-width: 18px;
  min-height: 18px;
}

.jp-Icon-20 {
  background-size: 20px;
  min-width: 20px;
  min-height: 20px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.lm-TabBar .lm-TabBar-addButton {
  align-items: center;
  display: flex;
  padding: 4px;
  padding-bottom: 5px;
  margin-right: 1px;
  background-color: var(--jp-layout-color2);
}

.lm-TabBar .lm-TabBar-addButton:hover {
  background-color: var(--jp-layout-color1);
}

.lm-DockPanel-tabBar .lm-TabBar-tab {
  width: var(--jp-private-horizontal-tab-width);
}

.lm-DockPanel-tabBar .lm-TabBar-content {
  flex: unset;
}

.lm-DockPanel-tabBar[data-orientation='horizontal'] {
  flex: 1 1 auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/**
 * Support for icons as inline SVG HTMLElements
 */

/* recolor the primary elements of an icon */
.jp-icon0[fill] {
  fill: var(--jp-inverse-layout-color0);
}

.jp-icon1[fill] {
  fill: var(--jp-inverse-layout-color1);
}

.jp-icon2[fill] {
  fill: var(--jp-inverse-layout-color2);
}

.jp-icon3[fill] {
  fill: var(--jp-inverse-layout-color3);
}

.jp-icon4[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon0[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}

.jp-icon1[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}

.jp-icon2[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}

.jp-icon3[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}

.jp-icon4[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/* recolor the accent elements of an icon */
.jp-icon-accent0[fill] {
  fill: var(--jp-layout-color0);
}

.jp-icon-accent1[fill] {
  fill: var(--jp-layout-color1);
}

.jp-icon-accent2[fill] {
  fill: var(--jp-layout-color2);
}

.jp-icon-accent3[fill] {
  fill: var(--jp-layout-color3);
}

.jp-icon-accent4[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-accent0[stroke] {
  stroke: var(--jp-layout-color0);
}

.jp-icon-accent1[stroke] {
  stroke: var(--jp-layout-color1);
}

.jp-icon-accent2[stroke] {
  stroke: var(--jp-layout-color2);
}

.jp-icon-accent3[stroke] {
  stroke: var(--jp-layout-color3);
}

.jp-icon-accent4[stroke] {
  stroke: var(--jp-layout-color4);
}

/* set the color of an icon to transparent */
.jp-icon-none[fill] {
  fill: none;
}

.jp-icon-none[stroke] {
  stroke: none;
}

/* brand icon colors. Same for light and dark */
.jp-icon-brand0[fill] {
  fill: var(--jp-brand-color0);
}

.jp-icon-brand1[fill] {
  fill: var(--jp-brand-color1);
}

.jp-icon-brand2[fill] {
  fill: var(--jp-brand-color2);
}

.jp-icon-brand3[fill] {
  fill: var(--jp-brand-color3);
}

.jp-icon-brand4[fill] {
  fill: var(--jp-brand-color4);
}

.jp-icon-brand0[stroke] {
  stroke: var(--jp-brand-color0);
}

.jp-icon-brand1[stroke] {
  stroke: var(--jp-brand-color1);
}

.jp-icon-brand2[stroke] {
  stroke: var(--jp-brand-color2);
}

.jp-icon-brand3[stroke] {
  stroke: var(--jp-brand-color3);
}

.jp-icon-brand4[stroke] {
  stroke: var(--jp-brand-color4);
}

/* warn icon colors. Same for light and dark */
.jp-icon-warn0[fill] {
  fill: var(--jp-warn-color0);
}

.jp-icon-warn1[fill] {
  fill: var(--jp-warn-color1);
}

.jp-icon-warn2[fill] {
  fill: var(--jp-warn-color2);
}

.jp-icon-warn3[fill] {
  fill: var(--jp-warn-color3);
}

.jp-icon-warn0[stroke] {
  stroke: var(--jp-warn-color0);
}

.jp-icon-warn1[stroke] {
  stroke: var(--jp-warn-color1);
}

.jp-icon-warn2[stroke] {
  stroke: var(--jp-warn-color2);
}

.jp-icon-warn3[stroke] {
  stroke: var(--jp-warn-color3);
}

/* icon colors that contrast well with each other and most backgrounds */
.jp-icon-contrast0[fill] {
  fill: var(--jp-icon-contrast-color0);
}

.jp-icon-contrast1[fill] {
  fill: var(--jp-icon-contrast-color1);
}

.jp-icon-contrast2[fill] {
  fill: var(--jp-icon-contrast-color2);
}

.jp-icon-contrast3[fill] {
  fill: var(--jp-icon-contrast-color3);
}

.jp-icon-contrast0[stroke] {
  stroke: var(--jp-icon-contrast-color0);
}

.jp-icon-contrast1[stroke] {
  stroke: var(--jp-icon-contrast-color1);
}

.jp-icon-contrast2[stroke] {
  stroke: var(--jp-icon-contrast-color2);
}

.jp-icon-contrast3[stroke] {
  stroke: var(--jp-icon-contrast-color3);
}

.jp-icon-dot[fill] {
  fill: var(--jp-warn-color0);
}

.jp-jupyter-icon-color[fill] {
  fill: var(--jp-jupyter-icon-color, var(--jp-warn-color0));
}

.jp-notebook-icon-color[fill] {
  fill: var(--jp-notebook-icon-color, var(--jp-warn-color0));
}

.jp-json-icon-color[fill] {
  fill: var(--jp-json-icon-color, var(--jp-warn-color1));
}

.jp-console-icon-color[fill] {
  fill: var(--jp-console-icon-color, white);
}

.jp-console-icon-background-color[fill] {
  fill: var(--jp-console-icon-background-color, var(--jp-brand-color1));
}

.jp-terminal-icon-color[fill] {
  fill: var(--jp-terminal-icon-color, var(--jp-layout-color2));
}

.jp-terminal-icon-background-color[fill] {
  fill: var(
    --jp-terminal-icon-background-color,
    var(--jp-inverse-layout-color2)
  );
}

.jp-text-editor-icon-color[fill] {
  fill: var(--jp-text-editor-icon-color, var(--jp-inverse-layout-color3));
}

.jp-inspector-icon-color[fill] {
  fill: var(--jp-inspector-icon-color, var(--jp-inverse-layout-color3));
}

/* CSS for icons in selected filebrowser listing items */
.jp-DirListing-item.jp-mod-selected .jp-icon-selectable[fill] {
  fill: #fff;
}

.jp-DirListing-item.jp-mod-selected .jp-icon-selectable-inverse[fill] {
  fill: var(--jp-brand-color1);
}

/* stylelint-disable selector-max-class, selector-max-compound-selectors */

/**
* TODO: come up with non css-hack solution for showing the busy icon on top
*  of the close icon
* CSS for complex behavior of close icon of tabs in the main area tabbar
*/
.lm-DockPanel-tabBar
  .lm-TabBar-tab.lm-mod-closable.jp-mod-dirty
  > .lm-TabBar-tabCloseIcon
  > :not(:hover)
  > .jp-icon3[fill] {
  fill: none;
}

.lm-DockPanel-tabBar
  .lm-TabBar-tab.lm-mod-closable.jp-mod-dirty
  > .lm-TabBar-tabCloseIcon
  > :not(:hover)
  > .jp-icon-busy[fill] {
  fill: var(--jp-inverse-layout-color3);
}

/* stylelint-enable selector-max-class, selector-max-compound-selectors */

/* CSS for icons in status bar */
#jp-main-statusbar .jp-mod-selected .jp-icon-selectable[fill] {
  fill: #fff;
}

#jp-main-statusbar .jp-mod-selected .jp-icon-selectable-inverse[fill] {
  fill: var(--jp-brand-color1);
}

/* special handling for splash icon CSS. While the theme CSS reloads during
   splash, the splash icon can loose theming. To prevent that, we set a
   default for its color variable */
:root {
  --jp-warn-color0: var(--md-orange-700);
}

/* not sure what to do with this one, used in filebrowser listing */
.jp-DragIcon {
  margin-right: 4px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/**
 * Support for alt colors for icons as inline SVG HTMLElements
 */

/* alt recolor the primary elements of an icon */
.jp-icon-alt .jp-icon0[fill] {
  fill: var(--jp-layout-color0);
}

.jp-icon-alt .jp-icon1[fill] {
  fill: var(--jp-layout-color1);
}

.jp-icon-alt .jp-icon2[fill] {
  fill: var(--jp-layout-color2);
}

.jp-icon-alt .jp-icon3[fill] {
  fill: var(--jp-layout-color3);
}

.jp-icon-alt .jp-icon4[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-alt .jp-icon0[stroke] {
  stroke: var(--jp-layout-color0);
}

.jp-icon-alt .jp-icon1[stroke] {
  stroke: var(--jp-layout-color1);
}

.jp-icon-alt .jp-icon2[stroke] {
  stroke: var(--jp-layout-color2);
}

.jp-icon-alt .jp-icon3[stroke] {
  stroke: var(--jp-layout-color3);
}

.jp-icon-alt .jp-icon4[stroke] {
  stroke: var(--jp-layout-color4);
}

/* alt recolor the accent elements of an icon */
.jp-icon-alt .jp-icon-accent0[fill] {
  fill: var(--jp-inverse-layout-color0);
}

.jp-icon-alt .jp-icon-accent1[fill] {
  fill: var(--jp-inverse-layout-color1);
}

.jp-icon-alt .jp-icon-accent2[fill] {
  fill: var(--jp-inverse-layout-color2);
}

.jp-icon-alt .jp-icon-accent3[fill] {
  fill: var(--jp-inverse-layout-color3);
}

.jp-icon-alt .jp-icon-accent4[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon-alt .jp-icon-accent0[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}

.jp-icon-alt .jp-icon-accent1[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}

.jp-icon-alt .jp-icon-accent2[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}

.jp-icon-alt .jp-icon-accent3[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}

.jp-icon-alt .jp-icon-accent4[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-icon-hoverShow:not(:hover) .jp-icon-hoverShow-content {
  display: none !important;
}

/**
 * Support for hover colors for icons as inline SVG HTMLElements
 */

/**
 * regular colors
 */

/* recolor the primary elements of an icon */
.jp-icon-hover :hover .jp-icon0-hover[fill] {
  fill: var(--jp-inverse-layout-color0);
}

.jp-icon-hover :hover .jp-icon1-hover[fill] {
  fill: var(--jp-inverse-layout-color1);
}

.jp-icon-hover :hover .jp-icon2-hover[fill] {
  fill: var(--jp-inverse-layout-color2);
}

.jp-icon-hover :hover .jp-icon3-hover[fill] {
  fill: var(--jp-inverse-layout-color3);
}

.jp-icon-hover :hover .jp-icon4-hover[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon-hover :hover .jp-icon0-hover[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}

.jp-icon-hover :hover .jp-icon1-hover[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}

.jp-icon-hover :hover .jp-icon2-hover[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}

.jp-icon-hover :hover .jp-icon3-hover[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}

.jp-icon-hover :hover .jp-icon4-hover[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/* recolor the accent elements of an icon */
.jp-icon-hover :hover .jp-icon-accent0-hover[fill] {
  fill: var(--jp-layout-color0);
}

.jp-icon-hover :hover .jp-icon-accent1-hover[fill] {
  fill: var(--jp-layout-color1);
}

.jp-icon-hover :hover .jp-icon-accent2-hover[fill] {
  fill: var(--jp-layout-color2);
}

.jp-icon-hover :hover .jp-icon-accent3-hover[fill] {
  fill: var(--jp-layout-color3);
}

.jp-icon-hover :hover .jp-icon-accent4-hover[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-hover :hover .jp-icon-accent0-hover[stroke] {
  stroke: var(--jp-layout-color0);
}

.jp-icon-hover :hover .jp-icon-accent1-hover[stroke] {
  stroke: var(--jp-layout-color1);
}

.jp-icon-hover :hover .jp-icon-accent2-hover[stroke] {
  stroke: var(--jp-layout-color2);
}

.jp-icon-hover :hover .jp-icon-accent3-hover[stroke] {
  stroke: var(--jp-layout-color3);
}

.jp-icon-hover :hover .jp-icon-accent4-hover[stroke] {
  stroke: var(--jp-layout-color4);
}

/* set the color of an icon to transparent */
.jp-icon-hover :hover .jp-icon-none-hover[fill] {
  fill: none;
}

.jp-icon-hover :hover .jp-icon-none-hover[stroke] {
  stroke: none;
}

/**
 * inverse colors
 */

/* inverse recolor the primary elements of an icon */
.jp-icon-hover.jp-icon-alt :hover .jp-icon0-hover[fill] {
  fill: var(--jp-layout-color0);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon1-hover[fill] {
  fill: var(--jp-layout-color1);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon2-hover[fill] {
  fill: var(--jp-layout-color2);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon3-hover[fill] {
  fill: var(--jp-layout-color3);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon4-hover[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon0-hover[stroke] {
  stroke: var(--jp-layout-color0);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon1-hover[stroke] {
  stroke: var(--jp-layout-color1);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon2-hover[stroke] {
  stroke: var(--jp-layout-color2);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon3-hover[stroke] {
  stroke: var(--jp-layout-color3);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon4-hover[stroke] {
  stroke: var(--jp-layout-color4);
}

/* inverse recolor the accent elements of an icon */
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent0-hover[fill] {
  fill: var(--jp-inverse-layout-color0);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent1-hover[fill] {
  fill: var(--jp-inverse-layout-color1);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent2-hover[fill] {
  fill: var(--jp-inverse-layout-color2);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent3-hover[fill] {
  fill: var(--jp-inverse-layout-color3);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent4-hover[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent0-hover[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent1-hover[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent2-hover[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent3-hover[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent4-hover[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-IFrame {
  width: 100%;
  height: 100%;
}

.jp-IFrame > iframe {
  border: none;
}

/*
When drag events occur, `lm-mod-override-cursor` is added to the body.
Because iframes steal all cursor events, the following two rules are necessary
to suppress pointer events while resize drags are occurring. There may be a
better solution to this problem.
*/
body.lm-mod-override-cursor .jp-IFrame {
  position: relative;
}

body.lm-mod-override-cursor .jp-IFrame::before {
  content: '';
  position: absolute;
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  background: transparent;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-HoverBox {
  position: fixed;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-FormGroup-content fieldset {
  border: none;
  padding: 0;
  min-width: 0;
  width: 100%;
}

/* stylelint-disable selector-max-type */

.jp-FormGroup-content fieldset .jp-inputFieldWrapper input,
.jp-FormGroup-content fieldset .jp-inputFieldWrapper select,
.jp-FormGroup-content fieldset .jp-inputFieldWrapper textarea {
  font-size: var(--jp-content-font-size2);
  border-color: var(--jp-input-border-color);
  border-style: solid;
  border-radius: var(--jp-border-radius);
  border-width: 1px;
  padding: 6px 8px;
  background: none;
  color: var(--jp-ui-font-color0);
  height: inherit;
}

.jp-FormGroup-content fieldset input[type='checkbox'] {
  position: relative;
  top: 2px;
  margin-left: 0;
}

.jp-FormGroup-content button.jp-mod-styled {
  cursor: pointer;
}

.jp-FormGroup-content .checkbox label {
  cursor: pointer;
  font-size: var(--jp-content-font-size1);
}

.jp-FormGroup-content .jp-root > fieldset > legend {
  display: none;
}

.jp-FormGroup-content .jp-root > fieldset > p {
  display: none;
}

/** copy of `input.jp-mod-styled:focus` style */
.jp-FormGroup-content fieldset input:focus,
.jp-FormGroup-content fieldset select:focus {
  -moz-outline-radius: unset;
  outline: var(--jp-border-width) solid var(--md-blue-500);
  outline-offset: -1px;
  box-shadow: inset 0 0 4px var(--md-blue-300);
}

.jp-FormGroup-content fieldset input:hover:not(:focus),
.jp-FormGroup-content fieldset select:hover:not(:focus) {
  background-color: var(--jp-border-color2);
}

/* stylelint-enable selector-max-type */

.jp-FormGroup-content .checkbox .field-description {
  /* Disable default description field for checkbox:
   because other widgets do not have description fields,
   we add descriptions to each widget on the field level.
  */
  display: none;
}

.jp-FormGroup-content #root__description {
  display: none;
}

.jp-FormGroup-content .jp-modifiedIndicator {
  width: 5px;
  background-color: var(--jp-brand-color2);
  margin-top: 0;
  margin-left: calc(var(--jp-private-settingeditor-modifier-indent) * -1);
  flex-shrink: 0;
}

.jp-FormGroup-content .jp-modifiedIndicator.jp-errorIndicator {
  background-color: var(--jp-error-color0);
  margin-right: 0.5em;
}

/* RJSF ARRAY style */

.jp-arrayFieldWrapper legend {
  font-size: var(--jp-content-font-size2);
  color: var(--jp-ui-font-color0);
  flex-basis: 100%;
  padding: 4px 0;
  font-weight: var(--jp-content-heading-font-weight);
  border-bottom: 1px solid var(--jp-border-color2);
}

.jp-arrayFieldWrapper .field-description {
  padding: 4px 0;
  white-space: pre-wrap;
}

.jp-arrayFieldWrapper .array-item {
  width: 100%;
  border: 1px solid var(--jp-border-color2);
  border-radius: 4px;
  margin: 4px;
}

.jp-ArrayOperations {
  display: flex;
  margin-left: 8px;
}

.jp-ArrayOperationsButton {
  margin: 2px;
}

.jp-ArrayOperationsButton .jp-icon3[fill] {
  fill: var(--jp-ui-font-color0);
}

button.jp-ArrayOperationsButton.jp-mod-styled:disabled {
  cursor: not-allowed;
  opacity: 0.5;
}

/* RJSF form validation error */

.jp-FormGroup-content .validationErrors {
  color: var(--jp-error-color0);
}

/* Hide panel level error as duplicated the field level error */
.jp-FormGroup-content .panel.errors {
  display: none;
}

/* RJSF normal content (settings-editor) */

.jp-FormGroup-contentNormal {
  display: flex;
  align-items: center;
  flex-wrap: wrap;
}

.jp-FormGroup-contentNormal .jp-FormGroup-contentItem {
  margin-left: 7px;
  color: var(--jp-ui-font-color0);
}

.jp-FormGroup-contentNormal .jp-FormGroup-description {
  flex-basis: 100%;
  padding: 4px 7px;
}

.jp-FormGroup-contentNormal .jp-FormGroup-default {
  flex-basis: 100%;
  padding: 4px 7px;
}

.jp-FormGroup-contentNormal .jp-FormGroup-fieldLabel {
  font-size: var(--jp-content-font-size1);
  font-weight: normal;
  min-width: 120px;
}

.jp-FormGroup-contentNormal fieldset:not(:first-child) {
  margin-left: 7px;
}

.jp-FormGroup-contentNormal .field-array-of-string .array-item {
  /* Display `jp-ArrayOperations` buttons side-by-side with content except
    for small screens where flex-wrap will place them one below the other.
  */
  display: flex;
  align-items: center;
  flex-wrap: wrap;
}

.jp-FormGroup-contentNormal .jp-objectFieldWrapper .form-group {
  padding: 2px 8px 2px var(--jp-private-settingeditor-modifier-indent);
  margin-top: 2px;
}

/* RJSF compact content (metadata-form) */

.jp-FormGroup-content.jp-FormGroup-contentCompact {
  width: 100%;
}

.jp-FormGroup-contentCompact .form-group {
  display: flex;
  padding: 0.5em 0.2em 0.5em 0;
}

.jp-FormGroup-contentCompact
  .jp-FormGroup-compactTitle
  .jp-FormGroup-description {
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color2);
}

.jp-FormGroup-contentCompact .jp-FormGroup-fieldLabel {
  padding-bottom: 0.3em;
}

.jp-FormGroup-contentCompact .jp-inputFieldWrapper .form-control {
  width: 100%;
  box-sizing: border-box;
}

.jp-FormGroup-contentCompact .jp-arrayFieldWrapper .jp-FormGroup-compactTitle {
  padding-bottom: 7px;
}

.jp-FormGroup-contentCompact
  .jp-objectFieldWrapper
  .jp-objectFieldWrapper
  .form-group {
  padding: 2px 8px 2px var(--jp-private-settingeditor-modifier-indent);
  margin-top: 2px;
}

.jp-FormGroup-contentCompact ul.error-detail {
  margin-block-start: 0.5em;
  margin-block-end: 0.5em;
  padding-inline-start: 1em;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.jp-SidePanel {
  display: flex;
  flex-direction: column;
  min-width: var(--jp-sidebar-min-width);
  overflow-y: auto;
  color: var(--jp-ui-font-color1);
  background: var(--jp-layout-color1);
  font-size: var(--jp-ui-font-size1);
}

.jp-SidePanel-header {
  flex: 0 0 auto;
  display: flex;
  border-bottom: var(--jp-border-width) solid var(--jp-border-color2);
  font-size: var(--jp-ui-font-size0);
  font-weight: 600;
  letter-spacing: 1px;
  margin: 0;
  padding: 2px;
  text-transform: uppercase;
}

.jp-SidePanel-toolbar {
  flex: 0 0 auto;
}

.jp-SidePanel-content {
  flex: 1 1 auto;
}

.jp-SidePanel-toolbar,
.jp-AccordionPanel-toolbar {
  height: var(--jp-private-toolbar-height);
}

.jp-SidePanel-toolbar.jp-Toolbar-micro {
  display: none;
}

.lm-AccordionPanel .jp-AccordionPanel-title {
  box-sizing: border-box;
  line-height: 25px;
  margin: 0;
  display: flex;
  align-items: center;
  background: var(--jp-layout-color1);
  color: var(--jp-ui-font-color1);
  border-bottom: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  box-shadow: var(--jp-toolbar-box-shadow);
  font-size: var(--jp-ui-font-size0);
}

.jp-AccordionPanel-title {
  cursor: pointer;
  user-select: none;
  -moz-user-select: none;
  -webkit-user-select: none;
  text-transform: uppercase;
}

.lm-AccordionPanel[data-orientation='horizontal'] > .jp-AccordionPanel-title {
  /* Title is rotated for horizontal accordion panel using CSS */
  display: block;
  transform-origin: top left;
  transform: rotate(-90deg) translate(-100%);
}

.jp-AccordionPanel-title .lm-AccordionPanel-titleLabel {
  user-select: none;
  text-overflow: ellipsis;
  white-space: nowrap;
  overflow: hidden;
}

.jp-AccordionPanel-title .lm-AccordionPanel-titleCollapser {
  transform: rotate(-90deg);
  margin: auto 0;
  height: 16px;
}

.jp-AccordionPanel-title.lm-mod-expanded .lm-AccordionPanel-titleCollapser {
  transform: rotate(0deg);
}

.lm-AccordionPanel .jp-AccordionPanel-toolbar {
  background: none;
  box-shadow: none;
  border: none;
  margin-left: auto;
}

.lm-AccordionPanel .lm-SplitPanel-handle:hover {
  background: var(--jp-layout-color3);
}

.jp-text-truncated {
  overflow: hidden;
  text-overflow: ellipsis;
  white-space: nowrap;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Spinner {
  position: absolute;
  display: flex;
  justify-content: center;
  align-items: center;
  z-index: 10;
  left: 0;
  top: 0;
  width: 100%;
  height: 100%;
  background: var(--jp-layout-color0);
  outline: none;
}

.jp-SpinnerContent {
  font-size: 10px;
  margin: 50px auto;
  text-indent: -9999em;
  width: 3em;
  height: 3em;
  border-radius: 50%;
  background: var(--jp-brand-color3);
  background: linear-gradient(
    to right,
    #f37626 10%,
    rgba(255, 255, 255, 0) 42%
  );
  position: relative;
  animation: load3 1s infinite linear, fadeIn 1s;
}

.jp-SpinnerContent::before {
  width: 50%;
  height: 50%;
  background: #f37626;
  border-radius: 100% 0 0;
  position: absolute;
  top: 0;
  left: 0;
  content: '';
}

.jp-SpinnerContent::after {
  background: var(--jp-layout-color0);
  width: 75%;
  height: 75%;
  border-radius: 50%;
  content: '';
  margin: auto;
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  right: 0;
}

@keyframes fadeIn {
  0% {
    opacity: 0;
  }

  100% {
    opacity: 1;
  }
}

@keyframes load3 {
  0% {
    transform: rotate(0deg);
  }

  100% {
    transform: rotate(360deg);
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

button.jp-mod-styled {
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color0);
  border: none;
  box-sizing: border-box;
  text-align: center;
  line-height: 32px;
  height: 32px;
  padding: 0 12px;
  letter-spacing: 0.8px;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
}

input.jp-mod-styled {
  background: var(--jp-input-background);
  height: 28px;
  box-sizing: border-box;
  border: var(--jp-border-width) solid var(--jp-border-color1);
  padding-left: 7px;
  padding-right: 7px;
  font-size: var(--jp-ui-font-size2);
  color: var(--jp-ui-font-color0);
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
}

input[type='checkbox'].jp-mod-styled {
  appearance: checkbox;
  -webkit-appearance: checkbox;
  -moz-appearance: checkbox;
  height: auto;
}

input.jp-mod-styled:focus {
  border: var(--jp-border-width) solid var(--md-blue-500);
  box-shadow: inset 0 0 4px var(--md-blue-300);
}

.jp-select-wrapper {
  display: flex;
  position: relative;
  flex-direction: column;
  padding: 1px;
  background-color: var(--jp-layout-color1);
  box-sizing: border-box;
  margin-bottom: 12px;
}

.jp-select-wrapper:not(.multiple) {
  height: 28px;
}

.jp-select-wrapper.jp-mod-focused select.jp-mod-styled {
  border: var(--jp-border-width) solid var(--jp-input-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
  background-color: var(--jp-input-active-background);
}

select.jp-mod-styled:hover {
  cursor: pointer;
  color: var(--jp-ui-font-color0);
  background-color: var(--jp-input-hover-background);
  box-shadow: inset 0 0 1px rgba(0, 0, 0, 0.5);
}

select.jp-mod-styled {
  flex: 1 1 auto;
  width: 100%;
  font-size: var(--jp-ui-font-size2);
  background: var(--jp-input-background);
  color: var(--jp-ui-font-color0);
  padding: 0 25px 0 8px;
  border: var(--jp-border-width) solid var(--jp-input-border-color);
  border-radius: 0;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
}

select.jp-mod-styled:not([multiple]) {
  height: 32px;
}

select.jp-mod-styled[multiple] {
  max-height: 200px;
  overflow-y: auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-switch {
  display: flex;
  align-items: center;
  padding-left: 4px;
  padding-right: 4px;
  font-size: var(--jp-ui-font-size1);
  background-color: transparent;
  color: var(--jp-ui-font-color1);
  border: none;
  height: 20px;
}

.jp-switch:hover {
  background-color: var(--jp-layout-color2);
}

.jp-switch-label {
  margin-right: 5px;
  font-family: var(--jp-ui-font-family);
}

.jp-switch-track {
  cursor: pointer;
  background-color: var(--jp-switch-color, var(--jp-border-color1));
  -webkit-transition: 0.4s;
  transition: 0.4s;
  border-radius: 34px;
  height: 16px;
  width: 35px;
  position: relative;
}

.jp-switch-track::before {
  content: '';
  position: absolute;
  height: 10px;
  width: 10px;
  margin: 3px;
  left: 0;
  background-color: var(--jp-ui-inverse-font-color1);
  -webkit-transition: 0.4s;
  transition: 0.4s;
  border-radius: 50%;
}

.jp-switch[aria-checked='true'] .jp-switch-track {
  background-color: var(--jp-switch-true-position-color, var(--jp-warn-color0));
}

.jp-switch[aria-checked='true'] .jp-switch-track::before {
  /* track width (35) - margins (3 + 3) - thumb width (10) */
  left: 19px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

:root {
  --jp-private-toolbar-height: calc(
    28px + var(--jp-border-width)
  ); /* leave 28px for content */
}

.jp-Toolbar {
  color: var(--jp-ui-font-color1);
  flex: 0 0 auto;
  display: flex;
  flex-direction: row;
  border-bottom: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  box-shadow: var(--jp-toolbar-box-shadow);
  background: var(--jp-toolbar-background);
  min-height: var(--jp-toolbar-micro-height);
  padding: 2px;
  z-index: 8;
  overflow-x: hidden;
}

/* Toolbar items */

.jp-Toolbar > .jp-Toolbar-item.jp-Toolbar-spacer {
  flex-grow: 1;
  flex-shrink: 1;
}

.jp-Toolbar-item.jp-Toolbar-kernelStatus {
  display: inline-block;
  width: 32px;
  background-repeat: no-repeat;
  background-position: center;
  background-size: 16px;
}

.jp-Toolbar > .jp-Toolbar-item {
  flex: 0 0 auto;
  display: flex;
  padding-left: 1px;
  padding-right: 1px;
  font-size: var(--jp-ui-font-size1);
  line-height: var(--jp-private-toolbar-height);
  height: 100%;
}

/* Toolbar buttons */

/* This is the div we use to wrap the react component into a Widget */
div.jp-ToolbarButton {
  color: transparent;
  border: none;
  box-sizing: border-box;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
  padding: 0;
  margin: 0;
}

button.jp-ToolbarButtonComponent {
  background: var(--jp-layout-color1);
  border: none;
  box-sizing: border-box;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
  padding: 0 6px;
  margin: 0;
  height: 24px;
  border-radius: var(--jp-border-radius);
  display: flex;
  align-items: center;
  text-align: center;
  font-size: 14px;
  min-width: unset;
  min-height: unset;
}

button.jp-ToolbarButtonComponent:disabled {
  opacity: 0.4;
}

button.jp-ToolbarButtonComponent > span {
  padding: 0;
  flex: 0 0 auto;
}

button.jp-ToolbarButtonComponent .jp-ToolbarButtonComponent-label {
  font-size: var(--jp-ui-font-size1);
  line-height: 100%;
  padding-left: 2px;
  color: var(--jp-ui-font-color1);
  font-family: var(--jp-ui-font-family);
}

#jp-main-dock-panel[data-mode='single-document']
  .jp-MainAreaWidget
  > .jp-Toolbar.jp-Toolbar-micro {
  padding: 0;
  min-height: 0;
}

#jp-main-dock-panel[data-mode='single-document']
  .jp-MainAreaWidget
  > .jp-Toolbar {
  border: none;
  box-shadow: none;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.jp-WindowedPanel-outer {
  position: relative;
  overflow-y: auto;
}

.jp-WindowedPanel-inner {
  position: relative;
}

.jp-WindowedPanel-window {
  position: absolute;
  left: 0;
  right: 0;
  overflow: visible;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* Sibling imports */

body {
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
}

/* Disable native link decoration styles everywhere outside of dialog boxes */
a {
  text-decoration: unset;
  color: unset;
}

a:hover {
  text-decoration: unset;
  color: unset;
}

/* Accessibility for links inside dialog box text */
.jp-Dialog-content a {
  text-decoration: revert;
  color: var(--jp-content-link-color);
}

.jp-Dialog-content a:hover {
  text-decoration: revert;
}

/* Styles for ui-components */
.jp-Button {
  color: var(--jp-ui-font-color2);
  border-radius: var(--jp-border-radius);
  padding: 0 12px;
  font-size: var(--jp-ui-font-size1);

  /* Copy from blueprint 3 */
  display: inline-flex;
  flex-direction: row;
  border: none;
  cursor: pointer;
  align-items: center;
  justify-content: center;
  text-align: left;
  vertical-align: middle;
  min-height: 30px;
  min-width: 30px;
}

.jp-Button:disabled {
  cursor: not-allowed;
}

.jp-Button:empty {
  padding: 0 !important;
}

.jp-Button.jp-mod-small {
  min-height: 24px;
  min-width: 24px;
  font-size: 12px;
  padding: 0 7px;
}

/* Use our own theme for hover styles */
.jp-Button.jp-mod-minimal:hover {
  background-color: var(--jp-layout-color2);
}

.jp-Button.jp-mod-minimal {
  background: none;
}

.jp-InputGroup {
  display: block;
  position: relative;
}

.jp-InputGroup input {
  box-sizing: border-box;
  border: none;
  border-radius: 0;
  background-color: transparent;
  color: var(--jp-ui-font-color0);
  box-shadow: inset 0 0 0 var(--jp-border-width) var(--jp-input-border-color);
  padding-bottom: 0;
  padding-top: 0;
  padding-left: 10px;
  padding-right: 28px;
  position: relative;
  width: 100%;
  -webkit-appearance: none;
  -moz-appearance: none;
  appearance: none;
  font-size: 14px;
  font-weight: 400;
  height: 30px;
  line-height: 30px;
  outline: none;
  vertical-align: middle;
}

.jp-InputGroup input:focus {
  box-shadow: inset 0 0 0 var(--jp-border-width)
      var(--jp-input-active-box-shadow-color),
    inset 0 0 0 3px var(--jp-input-active-box-shadow-color);
}

.jp-InputGroup input:disabled {
  cursor: not-allowed;
  resize: block;
  background-color: var(--jp-layout-color2);
  color: var(--jp-ui-font-color2);
}

.jp-InputGroup input:disabled ~ span {
  cursor: not-allowed;
  color: var(--jp-ui-font-color2);
}

.jp-InputGroup input::placeholder,
input::placeholder {
  color: var(--jp-ui-font-color2);
}

.jp-InputGroupAction {
  position: absolute;
  bottom: 1px;
  right: 0;
  padding: 6px;
}

.jp-HTMLSelect.jp-DefaultStyle select {
  background-color: initial;
  border: none;
  border-radius: 0;
  box-shadow: none;
  color: var(--jp-ui-font-color0);
  display: block;
  font-size: var(--jp-ui-font-size1);
  font-family: var(--jp-ui-font-family);
  height: 24px;
  line-height: 14px;
  padding: 0 25px 0 10px;
  text-align: left;
  -moz-appearance: none;
  -webkit-appearance: none;
}

.jp-HTMLSelect.jp-DefaultStyle select:disabled {
  background-color: var(--jp-layout-color2);
  color: var(--jp-ui-font-color2);
  cursor: not-allowed;
  resize: block;
}

.jp-HTMLSelect.jp-DefaultStyle select:disabled ~ span {
  cursor: not-allowed;
}

/* Use our own theme for hover and option styles */
/* stylelint-disable-next-line selector-max-type */
.jp-HTMLSelect.jp-DefaultStyle select:hover,
.jp-HTMLSelect.jp-DefaultStyle select > option {
  background-color: var(--jp-layout-color2);
  color: var(--jp-ui-font-color0);
}

select {
  box-sizing: border-box;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Styles
|----------------------------------------------------------------------------*/

.jp-StatusBar-Widget {
  display: flex;
  align-items: center;
  background: var(--jp-layout-color2);
  min-height: var(--jp-statusbar-height);
  justify-content: space-between;
  padding: 0 10px;
}

.jp-StatusBar-Left {
  display: flex;
  align-items: center;
  flex-direction: row;
}

.jp-StatusBar-Middle {
  display: flex;
  align-items: center;
}

.jp-StatusBar-Right {
  display: flex;
  align-items: center;
  flex-direction: row-reverse;
}

.jp-StatusBar-Item {
  max-height: var(--jp-statusbar-height);
  margin: 0 2px;
  height: var(--jp-statusbar-height);
  white-space: nowrap;
  text-overflow: ellipsis;
  color: var(--jp-ui-font-color1);
  padding: 0 6px;
}

.jp-mod-highlighted:hover {
  background-color: var(--jp-layout-color3);
}

.jp-mod-clicked {
  background-color: var(--jp-brand-color1);
}

.jp-mod-clicked:hover {
  background-color: var(--jp-brand-color0);
}

.jp-mod-clicked .jp-StatusBar-TextItem {
  color: var(--jp-ui-inverse-font-color1);
}

.jp-StatusBar-HoverItem {
  box-shadow: '0px 4px 4px rgba(0, 0, 0, 0.25)';
}

.jp-StatusBar-TextItem {
  font-size: var(--jp-ui-font-size1);
  font-family: var(--jp-ui-font-family);
  line-height: 24px;
  color: var(--jp-ui-font-color1);
}

.jp-StatusBar-GroupItem {
  display: flex;
  align-items: center;
  flex-direction: row;
}

.jp-Statusbar-ProgressCircle svg {
  display: block;
  margin: 0 auto;
  width: 16px;
  height: 24px;
  align-self: normal;
}

.jp-Statusbar-ProgressCircle path {
  fill: var(--jp-inverse-layout-color3);
}

.jp-Statusbar-ProgressBar-progress-bar {
  height: 10px;
  width: 100px;
  border: solid 0.25px var(--jp-brand-color2);
  border-radius: 3px;
  overflow: hidden;
  align-self: center;
}

.jp-Statusbar-ProgressBar-progress-bar > div {
  background-color: var(--jp-brand-color2);
  background-image: linear-gradient(
    -45deg,
    rgba(255, 255, 255, 0.2) 25%,
    transparent 25%,
    transparent 50%,
    rgba(255, 255, 255, 0.2) 50%,
    rgba(255, 255, 255, 0.2) 75%,
    transparent 75%,
    transparent
  );
  background-size: 40px 40px;
  float: left;
  width: 0%;
  height: 100%;
  font-size: 12px;
  line-height: 14px;
  color: #fff;
  text-align: center;
  animation: jp-Statusbar-ExecutionTime-progress-bar 2s linear infinite;
}

.jp-Statusbar-ProgressBar-progress-bar p {
  color: var(--jp-ui-font-color1);
  font-family: var(--jp-ui-font-family);
  font-size: var(--jp-ui-font-size1);
  line-height: 10px;
  width: 100px;
}

@keyframes jp-Statusbar-ExecutionTime-progress-bar {
  0% {
    background-position: 0 0;
  }

  100% {
    background-position: 40px 40px;
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

:root {
  --jp-private-commandpalette-search-height: 28px;
}

/*-----------------------------------------------------------------------------
| Overall styles
|----------------------------------------------------------------------------*/

.lm-CommandPalette {
  padding-bottom: 0;
  color: var(--jp-ui-font-color1);
  background: var(--jp-layout-color1);

  /* This is needed so that all font sizing of children done in ems is
   * relative to this base size */
  font-size: var(--jp-ui-font-size1);
}

/*-----------------------------------------------------------------------------
| Modal variant
|----------------------------------------------------------------------------*/

.jp-ModalCommandPalette {
  position: absolute;
  z-index: 10000;
  top: 38px;
  left: 30%;
  margin: 0;
  padding: 4px;
  width: 40%;
  box-shadow: var(--jp-elevation-z4);
  border-radius: 4px;
  background: var(--jp-layout-color0);
}

.jp-ModalCommandPalette .lm-CommandPalette {
  max-height: 40vh;
}

.jp-ModalCommandPalette .lm-CommandPalette .lm-close-icon::after {
  display: none;
}

.jp-ModalCommandPalette .lm-CommandPalette .lm-CommandPalette-header {
  display: none;
}

.jp-ModalCommandPalette .lm-CommandPalette .lm-CommandPalette-item {
  margin-left: 4px;
  margin-right: 4px;
}

.jp-ModalCommandPalette
  .lm-CommandPalette
  .lm-CommandPalette-item.lm-mod-disabled {
  display: none;
}

/*-----------------------------------------------------------------------------
| Search
|----------------------------------------------------------------------------*/

.lm-CommandPalette-search {
  padding: 4px;
  background-color: var(--jp-layout-color1);
  z-index: 2;
}

.lm-CommandPalette-wrapper {
  overflow: overlay;
  padding: 0 9px;
  background-color: var(--jp-input-active-background);
  height: 30px;
  box-shadow: inset 0 0 0 var(--jp-border-width) var(--jp-input-border-color);
}

.lm-CommandPalette.lm-mod-focused .lm-CommandPalette-wrapper {
  box-shadow: inset 0 0 0 1px var(--jp-input-active-box-shadow-color),
    inset 0 0 0 3px var(--jp-input-active-box-shadow-color);
}

.jp-SearchIconGroup {
  color: white;
  background-color: var(--jp-brand-color1);
  position: absolute;
  top: 4px;
  right: 4px;
  padding: 5px 5px 1px;
}

.jp-SearchIconGroup svg {
  height: 20px;
  width: 20px;
}

.jp-SearchIconGroup .jp-icon3[fill] {
  fill: var(--jp-layout-color0);
}

.lm-CommandPalette-input {
  background: transparent;
  width: calc(100% - 18px);
  float: left;
  border: none;
  outline: none;
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color0);
  line-height: var(--jp-private-commandpalette-search-height);
}

.lm-CommandPalette-input::-webkit-input-placeholder,
.lm-CommandPalette-input::-moz-placeholder,
.lm-CommandPalette-input:-ms-input-placeholder {
  color: var(--jp-ui-font-color2);
  font-size: var(--jp-ui-font-size1);
}

/*-----------------------------------------------------------------------------
| Results
|----------------------------------------------------------------------------*/

.lm-CommandPalette-header:first-child {
  margin-top: 0;
}

.lm-CommandPalette-header {
  border-bottom: solid var(--jp-border-width) var(--jp-border-color2);
  color: var(--jp-ui-font-color1);
  cursor: pointer;
  display: flex;
  font-size: var(--jp-ui-font-size0);
  font-weight: 600;
  letter-spacing: 1px;
  margin-top: 8px;
  padding: 8px 0 8px 12px;
  text-transform: uppercase;
}

.lm-CommandPalette-header.lm-mod-active {
  background: var(--jp-layout-color2);
}

.lm-CommandPalette-header > mark {
  background-color: transparent;
  font-weight: bold;
  color: var(--jp-ui-font-color1);
}

.lm-CommandPalette-item {
  padding: 4px 12px 4px 4px;
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
  font-weight: 400;
  display: flex;
}

.lm-CommandPalette-item.lm-mod-disabled {
  color: var(--jp-ui-font-color2);
}

.lm-CommandPalette-item.lm-mod-active {
  color: var(--jp-ui-inverse-font-color1);
  background: var(--jp-brand-color1);
}

.lm-CommandPalette-item.lm-mod-active .lm-CommandPalette-itemLabel > mark {
  color: var(--jp-ui-inverse-font-color0);
}

.lm-CommandPalette-item.lm-mod-active .jp-icon-selectable[fill] {
  fill: var(--jp-layout-color0);
}

.lm-CommandPalette-item.lm-mod-active:hover:not(.lm-mod-disabled) {
  color: var(--jp-ui-inverse-font-color1);
  background: var(--jp-brand-color1);
}

.lm-CommandPalette-item:hover:not(.lm-mod-active):not(.lm-mod-disabled) {
  background: var(--jp-layout-color2);
}

.lm-CommandPalette-itemContent {
  overflow: hidden;
}

.lm-CommandPalette-itemLabel > mark {
  color: var(--jp-ui-font-color0);
  background-color: transparent;
  font-weight: bold;
}

.lm-CommandPalette-item.lm-mod-disabled mark {
  color: var(--jp-ui-font-color2);
}

.lm-CommandPalette-item .lm-CommandPalette-itemIcon {
  margin: 0 4px 0 0;
  position: relative;
  width: 16px;
  top: 2px;
  flex: 0 0 auto;
}

.lm-CommandPalette-item.lm-mod-disabled .lm-CommandPalette-itemIcon {
  opacity: 0.6;
}

.lm-CommandPalette-item .lm-CommandPalette-itemShortcut {
  flex: 0 0 auto;
}

.lm-CommandPalette-itemCaption {
  display: none;
}

.lm-CommandPalette-content {
  background-color: var(--jp-layout-color1);
}

.lm-CommandPalette-content:empty::after {
  content: 'No results';
  margin: auto;
  margin-top: 20px;
  width: 100px;
  display: block;
  font-size: var(--jp-ui-font-size2);
  font-family: var(--jp-ui-font-family);
  font-weight: lighter;
}

.lm-CommandPalette-emptyMessage {
  text-align: center;
  margin-top: 24px;
  line-height: 1.32;
  padding: 0 8px;
  color: var(--jp-content-font-color3);
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Dialog {
  position: absolute;
  z-index: 10000;
  display: flex;
  flex-direction: column;
  align-items: center;
  justify-content: center;
  top: 0;
  left: 0;
  margin: 0;
  padding: 0;
  width: 100%;
  height: 100%;
  background: var(--jp-dialog-background);
}

.jp-Dialog-content {
  display: flex;
  flex-direction: column;
  margin-left: auto;
  margin-right: auto;
  background: var(--jp-layout-color1);
  padding: 24px 24px 12px;
  min-width: 300px;
  min-height: 150px;
  max-width: 1000px;
  max-height: 500px;
  box-sizing: border-box;
  box-shadow: var(--jp-elevation-z20);
  word-wrap: break-word;
  border-radius: var(--jp-border-radius);

  /* This is needed so that all font sizing of children done in ems is
   * relative to this base size */
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color1);
  resize: both;
}

.jp-Dialog-content.jp-Dialog-content-small {
  max-width: 500px;
}

.jp-Dialog-button {
  overflow: visible;
}

button.jp-Dialog-button:focus {
  outline: 1px solid var(--jp-brand-color1);
  outline-offset: 4px;
  -moz-outline-radius: 0;
}

button.jp-Dialog-button:focus::-moz-focus-inner {
  border: 0;
}

button.jp-Dialog-button.jp-mod-styled.jp-mod-accept:focus,
button.jp-Dialog-button.jp-mod-styled.jp-mod-warn:focus,
button.jp-Dialog-button.jp-mod-styled.jp-mod-reject:focus {
  outline-offset: 4px;
  -moz-outline-radius: 0;
}

button.jp-Dialog-button.jp-mod-styled.jp-mod-accept:focus {
  outline: 1px solid var(--jp-accept-color-normal, var(--jp-brand-color1));
}

button.jp-Dialog-button.jp-mod-styled.jp-mod-warn:focus {
  outline: 1px solid var(--jp-warn-color-normal, var(--jp-error-color1));
}

button.jp-Dialog-button.jp-mod-styled.jp-mod-reject:focus {
  outline: 1px solid var(--jp-reject-color-normal, var(--md-grey-600));
}

button.jp-Dialog-close-button {
  padding: 0;
  height: 100%;
  min-width: unset;
  min-height: unset;
}

.jp-Dialog-header {
  display: flex;
  justify-content: space-between;
  flex: 0 0 auto;
  padding-bottom: 12px;
  font-size: var(--jp-ui-font-size3);
  font-weight: 400;
  color: var(--jp-ui-font-color1);
}

.jp-Dialog-body {
  display: flex;
  flex-direction: column;
  flex: 1 1 auto;
  font-size: var(--jp-ui-font-size1);
  background: var(--jp-layout-color1);
  color: var(--jp-ui-font-color1);
  overflow: auto;
}

.jp-Dialog-footer {
  display: flex;
  flex-direction: row;
  justify-content: flex-end;
  align-items: center;
  flex: 0 0 auto;
  margin-left: -12px;
  margin-right: -12px;
  padding: 12px;
}

.jp-Dialog-checkbox {
  padding-right: 5px;
}

.jp-Dialog-checkbox > input:focus-visible {
  outline: 1px solid var(--jp-input-active-border-color);
  outline-offset: 1px;
}

.jp-Dialog-spacer {
  flex: 1 1 auto;
}

.jp-Dialog-title {
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}

.jp-Dialog-body > .jp-select-wrapper {
  width: 100%;
}

.jp-Dialog-body > button {
  padding: 0 16px;
}

.jp-Dialog-body > label {
  line-height: 1.4;
  color: var(--jp-ui-font-color0);
}

.jp-Dialog-button.jp-mod-styled:not(:last-child) {
  margin-right: 12px;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.jp-Input-Boolean-Dialog {
  flex-direction: row-reverse;
  align-items: end;
  width: 100%;
}

.jp-Input-Boolean-Dialog > label {
  flex: 1 1 auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-MainAreaWidget > :focus {
  outline: none;
}

.jp-MainAreaWidget .jp-MainAreaWidget-error {
  padding: 6px;
}

.jp-MainAreaWidget .jp-MainAreaWidget-error > pre {
  width: auto;
  padding: 10px;
  background: var(--jp-error-color3);
  border: var(--jp-border-width) solid var(--jp-error-color1);
  border-radius: var(--jp-border-radius);
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
  white-space: pre-wrap;
  word-wrap: break-word;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/**
 * google-material-color v1.2.6
 * https://github.com/danlevan/google-material-color
 */
:root {
  --md-red-50: #ffebee;
  --md-red-100: #ffcdd2;
  --md-red-200: #ef9a9a;
  --md-red-300: #e57373;
  --md-red-400: #ef5350;
  --md-red-500: #f44336;
  --md-red-600: #e53935;
  --md-red-700: #d32f2f;
  --md-red-800: #c62828;
  --md-red-900: #b71c1c;
  --md-red-A100: #ff8a80;
  --md-red-A200: #ff5252;
  --md-red-A400: #ff1744;
  --md-red-A700: #d50000;
  --md-pink-50: #fce4ec;
  --md-pink-100: #f8bbd0;
  --md-pink-200: #f48fb1;
  --md-pink-300: #f06292;
  --md-pink-400: #ec407a;
  --md-pink-500: #e91e63;
  --md-pink-600: #d81b60;
  --md-pink-700: #c2185b;
  --md-pink-800: #ad1457;
  --md-pink-900: #880e4f;
  --md-pink-A100: #ff80ab;
  --md-pink-A200: #ff4081;
  --md-pink-A400: #f50057;
  --md-pink-A700: #c51162;
  --md-purple-50: #f3e5f5;
  --md-purple-100: #e1bee7;
  --md-purple-200: #ce93d8;
  --md-purple-300: #ba68c8;
  --md-purple-400: #ab47bc;
  --md-purple-500: #9c27b0;
  --md-purple-600: #8e24aa;
  --md-purple-700: #7b1fa2;
  --md-purple-800: #6a1b9a;
  --md-purple-900: #4a148c;
  --md-purple-A100: #ea80fc;
  --md-purple-A200: #e040fb;
  --md-purple-A400: #d500f9;
  --md-purple-A700: #a0f;
  --md-deep-purple-50: #ede7f6;
  --md-deep-purple-100: #d1c4e9;
  --md-deep-purple-200: #b39ddb;
  --md-deep-purple-300: #9575cd;
  --md-deep-purple-400: #7e57c2;
  --md-deep-purple-500: #673ab7;
  --md-deep-purple-600: #5e35b1;
  --md-deep-purple-700: #512da8;
  --md-deep-purple-800: #4527a0;
  --md-deep-purple-900: #311b92;
  --md-deep-purple-A100: #b388ff;
  --md-deep-purple-A200: #7c4dff;
  --md-deep-purple-A400: #651fff;
  --md-deep-purple-A700: #6200ea;
  --md-indigo-50: #e8eaf6;
  --md-indigo-100: #c5cae9;
  --md-indigo-200: #9fa8da;
  --md-indigo-300: #7986cb;
  --md-indigo-400: #5c6bc0;
  --md-indigo-500: #3f51b5;
  --md-indigo-600: #3949ab;
  --md-indigo-700: #303f9f;
  --md-indigo-800: #283593;
  --md-indigo-900: #1a237e;
  --md-indigo-A100: #8c9eff;
  --md-indigo-A200: #536dfe;
  --md-indigo-A400: #3d5afe;
  --md-indigo-A700: #304ffe;
  --md-blue-50: #e3f2fd;
  --md-blue-100: #bbdefb;
  --md-blue-200: #90caf9;
  --md-blue-300: #64b5f6;
  --md-blue-400: #42a5f5;
  --md-blue-500: #2196f3;
  --md-blue-600: #1e88e5;
  --md-blue-700: #1976d2;
  --md-blue-800: #1565c0;
  --md-blue-900: #0d47a1;
  --md-blue-A100: #82b1ff;
  --md-blue-A200: #448aff;
  --md-blue-A400: #2979ff;
  --md-blue-A700: #2962ff;
  --md-light-blue-50: #e1f5fe;
  --md-light-blue-100: #b3e5fc;
  --md-light-blue-200: #81d4fa;
  --md-light-blue-300: #4fc3f7;
  --md-light-blue-400: #29b6f6;
  --md-light-blue-500: #03a9f4;
  --md-light-blue-600: #039be5;
  --md-light-blue-700: #0288d1;
  --md-light-blue-800: #0277bd;
  --md-light-blue-900: #01579b;
  --md-light-blue-A100: #80d8ff;
  --md-light-blue-A200: #40c4ff;
  --md-light-blue-A400: #00b0ff;
  --md-light-blue-A700: #0091ea;
  --md-cyan-50: #e0f7fa;
  --md-cyan-100: #b2ebf2;
  --md-cyan-200: #80deea;
  --md-cyan-300: #4dd0e1;
  --md-cyan-400: #26c6da;
  --md-cyan-500: #00bcd4;
  --md-cyan-600: #00acc1;
  --md-cyan-700: #0097a7;
  --md-cyan-800: #00838f;
  --md-cyan-900: #006064;
  --md-cyan-A100: #84ffff;
  --md-cyan-A200: #18ffff;
  --md-cyan-A400: #00e5ff;
  --md-cyan-A700: #00b8d4;
  --md-teal-50: #e0f2f1;
  --md-teal-100: #b2dfdb;
  --md-teal-200: #80cbc4;
  --md-teal-300: #4db6ac;
  --md-teal-400: #26a69a;
  --md-teal-500: #009688;
  --md-teal-600: #00897b;
  --md-teal-700: #00796b;
  --md-teal-800: #00695c;
  --md-teal-900: #004d40;
  --md-teal-A100: #a7ffeb;
  --md-teal-A200: #64ffda;
  --md-teal-A400: #1de9b6;
  --md-teal-A700: #00bfa5;
  --md-green-50: #e8f5e9;
  --md-green-100: #c8e6c9;
  --md-green-200: #a5d6a7;
  --md-green-300: #81c784;
  --md-green-400: #66bb6a;
  --md-green-500: #4caf50;
  --md-green-600: #43a047;
  --md-green-700: #388e3c;
  --md-green-800: #2e7d32;
  --md-green-900: #1b5e20;
  --md-green-A100: #b9f6ca;
  --md-green-A200: #69f0ae;
  --md-green-A400: #00e676;
  --md-green-A700: #00c853;
  --md-light-green-50: #f1f8e9;
  --md-light-green-100: #dcedc8;
  --md-light-green-200: #c5e1a5;
  --md-light-green-300: #aed581;
  --md-light-green-400: #9ccc65;
  --md-light-green-500: #8bc34a;
  --md-light-green-600: #7cb342;
  --md-light-green-700: #689f38;
  --md-light-green-800: #558b2f;
  --md-light-green-900: #33691e;
  --md-light-green-A100: #ccff90;
  --md-light-green-A200: #b2ff59;
  --md-light-green-A400: #76ff03;
  --md-light-green-A700: #64dd17;
  --md-lime-50: #f9fbe7;
  --md-lime-100: #f0f4c3;
  --md-lime-200: #e6ee9c;
  --md-lime-300: #dce775;
  --md-lime-400: #d4e157;
  --md-lime-500: #cddc39;
  --md-lime-600: #c0ca33;
  --md-lime-700: #afb42b;
  --md-lime-800: #9e9d24;
  --md-lime-900: #827717;
  --md-lime-A100: #f4ff81;
  --md-lime-A200: #eeff41;
  --md-lime-A400: #c6ff00;
  --md-lime-A700: #aeea00;
  --md-yellow-50: #fffde7;
  --md-yellow-100: #fff9c4;
  --md-yellow-200: #fff59d;
  --md-yellow-300: #fff176;
  --md-yellow-400: #ffee58;
  --md-yellow-500: #ffeb3b;
  --md-yellow-600: #fdd835;
  --md-yellow-700: #fbc02d;
  --md-yellow-800: #f9a825;
  --md-yellow-900: #f57f17;
  --md-yellow-A100: #ffff8d;
  --md-yellow-A200: #ff0;
  --md-yellow-A400: #ffea00;
  --md-yellow-A700: #ffd600;
  --md-amber-50: #fff8e1;
  --md-amber-100: #ffecb3;
  --md-amber-200: #ffe082;
  --md-amber-300: #ffd54f;
  --md-amber-400: #ffca28;
  --md-amber-500: #ffc107;
  --md-amber-600: #ffb300;
  --md-amber-700: #ffa000;
  --md-amber-800: #ff8f00;
  --md-amber-900: #ff6f00;
  --md-amber-A100: #ffe57f;
  --md-amber-A200: #ffd740;
  --md-amber-A400: #ffc400;
  --md-amber-A700: #ffab00;
  --md-orange-50: #fff3e0;
  --md-orange-100: #ffe0b2;
  --md-orange-200: #ffcc80;
  --md-orange-300: #ffb74d;
  --md-orange-400: #ffa726;
  --md-orange-500: #ff9800;
  --md-orange-600: #fb8c00;
  --md-orange-700: #f57c00;
  --md-orange-800: #ef6c00;
  --md-orange-900: #e65100;
  --md-orange-A100: #ffd180;
  --md-orange-A200: #ffab40;
  --md-orange-A400: #ff9100;
  --md-orange-A700: #ff6d00;
  --md-deep-orange-50: #fbe9e7;
  --md-deep-orange-100: #ffccbc;
  --md-deep-orange-200: #ffab91;
  --md-deep-orange-300: #ff8a65;
  --md-deep-orange-400: #ff7043;
  --md-deep-orange-500: #ff5722;
  --md-deep-orange-600: #f4511e;
  --md-deep-orange-700: #e64a19;
  --md-deep-orange-800: #d84315;
  --md-deep-orange-900: #bf360c;
  --md-deep-orange-A100: #ff9e80;
  --md-deep-orange-A200: #ff6e40;
  --md-deep-orange-A400: #ff3d00;
  --md-deep-orange-A700: #dd2c00;
  --md-brown-50: #efebe9;
  --md-brown-100: #d7ccc8;
  --md-brown-200: #bcaaa4;
  --md-brown-300: #a1887f;
  --md-brown-400: #8d6e63;
  --md-brown-500: #795548;
  --md-brown-600: #6d4c41;
  --md-brown-700: #5d4037;
  --md-brown-800: #4e342e;
  --md-brown-900: #3e2723;
  --md-grey-50: #fafafa;
  --md-grey-100: #f5f5f5;
  --md-grey-200: #eee;
  --md-grey-300: #e0e0e0;
  --md-grey-400: #bdbdbd;
  --md-grey-500: #9e9e9e;
  --md-grey-600: #757575;
  --md-grey-700: #616161;
  --md-grey-800: #424242;
  --md-grey-900: #212121;
  --md-blue-grey-50: #eceff1;
  --md-blue-grey-100: #cfd8dc;
  --md-blue-grey-200: #b0bec5;
  --md-blue-grey-300: #90a4ae;
  --md-blue-grey-400: #78909c;
  --md-blue-grey-500: #607d8b;
  --md-blue-grey-600: #546e7a;
  --md-blue-grey-700: #455a64;
  --md-blue-grey-800: #37474f;
  --md-blue-grey-900: #263238;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| RenderedText
|----------------------------------------------------------------------------*/

:root {
  /* This is the padding value to fill the gaps between lines containing spans with background color. */
  --jp-private-code-span-padding: calc(
    (var(--jp-code-line-height) - 1) * var(--jp-code-font-size) / 2
  );
}

.jp-RenderedText {
  text-align: left;
  padding-left: var(--jp-code-padding);
  line-height: var(--jp-code-line-height);
  font-family: var(--jp-code-font-family);
}

.jp-RenderedText pre,
.jp-RenderedJavaScript pre,
.jp-RenderedHTMLCommon pre {
  color: var(--jp-content-font-color1);
  font-size: var(--jp-code-font-size);
  border: none;
  margin: 0;
  padding: 0;
}

.jp-RenderedText pre a:link {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

.jp-RenderedText pre a:hover {
  text-decoration: underline;
  color: var(--jp-content-link-color);
}

.jp-RenderedText pre a:visited {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

/* console foregrounds and backgrounds */
.jp-RenderedText pre .ansi-black-fg {
  color: #3e424d;
}

.jp-RenderedText pre .ansi-red-fg {
  color: #e75c58;
}

.jp-RenderedText pre .ansi-green-fg {
  color: #00a250;
}

.jp-RenderedText pre .ansi-yellow-fg {
  color: #ddb62b;
}

.jp-RenderedText pre .ansi-blue-fg {
  color: #208ffb;
}

.jp-RenderedText pre .ansi-magenta-fg {
  color: #d160c4;
}

.jp-RenderedText pre .ansi-cyan-fg {
  color: #60c6c8;
}

.jp-RenderedText pre .ansi-white-fg {
  color: #c5c1b4;
}

.jp-RenderedText pre .ansi-black-bg {
  background-color: #3e424d;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-red-bg {
  background-color: #e75c58;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-green-bg {
  background-color: #00a250;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-yellow-bg {
  background-color: #ddb62b;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-blue-bg {
  background-color: #208ffb;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-magenta-bg {
  background-color: #d160c4;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-cyan-bg {
  background-color: #60c6c8;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-white-bg {
  background-color: #c5c1b4;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-black-intense-fg {
  color: #282c36;
}

.jp-RenderedText pre .ansi-red-intense-fg {
  color: #b22b31;
}

.jp-RenderedText pre .ansi-green-intense-fg {
  color: #007427;
}

.jp-RenderedText pre .ansi-yellow-intense-fg {
  color: #b27d12;
}

.jp-RenderedText pre .ansi-blue-intense-fg {
  color: #0065ca;
}

.jp-RenderedText pre .ansi-magenta-intense-fg {
  color: #a03196;
}

.jp-RenderedText pre .ansi-cyan-intense-fg {
  color: #258f8f;
}

.jp-RenderedText pre .ansi-white-intense-fg {
  color: #a1a6b2;
}

.jp-RenderedText pre .ansi-black-intense-bg {
  background-color: #282c36;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-red-intense-bg {
  background-color: #b22b31;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-green-intense-bg {
  background-color: #007427;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-yellow-intense-bg {
  background-color: #b27d12;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-blue-intense-bg {
  background-color: #0065ca;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-magenta-intense-bg {
  background-color: #a03196;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-cyan-intense-bg {
  background-color: #258f8f;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-white-intense-bg {
  background-color: #a1a6b2;
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-default-inverse-fg {
  color: var(--jp-ui-inverse-font-color0);
}

.jp-RenderedText pre .ansi-default-inverse-bg {
  background-color: var(--jp-inverse-layout-color0);
  padding: var(--jp-private-code-span-padding) 0;
}

.jp-RenderedText pre .ansi-bold {
  font-weight: bold;
}

.jp-RenderedText pre .ansi-underline {
  text-decoration: underline;
}

.jp-RenderedText[data-mime-type='application/vnd.jupyter.stderr'] {
  background: var(--jp-rendermime-error-background);
  padding-top: var(--jp-code-padding);
}

/*-----------------------------------------------------------------------------
| RenderedLatex
|----------------------------------------------------------------------------*/

.jp-RenderedLatex {
  color: var(--jp-content-font-color1);
  font-size: var(--jp-content-font-size1);
  line-height: var(--jp-content-line-height);
}

/* Left-justify outputs.*/
.jp-OutputArea-output.jp-RenderedLatex {
  padding: var(--jp-code-padding);
  text-align: left;
}

/*-----------------------------------------------------------------------------
| RenderedHTML
|----------------------------------------------------------------------------*/

.jp-RenderedHTMLCommon {
  color: var(--jp-content-font-color1);
  font-family: var(--jp-content-font-family);
  font-size: var(--jp-content-font-size1);
  line-height: var(--jp-content-line-height);

  /* Give a bit more R padding on Markdown text to keep line lengths reasonable */
  padding-right: 20px;
}

.jp-RenderedHTMLCommon em {
  font-style: italic;
}

.jp-RenderedHTMLCommon strong {
  font-weight: bold;
}

.jp-RenderedHTMLCommon u {
  text-decoration: underline;
}

.jp-RenderedHTMLCommon a:link {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

.jp-RenderedHTMLCommon a:hover {
  text-decoration: underline;
  color: var(--jp-content-link-color);
}

.jp-RenderedHTMLCommon a:visited {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

/* Headings */

.jp-RenderedHTMLCommon h1,
.jp-RenderedHTMLCommon h2,
.jp-RenderedHTMLCommon h3,
.jp-RenderedHTMLCommon h4,
.jp-RenderedHTMLCommon h5,
.jp-RenderedHTMLCommon h6 {
  line-height: var(--jp-content-heading-line-height);
  font-weight: var(--jp-content-heading-font-weight);
  font-style: normal;
  margin: var(--jp-content-heading-margin-top) 0
    var(--jp-content-heading-margin-bottom) 0;
}

.jp-RenderedHTMLCommon h1:first-child,
.jp-RenderedHTMLCommon h2:first-child,
.jp-RenderedHTMLCommon h3:first-child,
.jp-RenderedHTMLCommon h4:first-child,
.jp-RenderedHTMLCommon h5:first-child,
.jp-RenderedHTMLCommon h6:first-child {
  margin-top: calc(0.5 * var(--jp-content-heading-margin-top));
}

.jp-RenderedHTMLCommon h1:last-child,
.jp-RenderedHTMLCommon h2:last-child,
.jp-RenderedHTMLCommon h3:last-child,
.jp-RenderedHTMLCommon h4:last-child,
.jp-RenderedHTMLCommon h5:last-child,
.jp-RenderedHTMLCommon h6:last-child {
  margin-bottom: calc(0.5 * var(--jp-content-heading-margin-bottom));
}

.jp-RenderedHTMLCommon h1 {
  font-size: var(--jp-content-font-size5);
}

.jp-RenderedHTMLCommon h2 {
  font-size: var(--jp-content-font-size4);
}

.jp-RenderedHTMLCommon h3 {
  font-size: var(--jp-content-font-size3);
}

.jp-RenderedHTMLCommon h4 {
  font-size: var(--jp-content-font-size2);
}

.jp-RenderedHTMLCommon h5 {
  font-size: var(--jp-content-font-size1);
}

.jp-RenderedHTMLCommon h6 {
  font-size: var(--jp-content-font-size0);
}

/* Lists */

/* stylelint-disable selector-max-type, selector-max-compound-selectors */

.jp-RenderedHTMLCommon ul:not(.list-inline),
.jp-RenderedHTMLCommon ol:not(.list-inline) {
  padding-left: 2em;
}

.jp-RenderedHTMLCommon ul {
  list-style: disc;
}

.jp-RenderedHTMLCommon ul ul {
  list-style: square;
}

.jp-RenderedHTMLCommon ul ul ul {
  list-style: circle;
}

.jp-RenderedHTMLCommon ol {
  list-style: decimal;
}

.jp-RenderedHTMLCommon ol ol {
  list-style: upper-alpha;
}

.jp-RenderedHTMLCommon ol ol ol {
  list-style: lower-alpha;
}

.jp-RenderedHTMLCommon ol ol ol ol {
  list-style: lower-roman;
}

.jp-RenderedHTMLCommon ol ol ol ol ol {
  list-style: decimal;
}

.jp-RenderedHTMLCommon ol,
.jp-RenderedHTMLCommon ul {
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon ul ul,
.jp-RenderedHTMLCommon ul ol,
.jp-RenderedHTMLCommon ol ul,
.jp-RenderedHTMLCommon ol ol {
  margin-bottom: 0;
}

/* stylelint-enable selector-max-type, selector-max-compound-selectors */

.jp-RenderedHTMLCommon hr {
  color: var(--jp-border-color2);
  background-color: var(--jp-border-color1);
  margin-top: 1em;
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon > pre {
  margin: 1.5em 2em;
}

.jp-RenderedHTMLCommon pre,
.jp-RenderedHTMLCommon code {
  border: 0;
  background-color: var(--jp-layout-color0);
  color: var(--jp-content-font-color1);
  font-family: var(--jp-code-font-family);
  font-size: inherit;
  line-height: var(--jp-code-line-height);
  padding: 0;
  white-space: pre-wrap;
}

.jp-RenderedHTMLCommon :not(pre) > code {
  background-color: var(--jp-layout-color2);
  padding: 1px 5px;
}

/* Tables */

.jp-RenderedHTMLCommon table {
  border-collapse: collapse;
  border-spacing: 0;
  border: none;
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
  table-layout: fixed;
  margin-left: auto;
  margin-bottom: 1em;
  margin-right: auto;
}

.jp-RenderedHTMLCommon thead {
  border-bottom: var(--jp-border-width) solid var(--jp-border-color1);
  vertical-align: bottom;
}

.jp-RenderedHTMLCommon td,
.jp-RenderedHTMLCommon th,
.jp-RenderedHTMLCommon tr {
  vertical-align: middle;
  padding: 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}

.jp-RenderedMarkdown.jp-RenderedHTMLCommon td,
.jp-RenderedMarkdown.jp-RenderedHTMLCommon th {
  max-width: none;
}

:not(.jp-RenderedMarkdown).jp-RenderedHTMLCommon td,
:not(.jp-RenderedMarkdown).jp-RenderedHTMLCommon th,
:not(.jp-RenderedMarkdown).jp-RenderedHTMLCommon tr {
  text-align: right;
}

.jp-RenderedHTMLCommon th {
  font-weight: bold;
}

.jp-RenderedHTMLCommon tbody tr:nth-child(odd) {
  background: var(--jp-layout-color0);
}

.jp-RenderedHTMLCommon tbody tr:nth-child(even) {
  background: var(--jp-rendermime-table-row-background);
}

.jp-RenderedHTMLCommon tbody tr:hover {
  background: var(--jp-rendermime-table-row-hover-background);
}

.jp-RenderedHTMLCommon p {
  text-align: left;
  margin: 0;
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon img {
  -moz-force-broken-image-icon: 1;
}

/* Restrict to direct children as other images could be nested in other content. */
.jp-RenderedHTMLCommon > img {
  display: block;
  margin-left: 0;
  margin-right: 0;
  margin-bottom: 1em;
}

/* Change color behind transparent images if they need it... */
[data-jp-theme-light='false'] .jp-RenderedImage img.jp-needs-light-background {
  background-color: var(--jp-inverse-layout-color1);
}

[data-jp-theme-light='true'] .jp-RenderedImage img.jp-needs-dark-background {
  background-color: var(--jp-inverse-layout-color1);
}

.jp-RenderedHTMLCommon img,
.jp-RenderedImage img,
.jp-RenderedHTMLCommon svg,
.jp-RenderedSVG svg {
  max-width: 100%;
  height: auto;
}

.jp-RenderedHTMLCommon img.jp-mod-unconfined,
.jp-RenderedImage img.jp-mod-unconfined,
.jp-RenderedHTMLCommon svg.jp-mod-unconfined,
.jp-RenderedSVG svg.jp-mod-unconfined {
  max-width: none;
}

.jp-RenderedHTMLCommon .alert {
  padding: var(--jp-notebook-padding);
  border: var(--jp-border-width) solid transparent;
  border-radius: var(--jp-border-radius);
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon .alert-info {
  color: var(--jp-info-color0);
  background-color: var(--jp-info-color3);
  border-color: var(--jp-info-color2);
}

.jp-RenderedHTMLCommon .alert-info hr {
  border-color: var(--jp-info-color3);
}

.jp-RenderedHTMLCommon .alert-info > p:last-child,
.jp-RenderedHTMLCommon .alert-info > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon .alert-warning {
  color: var(--jp-warn-color0);
  background-color: var(--jp-warn-color3);
  border-color: var(--jp-warn-color2);
}

.jp-RenderedHTMLCommon .alert-warning hr {
  border-color: var(--jp-warn-color3);
}

.jp-RenderedHTMLCommon .alert-warning > p:last-child,
.jp-RenderedHTMLCommon .alert-warning > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon .alert-success {
  color: var(--jp-success-color0);
  background-color: var(--jp-success-color3);
  border-color: var(--jp-success-color2);
}

.jp-RenderedHTMLCommon .alert-success hr {
  border-color: var(--jp-success-color3);
}

.jp-RenderedHTMLCommon .alert-success > p:last-child,
.jp-RenderedHTMLCommon .alert-success > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon .alert-danger {
  color: var(--jp-error-color0);
  background-color: var(--jp-error-color3);
  border-color: var(--jp-error-color2);
}

.jp-RenderedHTMLCommon .alert-danger hr {
  border-color: var(--jp-error-color3);
}

.jp-RenderedHTMLCommon .alert-danger > p:last-child,
.jp-RenderedHTMLCommon .alert-danger > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon blockquote {
  margin: 1em 2em;
  padding: 0 1em;
  border-left: 5px solid var(--jp-border-color2);
}

a.jp-InternalAnchorLink {
  visibility: hidden;
  margin-left: 8px;
  color: var(--md-blue-800);
}

h1:hover .jp-InternalAnchorLink,
h2:hover .jp-InternalAnchorLink,
h3:hover .jp-InternalAnchorLink,
h4:hover .jp-InternalAnchorLink,
h5:hover .jp-InternalAnchorLink,
h6:hover .jp-InternalAnchorLink {
  visibility: visible;
}

.jp-RenderedHTMLCommon kbd {
  background-color: var(--jp-rendermime-table-row-background);
  border: 1px solid var(--jp-border-color0);
  border-bottom-color: var(--jp-border-color2);
  border-radius: 3px;
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.25);
  display: inline-block;
  font-size: var(--jp-ui-font-size0);
  line-height: 1em;
  padding: 0.2em 0.5em;
}

/* Most direct children of .jp-RenderedHTMLCommon have a margin-bottom of 1.0.
 * At the bottom of cells this is a bit too much as there is also spacing
 * between cells. Going all the way to 0 gets too tight between markdown and
 * code cells.
 */
.jp-RenderedHTMLCommon > *:last-child {
  margin-bottom: 0.5em;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

.lm-cursor-backdrop {
  position: fixed;
  width: 200px;
  height: 200px;
  margin-top: -100px;
  margin-left: -100px;
  will-change: transform;
  z-index: 100;
}

.lm-mod-drag-image {
  will-change: transform;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.jp-lineFormSearch {
  padding: 4px 12px;
  background-color: var(--jp-layout-color2);
  box-shadow: var(--jp-toolbar-box-shadow);
  z-index: 2;
  font-size: var(--jp-ui-font-size1);
}

.jp-lineFormCaption {
  font-size: var(--jp-ui-font-size0);
  line-height: var(--jp-ui-font-size1);
  margin-top: 4px;
  color: var(--jp-ui-font-color0);
}

.jp-baseLineForm {
  border: none;
  border-radius: 0;
  position: absolute;
  background-size: 16px;
  background-repeat: no-repeat;
  background-position: center;
  outline: none;
}

.jp-lineFormButtonContainer {
  top: 4px;
  right: 8px;
  height: 24px;
  padding: 0 12px;
  width: 12px;
}

.jp-lineFormButtonIcon {
  top: 0;
  right: 0;
  background-color: var(--jp-brand-color1);
  height: 100%;
  width: 100%;
  box-sizing: border-box;
  padding: 4px 6px;
}

.jp-lineFormButton {
  top: 0;
  right: 0;
  background-color: transparent;
  height: 100%;
  width: 100%;
  box-sizing: border-box;
}

.jp-lineFormWrapper {
  overflow: hidden;
  padding: 0 8px;
  border: 1px solid var(--jp-border-color0);
  background-color: var(--jp-input-active-background);
  height: 22px;
}

.jp-lineFormWrapperFocusWithin {
  border: var(--jp-border-width) solid var(--md-blue-500);
  box-shadow: inset 0 0 4px var(--md-blue-300);
}

.jp-lineFormInput {
  background: transparent;
  width: 200px;
  height: 100%;
  border: none;
  outline: none;
  color: var(--jp-ui-font-color0);
  line-height: 28px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-JSONEditor {
  display: flex;
  flex-direction: column;
  width: 100%;
}

.jp-JSONEditor-host {
  flex: 1 1 auto;
  border: var(--jp-border-width) solid var(--jp-input-border-color);
  border-radius: 0;
  background: var(--jp-layout-color0);
  min-height: 50px;
  padding: 1px;
}

.jp-JSONEditor.jp-mod-error .jp-JSONEditor-host {
  border-color: red;
  outline-color: red;
}

.jp-JSONEditor-header {
  display: flex;
  flex: 1 0 auto;
  padding: 0 0 0 12px;
}

.jp-JSONEditor-header label {
  flex: 0 0 auto;
}

.jp-JSONEditor-commitButton {
  height: 16px;
  width: 16px;
  background-size: 18px;
  background-repeat: no-repeat;
  background-position: center;
}

.jp-JSONEditor-host.jp-mod-focused {
  background-color: var(--jp-input-active-background);
  border: 1px solid var(--jp-input-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
}

.jp-Editor.jp-mod-dropTarget {
  border: var(--jp-border-width) solid var(--jp-input-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/
.jp-DocumentSearch-input {
  border: none;
  outline: none;
  color: var(--jp-ui-font-color0);
  font-size: var(--jp-ui-font-size1);
  background-color: var(--jp-layout-color0);
  font-family: var(--jp-ui-font-family);
  padding: 2px 1px;
  resize: none;
}

.jp-DocumentSearch-overlay {
  position: absolute;
  background-color: var(--jp-toolbar-background);
  border-bottom: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  border-left: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  top: 0;
  right: 0;
  z-index: 7;
  min-width: 405px;
  padding: 2px;
  font-size: var(--jp-ui-font-size1);

  --jp-private-document-search-button-height: 20px;
}

.jp-DocumentSearch-overlay button {
  background-color: var(--jp-toolbar-background);
  outline: 0;
}

.jp-DocumentSearch-overlay button:hover {
  background-color: var(--jp-layout-color2);
}

.jp-DocumentSearch-overlay button:active {
  background-color: var(--jp-layout-color3);
}

.jp-DocumentSearch-overlay-row {
  display: flex;
  align-items: center;
  margin-bottom: 2px;
}

.jp-DocumentSearch-button-content {
  display: inline-block;
  cursor: pointer;
  box-sizing: border-box;
  width: 100%;
  height: 100%;
}

.jp-DocumentSearch-button-content svg {
  width: 100%;
  height: 100%;
}

.jp-DocumentSearch-input-wrapper {
  border: var(--jp-border-width) solid var(--jp-border-color0);
  display: flex;
  background-color: var(--jp-layout-color0);
  margin: 2px;
}

.jp-DocumentSearch-input-wrapper:focus-within {
  border-color: var(--jp-cell-editor-active-border-color);
}

.jp-DocumentSearch-toggle-wrapper,
.jp-DocumentSearch-button-wrapper {
  all: initial;
  overflow: hidden;
  display: inline-block;
  border: none;
  box-sizing: border-box;
}

.jp-DocumentSearch-toggle-wrapper {
  width: 14px;
  height: 14px;
}

.jp-DocumentSearch-button-wrapper {
  width: var(--jp-private-document-search-button-height);
  height: var(--jp-private-document-search-button-height);
}

.jp-DocumentSearch-toggle-wrapper:focus,
.jp-DocumentSearch-button-wrapper:focus {
  outline: var(--jp-border-width) solid
    var(--jp-cell-editor-active-border-color);
  outline-offset: -1px;
}

.jp-DocumentSearch-toggle-wrapper,
.jp-DocumentSearch-button-wrapper,
.jp-DocumentSearch-button-content:focus {
  outline: none;
}

.jp-DocumentSearch-toggle-placeholder {
  width: 5px;
}

.jp-DocumentSearch-input-button::before {
  display: block;
  padding-top: 100%;
}

.jp-DocumentSearch-input-button-off {
  opacity: var(--jp-search-toggle-off-opacity);
}

.jp-DocumentSearch-input-button-off:hover {
  opacity: var(--jp-search-toggle-hover-opacity);
}

.jp-DocumentSearch-input-button-on {
  opacity: var(--jp-search-toggle-on-opacity);
}

.jp-DocumentSearch-index-counter {
  padding-left: 10px;
  padding-right: 10px;
  user-select: none;
  min-width: 35px;
  display: inline-block;
}

.jp-DocumentSearch-up-down-wrapper {
  display: inline-block;
  padding-right: 2px;
  margin-left: auto;
  white-space: nowrap;
}

.jp-DocumentSearch-spacer {
  margin-left: auto;
}

.jp-DocumentSearch-up-down-wrapper button {
  outline: 0;
  border: none;
  width: var(--jp-private-document-search-button-height);
  height: var(--jp-private-document-search-button-height);
  vertical-align: middle;
  margin: 1px 5px 2px;
}

.jp-DocumentSearch-up-down-button:hover {
  background-color: var(--jp-layout-color2);
}

.jp-DocumentSearch-up-down-button:active {
  background-color: var(--jp-layout-color3);
}

.jp-DocumentSearch-filter-button {
  border-radius: var(--jp-border-radius);
}

.jp-DocumentSearch-filter-button:hover {
  background-color: var(--jp-layout-color2);
}

.jp-DocumentSearch-filter-button-enabled {
  background-color: var(--jp-layout-color2);
}

.jp-DocumentSearch-filter-button-enabled:hover {
  background-color: var(--jp-layout-color3);
}

.jp-DocumentSearch-search-options {
  padding: 0 8px;
  margin-left: 3px;
  width: 100%;
  display: grid;
  justify-content: start;
  grid-template-columns: 1fr 1fr;
  align-items: center;
  justify-items: stretch;
}

.jp-DocumentSearch-search-filter-disabled {
  color: var(--jp-ui-font-color2);
}

.jp-DocumentSearch-search-filter {
  display: flex;
  align-items: center;
  user-select: none;
}

.jp-DocumentSearch-regex-error {
  color: var(--jp-error-color0);
}

.jp-DocumentSearch-replace-button-wrapper {
  overflow: hidden;
  display: inline-block;
  box-sizing: border-box;
  border: var(--jp-border-width) solid var(--jp-border-color0);
  margin: auto 2px;
  padding: 1px 4px;
  height: calc(var(--jp-private-document-search-button-height) + 2px);
}

.jp-DocumentSearch-replace-button-wrapper:focus {
  border: var(--jp-border-width) solid var(--jp-cell-editor-active-border-color);
}

.jp-DocumentSearch-replace-button {
  display: inline-block;
  text-align: center;
  cursor: pointer;
  box-sizing: border-box;
  color: var(--jp-ui-font-color1);

  /* height - 2 * (padding of wrapper) */
  line-height: calc(var(--jp-private-document-search-button-height) - 2px);
  width: 100%;
  height: 100%;
}

.jp-DocumentSearch-replace-button:focus {
  outline: none;
}

.jp-DocumentSearch-replace-wrapper-class {
  margin-left: 14px;
  display: flex;
}

.jp-DocumentSearch-replace-toggle {
  border: none;
  background-color: var(--jp-toolbar-background);
  border-radius: var(--jp-border-radius);
}

.jp-DocumentSearch-replace-toggle:hover {
  background-color: var(--jp-layout-color2);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.cm-editor {
  line-height: var(--jp-code-line-height);
  font-size: var(--jp-code-font-size);
  font-family: var(--jp-code-font-family);
  border: 0;
  border-radius: 0;
  height: auto;

  /* Changed to auto to autogrow */
}

.cm-editor pre {
  padding: 0 var(--jp-code-padding);
}

.jp-CodeMirrorEditor[data-type='inline'] .cm-dialog {
  background-color: var(--jp-layout-color0);
  color: var(--jp-content-font-color1);
}

.jp-CodeMirrorEditor {
  cursor: text;
}

/* When zoomed out 67% and 33% on a screen of 1440 width x 900 height */
@media screen and (min-width: 2138px) and (max-width: 4319px) {
  .jp-CodeMirrorEditor[data-type='inline'] .cm-cursor {
    border-left: var(--jp-code-cursor-width1) solid
      var(--jp-editor-cursor-color);
  }
}

/* When zoomed out less than 33% */
@media screen and (min-width: 4320px) {
  .jp-CodeMirrorEditor[data-type='inline'] .cm-cursor {
    border-left: var(--jp-code-cursor-width2) solid
      var(--jp-editor-cursor-color);
  }
}

.cm-editor.jp-mod-readOnly .cm-cursor {
  display: none;
}

.jp-CollaboratorCursor {
  border-left: 5px solid transparent;
  border-right: 5px solid transparent;
  border-top: none;
  border-bottom: 3px solid;
  background-clip: content-box;
  margin-left: -5px;
  margin-right: -5px;
}

.cm-searching,
.cm-searching span {
  /* `.cm-searching span`: we need to override syntax highlighting */
  background-color: var(--jp-search-unselected-match-background-color);
  color: var(--jp-search-unselected-match-color);
}

.cm-searching::selection,
.cm-searching span::selection {
  background-color: var(--jp-search-unselected-match-background-color);
  color: var(--jp-search-unselected-match-color);
}

.jp-current-match > .cm-searching,
.jp-current-match > .cm-searching span,
.cm-searching > .jp-current-match,
.cm-searching > .jp-current-match span {
  background-color: var(--jp-search-selected-match-background-color);
  color: var(--jp-search-selected-match-color);
}

.jp-current-match > .cm-searching::selection,
.cm-searching > .jp-current-match::selection,
.jp-current-match > .cm-searching span::selection {
  background-color: var(--jp-search-selected-match-background-color);
  color: var(--jp-search-selected-match-color);
}

.cm-trailingspace {
  background-image: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAFCAYAAAB4ka1VAAAAsElEQVQIHQGlAFr/AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA7+r3zKmT0/+pk9P/7+r3zAAAAAAAAAAABAAAAAAAAAAA6OPzM+/q9wAAAAAA6OPzMwAAAAAAAAAAAgAAAAAAAAAAGR8NiRQaCgAZIA0AGR8NiQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAQyoYJ/SY80UAAAAASUVORK5CYII=);
  background-position: center left;
  background-repeat: repeat-x;
}

.jp-CollaboratorCursor-hover {
  position: absolute;
  z-index: 1;
  transform: translateX(-50%);
  color: white;
  border-radius: 3px;
  padding-left: 4px;
  padding-right: 4px;
  padding-top: 1px;
  padding-bottom: 1px;
  text-align: center;
  font-size: var(--jp-ui-font-size1);
  white-space: nowrap;
}

.jp-CodeMirror-ruler {
  border-left: 1px dashed var(--jp-border-color2);
}

/* Styles for shared cursors (remote cursor locations and selected ranges) */
.jp-CodeMirrorEditor .cm-ySelectionCaret {
  position: relative;
  border-left: 1px solid black;
  margin-left: -1px;
  margin-right: -1px;
  box-sizing: border-box;
}

.jp-CodeMirrorEditor .cm-ySelectionCaret > .cm-ySelectionInfo {
  white-space: nowrap;
  position: absolute;
  top: -1.15em;
  padding-bottom: 0.05em;
  left: -1px;
  font-size: 0.95em;
  font-family: var(--jp-ui-font-family);
  font-weight: bold;
  line-height: normal;
  user-select: none;
  color: white;
  padding-left: 2px;
  padding-right: 2px;
  z-index: 101;
  transition: opacity 0.3s ease-in-out;
}

.jp-CodeMirrorEditor .cm-ySelectionInfo {
  transition-delay: 0.7s;
  opacity: 0;
}

.jp-CodeMirrorEditor .cm-ySelectionCaret:hover > .cm-ySelectionInfo {
  opacity: 1;
  transition-delay: 0s;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-MimeDocument {
  outline: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

:root {
  --jp-private-filebrowser-button-height: 28px;
  --jp-private-filebrowser-button-width: 48px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-FileBrowser .jp-SidePanel-content {
  display: flex;
  flex-direction: column;
}

.jp-FileBrowser-toolbar.jp-Toolbar {
  flex-wrap: wrap;
  row-gap: 12px;
  border-bottom: none;
  height: auto;
  margin: 8px 12px 0;
  box-shadow: none;
  padding: 0;
  justify-content: flex-start;
}

.jp-FileBrowser-Panel {
  flex: 1 1 auto;
  display: flex;
  flex-direction: column;
}

.jp-BreadCrumbs {
  flex: 0 0 auto;
  margin: 8px 12px;
}

.jp-BreadCrumbs-item {
  margin: 0 2px;
  padding: 0 2px;
  border-radius: var(--jp-border-radius);
  cursor: pointer;
}

.jp-BreadCrumbs-item:hover {
  background-color: var(--jp-layout-color2);
}

.jp-BreadCrumbs-item:first-child {
  margin-left: 0;
}

.jp-BreadCrumbs-item.jp-mod-dropTarget {
  background-color: var(--jp-brand-color2);
  opacity: 0.7;
}

/*-----------------------------------------------------------------------------
| Buttons
|----------------------------------------------------------------------------*/

.jp-FileBrowser-toolbar > .jp-Toolbar-item {
  flex: 0 0 auto;
  padding-left: 0;
  padding-right: 2px;
  align-items: center;
  height: unset;
}

.jp-FileBrowser-toolbar > .jp-Toolbar-item .jp-ToolbarButtonComponent {
  width: 40px;
}

/*-----------------------------------------------------------------------------
| Other styles
|----------------------------------------------------------------------------*/

.jp-FileDialog.jp-mod-conflict input {
  color: var(--jp-error-color1);
}

.jp-FileDialog .jp-new-name-title {
  margin-top: 12px;
}

.jp-LastModified-hidden {
  display: none;
}

.jp-FileSize-hidden {
  display: none;
}

.jp-FileBrowser .lm-AccordionPanel > h3:first-child {
  display: none;
}

/*-----------------------------------------------------------------------------
| DirListing
|----------------------------------------------------------------------------*/

.jp-DirListing {
  flex: 1 1 auto;
  display: flex;
  flex-direction: column;
  outline: 0;
}

.jp-DirListing-header {
  flex: 0 0 auto;
  display: flex;
  flex-direction: row;
  align-items: center;
  overflow: hidden;
  border-top: var(--jp-border-width) solid var(--jp-border-color2);
  border-bottom: var(--jp-border-width) solid var(--jp-border-color1);
  box-shadow: var(--jp-toolbar-box-shadow);
  z-index: 2;
}

.jp-DirListing-headerItem {
  padding: 4px 12px 2px;
  font-weight: 500;
}

.jp-DirListing-headerItem:hover {
  background: var(--jp-layout-color2);
}

.jp-DirListing-headerItem.jp-id-name {
  flex: 1 0 84px;
}

.jp-DirListing-headerItem.jp-id-modified {
  flex: 0 0 112px;
  border-left: var(--jp-border-width) solid var(--jp-border-color2);
  text-align: right;
}

.jp-DirListing-headerItem.jp-id-filesize {
  flex: 0 0 75px;
  border-left: var(--jp-border-width) solid var(--jp-border-color2);
  text-align: right;
}

.jp-id-narrow {
  display: none;
  flex: 0 0 5px;
  padding: 4px;
  border-left: var(--jp-border-width) solid var(--jp-border-color2);
  text-align: right;
  color: var(--jp-border-color2);
}

.jp-DirListing-narrow .jp-id-narrow {
  display: block;
}

.jp-DirListing-narrow .jp-id-modified,
.jp-DirListing-narrow .jp-DirListing-itemModified {
  display: none;
}

.jp-DirListing-headerItem.jp-mod-selected {
  font-weight: 600;
}

/* increase specificity to override bundled default */
.jp-DirListing-content {
  flex: 1 1 auto;
  margin: 0;
  padding: 0;
  list-style-type: none;
  overflow: auto;
  background-color: var(--jp-layout-color1);
}

.jp-DirListing-content mark {
  color: var(--jp-ui-font-color0);
  background-color: transparent;
  font-weight: bold;
}

.jp-DirListing-content .jp-DirListing-item.jp-mod-selected mark {
  color: var(--jp-ui-inverse-font-color0);
}

/* Style the directory listing content when a user drops a file to upload */
.jp-DirListing.jp-mod-native-drop .jp-DirListing-content {
  outline: 5px dashed rgba(128, 128, 128, 0.5);
  outline-offset: -10px;
  cursor: copy;
}

.jp-DirListing-item {
  display: flex;
  flex-direction: row;
  align-items: center;
  padding: 4px 12px;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.jp-DirListing-checkboxWrapper {
  /* Increases hit area of checkbox. */
  padding: 4px;
}

.jp-DirListing-header
  .jp-DirListing-checkboxWrapper
  + .jp-DirListing-headerItem {
  padding-left: 4px;
}

.jp-DirListing-content .jp-DirListing-checkboxWrapper {
  position: relative;
  left: -4px;
  margin: -4px 0 -4px -8px;
}

.jp-DirListing-checkboxWrapper.jp-mod-visible {
  visibility: visible;
}

/* For devices that support hovering, hide checkboxes until hovered, selected...
*/
@media (hover: hover) {
  .jp-DirListing-checkboxWrapper {
    visibility: hidden;
  }

  .jp-DirListing-item:hover .jp-DirListing-checkboxWrapper,
  .jp-DirListing-item.jp-mod-selected .jp-DirListing-checkboxWrapper {
    visibility: visible;
  }
}

.jp-DirListing-item[data-is-dot] {
  opacity: 75%;
}

.jp-DirListing-item.jp-mod-selected {
  color: var(--jp-ui-inverse-font-color1);
  background: var(--jp-brand-color1);
}

.jp-DirListing-item.jp-mod-dropTarget {
  background: var(--jp-brand-color3);
}

.jp-DirListing-item:hover:not(.jp-mod-selected) {
  background: var(--jp-layout-color2);
}

.jp-DirListing-itemIcon {
  flex: 0 0 20px;
  margin-right: 4px;
}

.jp-DirListing-itemText {
  flex: 1 0 64px;
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;
  user-select: none;
}

.jp-DirListing-itemText:focus {
  outline-width: 2px;
  outline-color: var(--jp-inverse-layout-color1);
  outline-style: solid;
  outline-offset: 1px;
}

.jp-DirListing-item.jp-mod-selected .jp-DirListing-itemText:focus {
  outline-color: var(--jp-layout-color1);
}

.jp-DirListing-itemModified {
  flex: 0 0 125px;
  text-align: right;
}

.jp-DirListing-itemFileSize {
  flex: 0 0 90px;
  text-align: right;
}

.jp-DirListing-editor {
  flex: 1 0 64px;
  outline: none;
  border: none;
  color: var(--jp-ui-font-color1);
  background-color: var(--jp-layout-color1);
}

.jp-DirListing-item.jp-mod-running .jp-DirListing-itemIcon::before {
  color: var(--jp-success-color1);
  content: '\25CF';
  font-size: 8px;
  position: absolute;
  left: -8px;
}

.jp-DirListing-item.jp-mod-running.jp-mod-selected
  .jp-DirListing-itemIcon::before {
  color: var(--jp-ui-inverse-font-color1);
}

.jp-DirListing-item.lm-mod-drag-image,
.jp-DirListing-item.jp-mod-selected.lm-mod-drag-image {
  font-size: var(--jp-ui-font-size1);
  padding-left: 4px;
  margin-left: 4px;
  width: 160px;
  background-color: var(--jp-ui-inverse-font-color2);
  box-shadow: var(--jp-elevation-z2);
  border-radius: 0;
  color: var(--jp-ui-font-color1);
  transform: translateX(-40%) translateY(-58%);
}

.jp-Document {
  min-width: 120px;
  min-height: 120px;
  outline: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Main OutputArea
| OutputArea has a list of Outputs
|----------------------------------------------------------------------------*/

.jp-OutputArea {
  overflow-y: auto;
}

.jp-OutputArea-child {
  display: table;
  table-layout: fixed;
  width: 100%;
  overflow: hidden;
}

.jp-OutputPrompt {
  width: var(--jp-cell-prompt-width);
  color: var(--jp-cell-outprompt-font-color);
  font-family: var(--jp-cell-prompt-font-family);
  padding: var(--jp-code-padding);
  letter-spacing: var(--jp-cell-prompt-letter-spacing);
  line-height: var(--jp-code-line-height);
  font-size: var(--jp-code-font-size);
  border: var(--jp-border-width) solid transparent;
  opacity: var(--jp-cell-prompt-opacity);

  /* Right align prompt text, don't wrap to handle large prompt numbers */
  text-align: right;
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;

  /* Disable text selection */
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.jp-OutputArea-prompt {
  display: table-cell;
  vertical-align: top;
}

.jp-OutputArea-output {
  display: table-cell;
  width: 100%;
  height: auto;
  overflow: auto;
  user-select: text;
  -moz-user-select: text;
  -webkit-user-select: text;
  -ms-user-select: text;
}

.jp-OutputArea .jp-RenderedText {
  padding-left: 1ch;
}

/**
 * Prompt overlay.
 */

.jp-OutputArea-promptOverlay {
  position: absolute;
  top: 0;
  width: var(--jp-cell-prompt-width);
  height: 100%;
  opacity: 0.5;
}

.jp-OutputArea-promptOverlay:hover {
  background: var(--jp-layout-color2);
  box-shadow: inset 0 0 1px var(--jp-inverse-layout-color0);
  cursor: zoom-out;
}

.jp-mod-outputsScrolled .jp-OutputArea-promptOverlay:hover {
  cursor: zoom-in;
}

/**
 * Isolated output.
 */
.jp-OutputArea-output.jp-mod-isolated {
  width: 100%;
  display: block;
}

/*
When drag events occur, `lm-mod-override-cursor` is added to the body.
Because iframes steal all cursor events, the following two rules are necessary
to suppress pointer events while resize drags are occurring. There may be a
better solution to this problem.
*/
body.lm-mod-override-cursor .jp-OutputArea-output.jp-mod-isolated {
  position: relative;
}

body.lm-mod-override-cursor .jp-OutputArea-output.jp-mod-isolated::before {
  content: '';
  position: absolute;
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  background: transparent;
}

/* pre */

.jp-OutputArea-output pre {
  border: none;
  margin: 0;
  padding: 0;
  overflow-x: auto;
  overflow-y: auto;
  word-break: break-all;
  word-wrap: break-word;
  white-space: pre-wrap;
}

/* tables */

.jp-OutputArea-output.jp-RenderedHTMLCommon table {
  margin-left: 0;
  margin-right: 0;
}

/* description lists */

.jp-OutputArea-output dl,
.jp-OutputArea-output dt,
.jp-OutputArea-output dd {
  display: block;
}

.jp-OutputArea-output dl {
  width: 100%;
  overflow: hidden;
  padding: 0;
  margin: 0;
}

.jp-OutputArea-output dt {
  font-weight: bold;
  float: left;
  width: 20%;
  padding: 0;
  margin: 0;
}

.jp-OutputArea-output dd {
  float: left;
  width: 80%;
  padding: 0;
  margin: 0;
}

.jp-TrimmedOutputs pre {
  background: var(--jp-layout-color3);
  font-size: calc(var(--jp-code-font-size) * 1.4);
  text-align: center;
  text-transform: uppercase;
}

/* Hide the gutter in case of
 *  - nested output areas (e.g. in the case of output widgets)
 *  - mirrored output areas
 */
.jp-OutputArea .jp-OutputArea .jp-OutputArea-prompt {
  display: none;
}

/* Hide empty lines in the output area, for instance due to cleared widgets */
.jp-OutputArea-prompt:empty {
  padding: 0;
  border: 0;
}

/*-----------------------------------------------------------------------------
| executeResult is added to any Output-result for the display of the object
| returned by a cell
|----------------------------------------------------------------------------*/

.jp-OutputArea-output.jp-OutputArea-executeResult {
  margin-left: 0;
  width: 100%;
}

/* Text output with the Out[] prompt needs a top padding to match the
 * alignment of the Out[] prompt itself.
 */
.jp-OutputArea-executeResult .jp-RenderedText.jp-OutputArea-output {
  padding-top: var(--jp-code-padding);
  border-top: var(--jp-border-width) solid transparent;
}

/*-----------------------------------------------------------------------------
| The Stdin output
|----------------------------------------------------------------------------*/

.jp-Stdin-prompt {
  color: var(--jp-content-font-color0);
  padding-right: var(--jp-code-padding);
  vertical-align: baseline;
  flex: 0 0 auto;
}

.jp-Stdin-input {
  font-family: var(--jp-code-font-family);
  font-size: inherit;
  color: inherit;
  background-color: inherit;
  width: 42%;
  min-width: 200px;

  /* make sure input baseline aligns with prompt */
  vertical-align: baseline;

  /* padding + margin = 0.5em between prompt and cursor */
  padding: 0 0.25em;
  margin: 0 0.25em;
  flex: 0 0 70%;
}

.jp-Stdin-input::placeholder {
  opacity: 0;
}

.jp-Stdin-input:focus {
  box-shadow: none;
}

.jp-Stdin-input:focus::placeholder {
  opacity: 1;
}

/*-----------------------------------------------------------------------------
| Output Area View
|----------------------------------------------------------------------------*/

.jp-LinkedOutputView .jp-OutputArea {
  height: 100%;
  display: block;
}

.jp-LinkedOutputView .jp-OutputArea-output:only-child {
  height: 100%;
}

/*-----------------------------------------------------------------------------
| Printing
|----------------------------------------------------------------------------*/

@media print {
  .jp-OutputArea-child {
    break-inside: avoid-page;
  }
}

/*-----------------------------------------------------------------------------
| Mobile
|----------------------------------------------------------------------------*/
@media only screen and (max-width: 760px) {
  .jp-OutputPrompt {
    display: table-row;
    text-align: left;
  }

  .jp-OutputArea-child .jp-OutputArea-output {
    display: table-row;
    margin-left: var(--jp-notebook-padding);
  }
}

/* Trimmed outputs warning */
.jp-TrimmedOutputs > a {
  margin: 10px;
  text-decoration: none;
  cursor: pointer;
}

.jp-TrimmedOutputs > a:hover {
  text-decoration: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Table of Contents
|----------------------------------------------------------------------------*/

:root {
  --jp-private-toc-active-width: 4px;
}

.jp-TableOfContents {
  display: flex;
  flex-direction: column;
  background: var(--jp-layout-color1);
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
  height: 100%;
}

.jp-TableOfContents-placeholder {
  text-align: center;
}

.jp-TableOfContents-placeholderContent {
  color: var(--jp-content-font-color2);
  padding: 8px;
}

.jp-TableOfContents-placeholderContent > h3 {
  margin-bottom: var(--jp-content-heading-margin-bottom);
}

.jp-TableOfContents .jp-SidePanel-content {
  overflow-y: auto;
}

.jp-TableOfContents-tree {
  margin: 4px;
}

.jp-TableOfContents ol {
  list-style-type: none;
}

/* stylelint-disable-next-line selector-max-type */
.jp-TableOfContents li > ol {
  /* Align left border with triangle icon center */
  padding-left: 11px;
}

.jp-TableOfContents-content {
  /* left margin for the active heading indicator */
  margin: 0 0 0 var(--jp-private-toc-active-width);
  padding: 0;
  background-color: var(--jp-layout-color1);
}

.jp-tocItem {
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.jp-tocItem-heading {
  display: flex;
  cursor: pointer;
}

.jp-tocItem-heading:hover {
  background-color: var(--jp-layout-color2);
}

.jp-tocItem-content {
  display: block;
  padding: 4px 0;
  white-space: nowrap;
  text-overflow: ellipsis;
  overflow-x: hidden;
}

.jp-tocItem-collapser {
  height: 20px;
  margin: 2px 2px 0;
  padding: 0;
  background: none;
  border: none;
  cursor: pointer;
}

.jp-tocItem-collapser:hover {
  background-color: var(--jp-layout-color3);
}

/* Active heading indicator */

.jp-tocItem-heading::before {
  content: ' ';
  background: transparent;
  width: var(--jp-private-toc-active-width);
  height: 24px;
  position: absolute;
  left: 0;
  border-radius: var(--jp-border-radius);
}

.jp-tocItem-heading.jp-tocItem-active::before {
  background-color: var(--jp-brand-color1);
}

.jp-tocItem-heading:hover.jp-tocItem-active::before {
  background: var(--jp-brand-color0);
  opacity: 1;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Collapser {
  flex: 0 0 var(--jp-cell-collapser-width);
  padding: 0;
  margin: 0;
  border: none;
  outline: none;
  background: transparent;
  border-radius: var(--jp-border-radius);
  opacity: 1;
}

.jp-Collapser-child {
  display: block;
  width: 100%;
  box-sizing: border-box;

  /* height: 100% doesn't work because the height of its parent is computed from content */
  position: absolute;
  top: 0;
  bottom: 0;
}

/*-----------------------------------------------------------------------------
| Printing
|----------------------------------------------------------------------------*/

/*
Hiding collapsers in print mode.

Note: input and output wrappers have "display: block" propery in print mode.
*/

@media print {
  .jp-Collapser {
    display: none;
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Header/Footer
|----------------------------------------------------------------------------*/

/* Hidden by zero height by default */
.jp-CellHeader,
.jp-CellFooter {
  height: 0;
  width: 100%;
  padding: 0;
  margin: 0;
  border: none;
  outline: none;
  background: transparent;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Input
|----------------------------------------------------------------------------*/

/* All input areas */
.jp-InputArea {
  display: table;
  table-layout: fixed;
  width: 100%;
  overflow: hidden;
}

.jp-InputArea-editor {
  display: table-cell;
  overflow: hidden;
  vertical-align: top;

  /* This is the non-active, default styling */
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  border-radius: 0;
  background: var(--jp-cell-editor-background);
}

.jp-InputPrompt {
  display: table-cell;
  vertical-align: top;
  width: var(--jp-cell-prompt-width);
  color: var(--jp-cell-inprompt-font-color);
  font-family: var(--jp-cell-prompt-font-family);
  padding: var(--jp-code-padding);
  letter-spacing: var(--jp-cell-prompt-letter-spacing);
  opacity: var(--jp-cell-prompt-opacity);
  line-height: var(--jp-code-line-height);
  font-size: var(--jp-code-font-size);
  border: var(--jp-border-width) solid transparent;

  /* Right align prompt text, don't wrap to handle large prompt numbers */
  text-align: right;
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;

  /* Disable text selection */
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

/*-----------------------------------------------------------------------------
| Mobile
|----------------------------------------------------------------------------*/
@media only screen and (max-width: 760px) {
  .jp-InputArea-editor {
    display: table-row;
    margin-left: var(--jp-notebook-padding);
  }

  .jp-InputPrompt {
    display: table-row;
    text-align: left;
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Placeholder
|----------------------------------------------------------------------------*/

.jp-Placeholder {
  display: table;
  table-layout: fixed;
  width: 100%;
}

.jp-Placeholder-prompt {
  display: table-cell;
  box-sizing: border-box;
}

.jp-Placeholder-content {
  display: table-cell;
  padding: 4px 6px;
  border: 1px solid transparent;
  border-radius: 0;
  background: none;
  box-sizing: border-box;
  cursor: pointer;
}

.jp-Placeholder-contentContainer {
  display: flex;
}

.jp-Placeholder-content:hover,
.jp-InputPlaceholder > .jp-Placeholder-content:hover {
  border-color: var(--jp-layout-color3);
}

.jp-Placeholder-content .jp-MoreHorizIcon {
  width: 32px;
  height: 16px;
  border: 1px solid transparent;
  border-radius: var(--jp-border-radius);
}

.jp-Placeholder-content .jp-MoreHorizIcon:hover {
  border: 1px solid var(--jp-border-color1);
  box-shadow: 0 0 2px 0 rgba(0, 0, 0, 0.25);
  background-color: var(--jp-layout-color0);
}

.jp-PlaceholderText {
  white-space: nowrap;
  overflow-x: hidden;
  color: var(--jp-inverse-layout-color3);
  font-family: var(--jp-code-font-family);
}

.jp-InputPlaceholder > .jp-Placeholder-content {
  border-color: var(--jp-cell-editor-border-color);
  background: var(--jp-cell-editor-background);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Private CSS variables
|----------------------------------------------------------------------------*/

:root {
  --jp-private-cell-scrolling-output-offset: 5px;
}

/*-----------------------------------------------------------------------------
| Cell
|----------------------------------------------------------------------------*/

.jp-Cell {
  padding: var(--jp-cell-padding);
  margin: 0;
  border: none;
  outline: none;
  background: transparent;
}

/*-----------------------------------------------------------------------------
| Common input/output
|----------------------------------------------------------------------------*/

.jp-Cell-inputWrapper,
.jp-Cell-outputWrapper {
  display: flex;
  flex-direction: row;
  padding: 0;
  margin: 0;

  /* Added to reveal the box-shadow on the input and output collapsers. */
  overflow: visible;
}

/* Only input/output areas inside cells */
.jp-Cell-inputArea,
.jp-Cell-outputArea {
  flex: 1 1 auto;
}

/*-----------------------------------------------------------------------------
| Collapser
|----------------------------------------------------------------------------*/

/* Make the output collapser disappear when there is not output, but do so
 * in a manner that leaves it in the layout and preserves its width.
 */
.jp-Cell.jp-mod-noOutputs .jp-Cell-outputCollapser {
  border: none !important;
  background: transparent !important;
}

.jp-Cell:not(.jp-mod-noOutputs) .jp-Cell-outputCollapser {
  min-height: var(--jp-cell-collapser-min-height);
}

/*-----------------------------------------------------------------------------
| Output
|----------------------------------------------------------------------------*/

/* Put a space between input and output when there IS output */
.jp-Cell:not(.jp-mod-noOutputs) .jp-Cell-outputWrapper {
  margin-top: 5px;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-Cell-outputArea {
  overflow-y: auto;
  max-height: 24em;
  margin-left: var(--jp-private-cell-scrolling-output-offset);
  resize: vertical;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-Cell-outputArea[style*='height'] {
  max-height: unset;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-Cell-outputArea::after {
  content: ' ';
  box-shadow: inset 0 0 6px 2px rgb(0 0 0 / 30%);
  width: 100%;
  height: 100%;
  position: sticky;
  bottom: 0;
  top: 0;
  margin-top: -50%;
  float: left;
  display: block;
  pointer-events: none;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-OutputArea-child {
  padding-top: 6px;
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-OutputArea-prompt {
  width: calc(
    var(--jp-cell-prompt-width) - var(--jp-private-cell-scrolling-output-offset)
  );
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-OutputArea-promptOverlay {
  left: calc(-1 * var(--jp-private-cell-scrolling-output-offset));
}

/*-----------------------------------------------------------------------------
| CodeCell
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| MarkdownCell
|----------------------------------------------------------------------------*/

.jp-MarkdownOutput {
  display: table-cell;
  width: 100%;
  margin-top: 0;
  margin-bottom: 0;
  padding-left: var(--jp-code-padding);
}

.jp-MarkdownOutput.jp-RenderedHTMLCommon {
  overflow: auto;
}

/* collapseHeadingButton (show always if hiddenCellsButton is _not_ shown) */
.jp-collapseHeadingButton {
  display: flex;
  min-height: var(--jp-cell-collapser-min-height);
  font-size: var(--jp-code-font-size);
  position: absolute;
  background-color: transparent;
  background-size: 25px;
  background-repeat: no-repeat;
  background-position-x: center;
  background-position-y: top;
  background-image: var(--jp-icon-caret-down);
  right: 0;
  top: 0;
  bottom: 0;
}

.jp-collapseHeadingButton.jp-mod-collapsed {
  background-image: var(--jp-icon-caret-right);
}

/*
 set the container font size to match that of content
 so that the nested collapse buttons have the right size
*/
.jp-MarkdownCell .jp-InputPrompt {
  font-size: var(--jp-content-font-size1);
}

/*
  Align collapseHeadingButton with cell top header
  The font sizes are identical to the ones in packages/rendermime/style/base.css
*/
.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='1'] {
  font-size: var(--jp-content-font-size5);
  background-position-y: calc(0.3 * var(--jp-content-font-size5));
}

.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='2'] {
  font-size: var(--jp-content-font-size4);
  background-position-y: calc(0.3 * var(--jp-content-font-size4));
}

.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='3'] {
  font-size: var(--jp-content-font-size3);
  background-position-y: calc(0.3 * var(--jp-content-font-size3));
}

.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='4'] {
  font-size: var(--jp-content-font-size2);
  background-position-y: calc(0.3 * var(--jp-content-font-size2));
}

.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='5'] {
  font-size: var(--jp-content-font-size1);
  background-position-y: top;
}

.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='6'] {
  font-size: var(--jp-content-font-size0);
  background-position-y: top;
}

/* collapseHeadingButton (show only on (hover,active) if hiddenCellsButton is shown) */
.jp-Notebook.jp-mod-showHiddenCellsButton .jp-collapseHeadingButton {
  display: none;
}

.jp-Notebook.jp-mod-showHiddenCellsButton
  :is(.jp-MarkdownCell:hover, .jp-mod-active)
  .jp-collapseHeadingButton {
  display: flex;
}

/* showHiddenCellsButton (only show if jp-mod-showHiddenCellsButton is set, which
is a consequence of the showHiddenCellsButton option in Notebook Settings)*/
.jp-Notebook.jp-mod-showHiddenCellsButton .jp-showHiddenCellsButton {
  margin-left: calc(var(--jp-cell-prompt-width) + 2 * var(--jp-code-padding));
  margin-top: var(--jp-code-padding);
  border: 1px solid var(--jp-border-color2);
  background-color: var(--jp-border-color3) !important;
  color: var(--jp-content-font-color0) !important;
  display: flex;
}

.jp-Notebook.jp-mod-showHiddenCellsButton .jp-showHiddenCellsButton:hover {
  background-color: var(--jp-border-color2) !important;
}

.jp-showHiddenCellsButton {
  display: none;
}

/*-----------------------------------------------------------------------------
| Printing
|----------------------------------------------------------------------------*/

/*
Using block instead of flex to allow the use of the break-inside CSS property for
cell outputs.
*/

@media print {
  .jp-Cell-inputWrapper,
  .jp-Cell-outputWrapper {
    display: block;
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

:root {
  --jp-notebook-toolbar-padding: 2px 5px 2px 2px;
}

/*-----------------------------------------------------------------------------

/*-----------------------------------------------------------------------------
| Styles
|----------------------------------------------------------------------------*/

.jp-NotebookPanel-toolbar {
  padding: var(--jp-notebook-toolbar-padding);

  /* disable paint containment from lumino 2.0 default strict CSS containment */
  contain: style size !important;
}

.jp-Toolbar-item.jp-Notebook-toolbarCellType .jp-select-wrapper.jp-mod-focused {
  border: none;
  box-shadow: none;
}

.jp-Notebook-toolbarCellTypeDropdown select {
  height: 24px;
  font-size: var(--jp-ui-font-size1);
  line-height: 14px;
  border-radius: 0;
  display: block;
}

.jp-Notebook-toolbarCellTypeDropdown span {
  top: 5px !important;
}

.jp-Toolbar-responsive-popup {
  position: absolute;
  height: fit-content;
  display: flex;
  flex-direction: row;
  flex-wrap: wrap;
  justify-content: flex-end;
  border-bottom: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  box-shadow: var(--jp-toolbar-box-shadow);
  background: var(--jp-toolbar-background);
  min-height: var(--jp-toolbar-micro-height);
  padding: var(--jp-notebook-toolbar-padding);
  z-index: 1;
  right: 0;
  top: 0;
}

.jp-Toolbar > .jp-Toolbar-responsive-opener {
  margin-left: auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------

/*-----------------------------------------------------------------------------
| Styles
|----------------------------------------------------------------------------*/

.jp-Notebook-ExecutionIndicator {
  position: relative;
  display: inline-block;
  height: 100%;
  z-index: 9997;
}

.jp-Notebook-ExecutionIndicator-tooltip {
  visibility: hidden;
  height: auto;
  width: max-content;
  width: -moz-max-content;
  background-color: var(--jp-layout-color2);
  color: var(--jp-ui-font-color1);
  text-align: justify;
  border-radius: 6px;
  padding: 0 5px;
  position: fixed;
  display: table;
}

.jp-Notebook-ExecutionIndicator-tooltip.up {
  transform: translateX(-50%) translateY(-100%) translateY(-32px);
}

.jp-Notebook-ExecutionIndicator-tooltip.down {
  transform: translateX(calc(-100% + 16px)) translateY(5px);
}

.jp-Notebook-ExecutionIndicator-tooltip.hidden {
  display: none;
}

.jp-Notebook-ExecutionIndicator:hover .jp-Notebook-ExecutionIndicator-tooltip {
  visibility: visible;
}

.jp-Notebook-ExecutionIndicator span {
  font-size: var(--jp-ui-font-size1);
  font-family: var(--jp-ui-font-family);
  color: var(--jp-ui-font-color1);
  line-height: 24px;
  display: block;
}

.jp-Notebook-ExecutionIndicator-progress-bar {
  display: flex;
  justify-content: center;
  height: 100%;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

/*
 * Execution indicator
 */
.jp-tocItem-content::after {
  content: '';

  /* Must be identical to form a circle */
  width: 12px;
  height: 12px;
  background: none;
  border: none;
  position: absolute;
  right: 0;
}

.jp-tocItem-content[data-running='0']::after {
  border-radius: 50%;
  border: var(--jp-border-width) solid var(--jp-inverse-layout-color3);
  background: none;
}

.jp-tocItem-content[data-running='1']::after {
  border-radius: 50%;
  border: var(--jp-border-width) solid var(--jp-inverse-layout-color3);
  background-color: var(--jp-inverse-layout-color3);
}

.jp-tocItem-content[data-running='0'],
.jp-tocItem-content[data-running='1'] {
  margin-right: 12px;
}

/*
 * Copyright (c) Jupyter Development Team.
 * Distributed under the terms of the Modified BSD License.
 */

.jp-Notebook-footer {
  height: 27px;
  margin-left: calc(
    var(--jp-cell-prompt-width) + var(--jp-cell-collapser-width) +
      var(--jp-cell-padding)
  );
  width: calc(
    100% -
      (
        var(--jp-cell-prompt-width) + var(--jp-cell-collapser-width) +
          var(--jp-cell-padding) + var(--jp-cell-padding)
      )
  );
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  color: var(--jp-ui-font-color3);
  margin-top: 6px;
  background: none;
  cursor: pointer;
}

.jp-Notebook-footer:focus {
  border-color: var(--jp-cell-editor-active-border-color);
}

/* For devices that support hovering, hide footer until hover */
@media (hover: hover) {
  .jp-Notebook-footer {
    opacity: 0;
  }

  .jp-Notebook-footer:focus,
  .jp-Notebook-footer:hover {
    opacity: 1;
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Imports
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| CSS variables
|----------------------------------------------------------------------------*/

:root {
  --jp-side-by-side-output-size: 1fr;
  --jp-side-by-side-resized-cell: var(--jp-side-by-side-output-size);
  --jp-private-notebook-dragImage-width: 304px;
  --jp-private-notebook-dragImage-height: 36px;
  --jp-private-notebook-selected-color: var(--md-blue-400);
  --jp-private-notebook-active-color: var(--md-green-400);
}

/*-----------------------------------------------------------------------------
| Notebook
|----------------------------------------------------------------------------*/

/* stylelint-disable selector-max-class */

.jp-NotebookPanel {
  display: block;
  height: 100%;
}

.jp-NotebookPanel.jp-Document {
  min-width: 240px;
  min-height: 120px;
}

.jp-Notebook {
  padding: var(--jp-notebook-padding);
  outline: none;
  overflow: auto;
  background: var(--jp-layout-color0);
}

.jp-Notebook.jp-mod-scrollPastEnd::after {
  display: block;
  content: '';
  min-height: var(--jp-notebook-scroll-padding);
}

.jp-MainAreaWidget-ContainStrict .jp-Notebook * {
  contain: strict;
}

.jp-Notebook .jp-Cell {
  overflow: visible;
}

.jp-Notebook .jp-Cell .jp-InputPrompt {
  cursor: move;
}

/*-----------------------------------------------------------------------------
| Notebook state related styling
|
| The notebook and cells each have states, here are the possibilities:
|
| - Notebook
|   - Command
|   - Edit
| - Cell
|   - None
|   - Active (only one can be active)
|   - Selected (the cells actions are applied to)
|   - Multiselected (when multiple selected, the cursor)
|   - No outputs
|----------------------------------------------------------------------------*/

/* Command or edit modes */

.jp-Notebook .jp-Cell:not(.jp-mod-active) .jp-InputPrompt {
  opacity: var(--jp-cell-prompt-not-active-opacity);
  color: var(--jp-cell-prompt-not-active-font-color);
}

.jp-Notebook .jp-Cell:not(.jp-mod-active) .jp-OutputPrompt {
  opacity: var(--jp-cell-prompt-not-active-opacity);
  color: var(--jp-cell-prompt-not-active-font-color);
}

/* cell is active */
.jp-Notebook .jp-Cell.jp-mod-active .jp-Collapser {
  background: var(--jp-brand-color1);
}

/* cell is dirty */
.jp-Notebook .jp-Cell.jp-mod-dirty .jp-InputPrompt {
  color: var(--jp-warn-color1);
}

.jp-Notebook .jp-Cell.jp-mod-dirty .jp-InputPrompt::before {
  color: var(--jp-warn-color1);
  content: '•';
}

.jp-Notebook .jp-Cell.jp-mod-active.jp-mod-dirty .jp-Collapser {
  background: var(--jp-warn-color1);
}

/* collapser is hovered */
.jp-Notebook .jp-Cell .jp-Collapser:hover {
  box-shadow: var(--jp-elevation-z2);
  background: var(--jp-brand-color1);
  opacity: var(--jp-cell-collapser-not-active-hover-opacity);
}

/* cell is active and collapser is hovered */
.jp-Notebook .jp-Cell.jp-mod-active .jp-Collapser:hover {
  background: var(--jp-brand-color0);
  opacity: 1;
}

/* Command mode */

.jp-Notebook.jp-mod-commandMode .jp-Cell.jp-mod-selected {
  background: var(--jp-notebook-multiselected-color);
}

.jp-Notebook.jp-mod-commandMode
  .jp-Cell.jp-mod-active.jp-mod-selected:not(.jp-mod-multiSelected) {
  background: transparent;
}

/* Edit mode */

.jp-Notebook.jp-mod-editMode .jp-Cell.jp-mod-active .jp-InputArea-editor {
  border: var(--jp-border-width) solid var(--jp-cell-editor-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
  background-color: var(--jp-cell-editor-active-background);
}

/*-----------------------------------------------------------------------------
| Notebook drag and drop
|----------------------------------------------------------------------------*/

.jp-Notebook-cell.jp-mod-dropSource {
  opacity: 0.5;
}

.jp-Notebook-cell.jp-mod-dropTarget,
.jp-Notebook.jp-mod-commandMode
  .jp-Notebook-cell.jp-mod-active.jp-mod-selected.jp-mod-dropTarget {
  border-top-color: var(--jp-private-notebook-selected-color);
  border-top-style: solid;
  border-top-width: 2px;
}

.jp-dragImage {
  display: block;
  flex-direction: row;
  width: var(--jp-private-notebook-dragImage-width);
  height: var(--jp-private-notebook-dragImage-height);
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  background: var(--jp-cell-editor-background);
  overflow: visible;
}

.jp-dragImage-singlePrompt {
  box-shadow: 2px 2px 4px 0 rgba(0, 0, 0, 0.12);
}

.jp-dragImage .jp-dragImage-content {
  flex: 1 1 auto;
  z-index: 2;
  font-size: var(--jp-code-font-size);
  font-family: var(--jp-code-font-family);
  line-height: var(--jp-code-line-height);
  padding: var(--jp-code-padding);
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  background: var(--jp-cell-editor-background-color);
  color: var(--jp-content-font-color3);
  text-align: left;
  margin: 4px 4px 4px 0;
}

.jp-dragImage .jp-dragImage-prompt {
  flex: 0 0 auto;
  min-width: 36px;
  color: var(--jp-cell-inprompt-font-color);
  padding: var(--jp-code-padding);
  padding-left: 12px;
  font-family: var(--jp-cell-prompt-font-family);
  letter-spacing: var(--jp-cell-prompt-letter-spacing);
  line-height: 1.9;
  font-size: var(--jp-code-font-size);
  border: var(--jp-border-width) solid transparent;
}

.jp-dragImage-multipleBack {
  z-index: -1;
  position: absolute;
  height: 32px;
  width: 300px;
  top: 8px;
  left: 8px;
  background: var(--jp-layout-color2);
  border: var(--jp-border-width) solid var(--jp-input-border-color);
  box-shadow: 2px 2px 4px 0 rgba(0, 0, 0, 0.12);
}

/*-----------------------------------------------------------------------------
| Cell toolbar
|----------------------------------------------------------------------------*/

.jp-NotebookTools {
  display: block;
  min-width: var(--jp-sidebar-min-width);
  color: var(--jp-ui-font-color1);
  background: var(--jp-layout-color1);

  /* This is needed so that all font sizing of children done in ems is
    * relative to this base size */
  font-size: var(--jp-ui-font-size1);
  overflow: auto;
}

.jp-ActiveCellTool {
  padding: 12px 0;
  display: flex;
}

.jp-ActiveCellTool-Content {
  flex: 1 1 auto;
}

.jp-ActiveCellTool .jp-ActiveCellTool-CellContent {
  background: var(--jp-cell-editor-background);
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  border-radius: 0;
  min-height: 29px;
}

.jp-ActiveCellTool .jp-InputPrompt {
  min-width: calc(var(--jp-cell-prompt-width) * 0.75);
}

.jp-ActiveCellTool-CellContent > pre {
  padding: 5px 4px;
  margin: 0;
  white-space: normal;
}

.jp-MetadataEditorTool {
  flex-direction: column;
  padding: 12px 0;
}

.jp-RankedPanel > :not(:first-child) {
  margin-top: 12px;
}

.jp-KeySelector select.jp-mod-styled {
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color0);
  border: var(--jp-border-width) solid var(--jp-border-color1);
}

.jp-KeySelector label,
.jp-MetadataEditorTool label,
.jp-NumberSetter label {
  line-height: 1.4;
}

.jp-NotebookTools .jp-select-wrapper {
  margin-top: 4px;
  margin-bottom: 0;
}

.jp-NumberSetter input {
  width: 100%;
  margin-top: 4px;
}

.jp-NotebookTools .jp-Collapse {
  margin-top: 16px;
}

/*-----------------------------------------------------------------------------
| Presentation Mode (.jp-mod-presentationMode)
|----------------------------------------------------------------------------*/

.jp-mod-presentationMode .jp-Notebook {
  --jp-content-font-size1: var(--jp-content-presentation-font-size1);
  --jp-code-font-size: var(--jp-code-presentation-font-size);
}

.jp-mod-presentationMode .jp-Notebook .jp-Cell .jp-InputPrompt,
.jp-mod-presentationMode .jp-Notebook .jp-Cell .jp-OutputPrompt {
  flex: 0 0 110px;
}

/*-----------------------------------------------------------------------------
| Side-by-side Mode (.jp-mod-sideBySide)
|----------------------------------------------------------------------------*/
.jp-mod-sideBySide.jp-Notebook .jp-Notebook-cell {
  margin-top: 3em;
  margin-bottom: 3em;
  margin-left: 5%;
  margin-right: 5%;
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell {
  display: grid;
  grid-template-columns: minmax(0, 1fr) min-content minmax(
      0,
      var(--jp-side-by-side-output-size)
    );
  grid-template-rows: auto minmax(0, 1fr) auto;
  grid-template-areas:
    'header header header'
    'input handle output'
    'footer footer footer';
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell.jp-mod-resizedCell {
  grid-template-columns: minmax(0, 1fr) min-content minmax(
      0,
      var(--jp-side-by-side-resized-cell)
    );
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-CellHeader {
  grid-area: header;
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-Cell-inputWrapper {
  grid-area: input;
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-Cell-outputWrapper {
  /* overwrite the default margin (no vertical separation needed in side by side move */
  margin-top: 0;
  grid-area: output;
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-CellFooter {
  grid-area: footer;
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-CellResizeHandle {
  grid-area: handle;
  user-select: none;
  display: block;
  height: 100%;
  cursor: ew-resize;
  padding: 0 var(--jp-cell-padding);
}

.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-CellResizeHandle::after {
  content: '';
  display: block;
  background: var(--jp-border-color2);
  height: 100%;
  width: 5px;
}

.jp-mod-sideBySide.jp-Notebook
  .jp-CodeCell.jp-mod-resizedCell
  .jp-CellResizeHandle::after {
  background: var(--jp-border-color0);
}

.jp-CellResizeHandle {
  display: none;
}

/*-----------------------------------------------------------------------------
| Placeholder
|----------------------------------------------------------------------------*/

.jp-Cell-Placeholder {
  padding-left: 55px;
}

.jp-Cell-Placeholder-wrapper {
  background: #fff;
  border: 1px solid;
  border-color: #e5e6e9 #dfe0e4 #d0d1d5;
  border-radius: 4px;
  -webkit-border-radius: 4px;
  margin: 10px 15px;
}

.jp-Cell-Placeholder-wrapper-inner {
  padding: 15px;
  position: relative;
}

.jp-Cell-Placeholder-wrapper-body {
  background-repeat: repeat;
  background-size: 50% auto;
}

.jp-Cell-Placeholder-wrapper-body div {
  background: #f6f7f8;
  background-image: -webkit-linear-gradient(
    left,
    #f6f7f8 0%,
    #edeef1 20%,
    #f6f7f8 40%,
    #f6f7f8 100%
  );
  background-repeat: no-repeat;
  background-size: 800px 104px;
  height: 104px;
  position: absolute;
  right: 15px;
  left: 15px;
  top: 15px;
}

div.jp-Cell-Placeholder-h1 {
  top: 20px;
  height: 20px;
  left: 15px;
  width: 150px;
}

div.jp-Cell-Placeholder-h2 {
  left: 15px;
  top: 50px;
  height: 10px;
  width: 100px;
}

div.jp-Cell-Placeholder-content-1,
div.jp-Cell-Placeholder-content-2,
div.jp-Cell-Placeholder-content-3 {
  left: 15px;
  right: 15px;
  height: 10px;
}

div.jp-Cell-Placeholder-content-1 {
  top: 100px;
}

div.jp-Cell-Placeholder-content-2 {
  top: 120px;
}

div.jp-Cell-Placeholder-content-3 {
  top: 140px;
}

</style>
<style type="text/css">
/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*
The following CSS variables define the main, public API for styling JupyterLab.
These variables should be used by all plugins wherever possible. In other
words, plugins should not define custom colors, sizes, etc unless absolutely
necessary. This enables users to change the visual theme of JupyterLab
by changing these variables.

Many variables appear in an ordered sequence (0,1,2,3). These sequences
are designed to work well together, so for example, `--jp-border-color1` should
be used with `--jp-layout-color1`. The numbers have the following meanings:

* 0: super-primary, reserved for special emphasis
* 1: primary, most important under normal situations
* 2: secondary, next most important under normal situations
* 3: tertiary, next most important under normal situations

Throughout JupyterLab, we are mostly following principles from Google's
Material Design when selecting colors. We are not, however, following
all of MD as it is not optimized for dense, information rich UIs.
*/

:root {
  /* Elevation
   *
   * We style box-shadows using Material Design's idea of elevation. These particular numbers are taken from here:
   *
   * https://github.com/material-components/material-components-web
   * https://material-components-web.appspot.com/elevation.html
   */

  --jp-shadow-base-lightness: 0;
  --jp-shadow-umbra-color: rgba(
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    0.2
  );
  --jp-shadow-penumbra-color: rgba(
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    0.14
  );
  --jp-shadow-ambient-color: rgba(
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    0.12
  );
  --jp-elevation-z0: none;
  --jp-elevation-z1: 0 2px 1px -1px var(--jp-shadow-umbra-color),
    0 1px 1px 0 var(--jp-shadow-penumbra-color),
    0 1px 3px 0 var(--jp-shadow-ambient-color);
  --jp-elevation-z2: 0 3px 1px -2px var(--jp-shadow-umbra-color),
    0 2px 2px 0 var(--jp-shadow-penumbra-color),
    0 1px 5px 0 var(--jp-shadow-ambient-color);
  --jp-elevation-z4: 0 2px 4px -1px var(--jp-shadow-umbra-color),
    0 4px 5px 0 var(--jp-shadow-penumbra-color),
    0 1px 10px 0 var(--jp-shadow-ambient-color);
  --jp-elevation-z6: 0 3px 5px -1px var(--jp-shadow-umbra-color),
    0 6px 10px 0 var(--jp-shadow-penumbra-color),
    0 1px 18px 0 var(--jp-shadow-ambient-color);
  --jp-elevation-z8: 0 5px 5px -3px var(--jp-shadow-umbra-color),
    0 8px 10px 1px var(--jp-shadow-penumbra-color),
    0 3px 14px 2px var(--jp-shadow-ambient-color);
  --jp-elevation-z12: 0 7px 8px -4px var(--jp-shadow-umbra-color),
    0 12px 17px 2px var(--jp-shadow-penumbra-color),
    0 5px 22px 4px var(--jp-shadow-ambient-color);
  --jp-elevation-z16: 0 8px 10px -5px var(--jp-shadow-umbra-color),
    0 16px 24px 2px var(--jp-shadow-penumbra-color),
    0 6px 30px 5px var(--jp-shadow-ambient-color);
  --jp-elevation-z20: 0 10px 13px -6px var(--jp-shadow-umbra-color),
    0 20px 31px 3px var(--jp-shadow-penumbra-color),
    0 8px 38px 7px var(--jp-shadow-ambient-color);
  --jp-elevation-z24: 0 11px 15px -7px var(--jp-shadow-umbra-color),
    0 24px 38px 3px var(--jp-shadow-penumbra-color),
    0 9px 46px 8px var(--jp-shadow-ambient-color);

  /* Borders
   *
   * The following variables, specify the visual styling of borders in JupyterLab.
   */

  --jp-border-width: 1px;
  --jp-border-color0: var(--md-grey-400);
  --jp-border-color1: var(--md-grey-400);
  --jp-border-color2: var(--md-grey-300);
  --jp-border-color3: var(--md-grey-200);
  --jp-inverse-border-color: var(--md-grey-600);
  --jp-border-radius: 2px;

  /* UI Fonts
   *
   * The UI font CSS variables are used for the typography all of the JupyterLab
   * user interface elements that are not directly user generated content.
   *
   * The font sizing here is done assuming that the body font size of --jp-ui-font-size1
   * is applied to a parent element. When children elements, such as headings, are sized
   * in em all things will be computed relative to that body size.
   */

  --jp-ui-font-scale-factor: 1.2;
  --jp-ui-font-size0: 0.83333em;
  --jp-ui-font-size1: 13px; /* Base font size */
  --jp-ui-font-size2: 1.2em;
  --jp-ui-font-size3: 1.44em;
  --jp-ui-font-family: system-ui, -apple-system, blinkmacsystemfont, 'Segoe UI',
    helvetica, arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji',
    'Segoe UI Symbol';

  /*
   * Use these font colors against the corresponding main layout colors.
   * In a light theme, these go from dark to light.
   */

  /* Defaults use Material Design specification */
  --jp-ui-font-color0: rgba(0, 0, 0, 1);
  --jp-ui-font-color1: rgba(0, 0, 0, 0.87);
  --jp-ui-font-color2: rgba(0, 0, 0, 0.54);
  --jp-ui-font-color3: rgba(0, 0, 0, 0.38);

  /*
   * Use these against the brand/accent/warn/error colors.
   * These will typically go from light to darker, in both a dark and light theme.
   */

  --jp-ui-inverse-font-color0: rgba(255, 255, 255, 1);
  --jp-ui-inverse-font-color1: rgba(255, 255, 255, 1);
  --jp-ui-inverse-font-color2: rgba(255, 255, 255, 0.7);
  --jp-ui-inverse-font-color3: rgba(255, 255, 255, 0.5);

  /* Content Fonts
   *
   * Content font variables are used for typography of user generated content.
   *
   * The font sizing here is done assuming that the body font size of --jp-content-font-size1
   * is applied to a parent element. When children elements, such as headings, are sized
   * in em all things will be computed relative to that body size.
   */

  --jp-content-line-height: 1.6;
  --jp-content-font-scale-factor: 1.2;
  --jp-content-font-size0: 0.83333em;
  --jp-content-font-size1: 14px; /* Base font size */
  --jp-content-font-size2: 1.2em;
  --jp-content-font-size3: 1.44em;
  --jp-content-font-size4: 1.728em;
  --jp-content-font-size5: 2.0736em;

  /* This gives a magnification of about 125% in presentation mode over normal. */
  --jp-content-presentation-font-size1: 17px;
  --jp-content-heading-line-height: 1;
  --jp-content-heading-margin-top: 1.2em;
  --jp-content-heading-margin-bottom: 0.8em;
  --jp-content-heading-font-weight: 500;

  /* Defaults use Material Design specification */
  --jp-content-font-color0: rgba(0, 0, 0, 1);
  --jp-content-font-color1: rgba(0, 0, 0, 0.87);
  --jp-content-font-color2: rgba(0, 0, 0, 0.54);
  --jp-content-font-color3: rgba(0, 0, 0, 0.38);
  --jp-content-link-color: var(--md-blue-900);
  --jp-content-font-family: system-ui, -apple-system, blinkmacsystemfont,
    'Segoe UI', helvetica, arial, sans-serif, 'Apple Color Emoji',
    'Segoe UI Emoji', 'Segoe UI Symbol';

  /*
   * Code Fonts
   *
   * Code font variables are used for typography of code and other monospaces content.
   */

  --jp-code-font-size: 13px;
  --jp-code-line-height: 1.3077; /* 17px for 13px base */
  --jp-code-padding: 5px; /* 5px for 13px base, codemirror highlighting needs integer px value */
  --jp-code-font-family-default: menlo, consolas, 'DejaVu Sans Mono', monospace;
  --jp-code-font-family: var(--jp-code-font-family-default);

  /* This gives a magnification of about 125% in presentation mode over normal. */
  --jp-code-presentation-font-size: 16px;

  /* may need to tweak cursor width if you change font size */
  --jp-code-cursor-width0: 1.4px;
  --jp-code-cursor-width1: 2px;
  --jp-code-cursor-width2: 4px;

  /* Layout
   *
   * The following are the main layout colors use in JupyterLab. In a light
   * theme these would go from light to dark.
   */

  --jp-layout-color0: white;
  --jp-layout-color1: white;
  --jp-layout-color2: var(--md-grey-200);
  --jp-layout-color3: var(--md-grey-400);
  --jp-layout-color4: var(--md-grey-600);

  /* Inverse Layout
   *
   * The following are the inverse layout colors use in JupyterLab. In a light
   * theme these would go from dark to light.
   */

  --jp-inverse-layout-color0: #111;
  --jp-inverse-layout-color1: var(--md-grey-900);
  --jp-inverse-layout-color2: var(--md-grey-800);
  --jp-inverse-layout-color3: var(--md-grey-700);
  --jp-inverse-layout-color4: var(--md-grey-600);

  /* Brand/accent */

  --jp-brand-color0: var(--md-blue-900);
  --jp-brand-color1: var(--md-blue-700);
  --jp-brand-color2: var(--md-blue-300);
  --jp-brand-color3: var(--md-blue-100);
  --jp-brand-color4: var(--md-blue-50);
  --jp-accent-color0: var(--md-green-900);
  --jp-accent-color1: var(--md-green-700);
  --jp-accent-color2: var(--md-green-300);
  --jp-accent-color3: var(--md-green-100);

  /* State colors (warn, error, success, info) */

  --jp-warn-color0: var(--md-orange-900);
  --jp-warn-color1: var(--md-orange-700);
  --jp-warn-color2: var(--md-orange-300);
  --jp-warn-color3: var(--md-orange-100);
  --jp-error-color0: var(--md-red-900);
  --jp-error-color1: var(--md-red-700);
  --jp-error-color2: var(--md-red-300);
  --jp-error-color3: var(--md-red-100);
  --jp-success-color0: var(--md-green-900);
  --jp-success-color1: var(--md-green-700);
  --jp-success-color2: var(--md-green-300);
  --jp-success-color3: var(--md-green-100);
  --jp-info-color0: var(--md-cyan-900);
  --jp-info-color1: var(--md-cyan-700);
  --jp-info-color2: var(--md-cyan-300);
  --jp-info-color3: var(--md-cyan-100);

  /* Cell specific styles */

  --jp-cell-padding: 5px;
  --jp-cell-collapser-width: 8px;
  --jp-cell-collapser-min-height: 20px;
  --jp-cell-collapser-not-active-hover-opacity: 0.6;
  --jp-cell-editor-background: var(--md-grey-100);
  --jp-cell-editor-border-color: var(--md-grey-300);
  --jp-cell-editor-box-shadow: inset 0 0 2px var(--md-blue-300);
  --jp-cell-editor-active-background: var(--jp-layout-color0);
  --jp-cell-editor-active-border-color: var(--jp-brand-color1);
  --jp-cell-prompt-width: 64px;
  --jp-cell-prompt-font-family: var(--jp-code-font-family-default);
  --jp-cell-prompt-letter-spacing: 0;
  --jp-cell-prompt-opacity: 1;
  --jp-cell-prompt-not-active-opacity: 0.5;
  --jp-cell-prompt-not-active-font-color: var(--md-grey-700);

  /* A custom blend of MD grey and blue 600
   * See https://meyerweb.com/eric/tools/color-blend/#546E7A:1E88E5:5:hex */
  --jp-cell-inprompt-font-color: #307fc1;

  /* A custom blend of MD grey and orange 600
   * https://meyerweb.com/eric/tools/color-blend/#546E7A:F4511E:5:hex */
  --jp-cell-outprompt-font-color: #bf5b3d;

  /* Notebook specific styles */

  --jp-notebook-padding: 10px;
  --jp-notebook-select-background: var(--jp-layout-color1);
  --jp-notebook-multiselected-color: var(--md-blue-50);

  /* The scroll padding is calculated to fill enough space at the bottom of the
  notebook to show one single-line cell (with appropriate padding) at the top
  when the notebook is scrolled all the way to the bottom. We also subtract one
  pixel so that no scrollbar appears if we have just one single-line cell in the
  notebook. This padding is to enable a 'scroll past end' feature in a notebook.
  */
  --jp-notebook-scroll-padding: calc(
    100% - var(--jp-code-font-size) * var(--jp-code-line-height) -
      var(--jp-code-padding) - var(--jp-cell-padding) - 1px
  );

  /* Rendermime styles */

  --jp-rendermime-error-background: #fdd;
  --jp-rendermime-table-row-background: var(--md-grey-100);
  --jp-rendermime-table-row-hover-background: var(--md-light-blue-50);

  /* Dialog specific styles */

  --jp-dialog-background: rgba(0, 0, 0, 0.25);

  /* Console specific styles */

  --jp-console-padding: 10px;

  /* Toolbar specific styles */

  --jp-toolbar-border-color: var(--jp-border-color1);
  --jp-toolbar-micro-height: 8px;
  --jp-toolbar-background: var(--jp-layout-color1);
  --jp-toolbar-box-shadow: 0 0 2px 0 rgba(0, 0, 0, 0.24);
  --jp-toolbar-header-margin: 4px 4px 0 4px;
  --jp-toolbar-active-background: var(--md-grey-300);

  /* Statusbar specific styles */

  --jp-statusbar-height: 24px;

  /* Input field styles */

  --jp-input-box-shadow: inset 0 0 2px var(--md-blue-300);
  --jp-input-active-background: var(--jp-layout-color1);
  --jp-input-hover-background: var(--jp-layout-color1);
  --jp-input-background: var(--md-grey-100);
  --jp-input-border-color: var(--jp-inverse-border-color);
  --jp-input-active-border-color: var(--jp-brand-color1);
  --jp-input-active-box-shadow-color: rgba(19, 124, 189, 0.3);

  /* General editor styles */

  --jp-editor-selected-background: #d9d9d9;
  --jp-editor-selected-focused-background: #d7d4f0;
  --jp-editor-cursor-color: var(--jp-ui-font-color0);

  /* Code mirror specific styles */

  --jp-mirror-editor-keyword-color: #008000;
  --jp-mirror-editor-atom-color: #88f;
  --jp-mirror-editor-number-color: #080;
  --jp-mirror-editor-def-color: #00f;
  --jp-mirror-editor-variable-color: var(--md-grey-900);
  --jp-mirror-editor-variable-2-color: rgb(0, 54, 109);
  --jp-mirror-editor-variable-3-color: #085;
  --jp-mirror-editor-punctuation-color: #05a;
  --jp-mirror-editor-property-color: #05a;
  --jp-mirror-editor-operator-color: #a2f;
  --jp-mirror-editor-comment-color: #408080;
  --jp-mirror-editor-string-color: #ba2121;
  --jp-mirror-editor-string-2-color: #708;
  --jp-mirror-editor-meta-color: #a2f;
  --jp-mirror-editor-qualifier-color: #555;
  --jp-mirror-editor-builtin-color: #008000;
  --jp-mirror-editor-bracket-color: #997;
  --jp-mirror-editor-tag-color: #170;
  --jp-mirror-editor-attribute-color: #00c;
  --jp-mirror-editor-header-color: blue;
  --jp-mirror-editor-quote-color: #090;
  --jp-mirror-editor-link-color: #00c;
  --jp-mirror-editor-error-color: #f00;
  --jp-mirror-editor-hr-color: #999;

  /*
    RTC user specific colors.
    These colors are used for the cursor, username in the editor,
    and the icon of the user.
  */

  --jp-collaborator-color1: #ffad8e;
  --jp-collaborator-color2: #dac83d;
  --jp-collaborator-color3: #72dd76;
  --jp-collaborator-color4: #00e4d0;
  --jp-collaborator-color5: #45d4ff;
  --jp-collaborator-color6: #e2b1ff;
  --jp-collaborator-color7: #ff9de6;

  /* Vega extension styles */

  --jp-vega-background: white;

  /* Sidebar-related styles */

  --jp-sidebar-min-width: 250px;

  /* Search-related styles */

  --jp-search-toggle-off-opacity: 0.5;
  --jp-search-toggle-hover-opacity: 0.8;
  --jp-search-toggle-on-opacity: 1;
  --jp-search-selected-match-background-color: rgb(245, 200, 0);
  --jp-search-selected-match-color: black;
  --jp-search-unselected-match-background-color: var(
    --jp-inverse-layout-color0
  );
  --jp-search-unselected-match-color: var(--jp-ui-inverse-font-color0);

  /* Icon colors that work well with light or dark backgrounds */
  --jp-icon-contrast-color0: var(--md-purple-600);
  --jp-icon-contrast-color1: var(--md-green-600);
  --jp-icon-contrast-color2: var(--md-pink-600);
  --jp-icon-contrast-color3: var(--md-blue-600);

  /* Button colors */
  --jp-accept-color-normal: var(--md-blue-700);
  --jp-accept-color-hover: var(--md-blue-800);
  --jp-accept-color-active: var(--md-blue-900);
  --jp-warn-color-normal: var(--md-red-700);
  --jp-warn-color-hover: var(--md-red-800);
  --jp-warn-color-active: var(--md-red-900);
  --jp-reject-color-normal: var(--md-grey-600);
  --jp-reject-color-hover: var(--md-grey-700);
  --jp-reject-color-active: var(--md-grey-800);

  /* File or activity icons and switch semantic variables */
  --jp-jupyter-icon-color: #f37626;
  --jp-notebook-icon-color: #f37626;
  --jp-json-icon-color: var(--md-orange-700);
  --jp-console-icon-background-color: var(--md-blue-700);
  --jp-console-icon-color: white;
  --jp-terminal-icon-background-color: var(--md-grey-800);
  --jp-terminal-icon-color: var(--md-grey-200);
  --jp-text-editor-icon-color: var(--md-grey-700);
  --jp-inspector-icon-color: var(--md-grey-700);
  --jp-switch-color: var(--md-grey-400);
  --jp-switch-true-position-color: var(--md-orange-900);
}
</style>
<style type="text/css">
/* Force rendering true colors when outputing to pdf */
* {
  -webkit-print-color-adjust: exact;
}

/* Misc */
a.anchor-link {
  display: none;
}

/* Input area styling */
.jp-InputArea {
  overflow: hidden;
}

.jp-InputArea-editor {
  overflow: hidden;
}

.cm-editor.cm-s-jupyter .highlight pre {
/* weird, but --jp-code-padding defined to be 5px but 4px horizontal padding is hardcoded for pre.cm-line */
  padding: var(--jp-code-padding) 4px;
  margin: 0;

  font-family: inherit;
  font-size: inherit;
  line-height: inherit;
  color: inherit;

}

.jp-OutputArea-output pre {
  line-height: inherit;
  font-family: inherit;
}

.jp-RenderedText pre {
  color: var(--jp-content-font-color1);
  font-size: var(--jp-code-font-size);
}

/* Hiding the collapser by default */
.jp-Collapser {
  display: none;
}

@page {
    margin: 0.5in; /* Margin for each printed piece of paper */
}

@media print {
  .jp-Cell-inputWrapper,
  .jp-Cell-outputWrapper {
    display: block;
  }
}
</style>
<!-- Load mathjax -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS_CHTML-full,Safe"> </script>
<!-- MathJax configuration -->
<script type="text/x-mathjax-config">
    init_mathjax = function() {
        if (window.MathJax) {
        // MathJax loaded
            MathJax.Hub.Config({
                TeX: {
                    equationNumbers: {
                    autoNumber: "AMS",
                    useLabelIds: true
                    }
                },
                tex2jax: {
                    inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                    displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                    processEscapes: true,
                    processEnvironments: true
                },
                displayAlign: 'center',
                messageStyle: 'none',
                CommonHTML: {
                    linebreaks: {
                    automatic: true
                    }
                }
            });

            MathJax.Hub.Queue(["Typeset", MathJax.Hub]);
        }
    }
    init_mathjax();
    </script>
<!-- End of mathjax configuration --><script type="module">
  document.addEventListener("DOMContentLoaded", async () => {
    const diagrams = document.querySelectorAll(".jp-Mermaid > pre.mermaid");
    // do not load mermaidjs if not needed
    if (!diagrams.length) {
      return;
    }
    const mermaid = (await import("https://cdnjs.cloudflare.com/ajax/libs/mermaid/10.7.0/mermaid.esm.min.mjs")).default;
    const parser = new DOMParser();

    mermaid.initialize({
      maxTextSize: 100000,
      maxEdges: 100000,
      startOnLoad: false,
      fontFamily: window
        .getComputedStyle(document.body)
        .getPropertyValue("--jp-ui-font-family"),
      theme: document.querySelector("body[data-jp-theme-light='true']")
        ? "default"
        : "dark",
    });

    let _nextMermaidId = 0;

    function makeMermaidImage(svg) {
      const img = document.createElement("img");
      const doc = parser.parseFromString(svg, "image/svg+xml");
      const svgEl = doc.querySelector("svg");
      const { maxWidth } = svgEl?.style || {};
      const firstTitle = doc.querySelector("title");
      const firstDesc = doc.querySelector("desc");

      img.setAttribute("src", `data:image/svg+xml,${encodeURIComponent(svg)}`);
      if (maxWidth) {
        img.width = parseInt(maxWidth);
      }
      if (firstTitle) {
        img.setAttribute("alt", firstTitle.textContent);
      }
      if (firstDesc) {
        const caption = document.createElement("figcaption");
        caption.className = "sr-only";
        caption.textContent = firstDesc.textContent;
        return [img, caption];
      }
      return [img];
    }

    async function makeMermaidError(text) {
      let errorMessage = "";
      try {
        await mermaid.parse(text);
      } catch (err) {
        errorMessage = `${err}`;
      }

      const result = document.createElement("details");
      result.className = 'jp-RenderedMermaid-Details';
      const summary = document.createElement("summary");
      summary.className = 'jp-RenderedMermaid-Summary';
      const pre = document.createElement("pre");
      const code = document.createElement("code");
      code.innerText = text;
      pre.appendChild(code);
      summary.appendChild(pre);
      result.appendChild(summary);

      const warning = document.createElement("pre");
      warning.innerText = errorMessage;
      result.appendChild(warning);
      return [result];
    }

    async function renderOneMarmaid(src) {
      const id = `jp-mermaid-${_nextMermaidId++}`;
      const parent = src.parentNode;
      let raw = src.textContent.trim();
      const el = document.createElement("div");
      el.style.visibility = "hidden";
      document.body.appendChild(el);
      let results = null;
      let output = null;
      try {
        let { svg } = await mermaid.render(id, raw, el);
        svg = cleanMermaidSvg(svg);
        results = makeMermaidImage(svg);
        output = document.createElement("figure");
        results.map(output.appendChild, output);
      } catch (err) {
        parent.classList.add("jp-mod-warning");
        results = await makeMermaidError(raw);
        output = results[0];
      } finally {
        el.remove();
      }
      parent.classList.add("jp-RenderedMermaid");
      parent.appendChild(output);
    }


    /**
     * Post-process to ensure mermaid diagrams contain only valid SVG and XHTML.
     */
    function cleanMermaidSvg(svg) {
      return svg.replace(RE_VOID_ELEMENT, replaceVoidElement);
    }


    /**
     * A regular expression for all void elements, which may include attributes and
     * a slash.
     *
     * @see https://developer.mozilla.org/en-US/docs/Glossary/Void_element
     *
     * Of these, only `<br>` is generated by Mermaid in place of `\n`,
     * but _any_ "malformed" tag will break the SVG rendering entirely.
     */
    const RE_VOID_ELEMENT =
      /<\s*(area|base|br|col|embed|hr|img|input|link|meta|param|source|track|wbr)\s*([^>]*?)\s*>/gi;

    /**
     * Ensure a void element is closed with a slash, preserving any attributes.
     */
    function replaceVoidElement(match, tag, rest) {
      rest = rest.trim();
      if (!rest.endsWith('/')) {
        rest = `${rest} /`;
      }
      return `<${tag} ${rest}>`;
    }

    void Promise.all([...diagrams].map(renderOneMarmaid));
  });
</script>
<style>
  .jp-Mermaid:not(.jp-RenderedMermaid) {
    display: none;
  }

  .jp-RenderedMermaid {
    overflow: auto;
    display: flex;
  }

  .jp-RenderedMermaid.jp-mod-warning {
    width: auto;
    padding: 0.5em;
    margin-top: 0.5em;
    border: var(--jp-border-width) solid var(--jp-warn-color2);
    border-radius: var(--jp-border-radius);
    color: var(--jp-ui-font-color1);
    font-size: var(--jp-ui-font-size1);
    white-space: pre-wrap;
    word-wrap: break-word;
  }

  .jp-RenderedMermaid figure {
    margin: 0;
    overflow: auto;
    max-width: 100%;
  }

  .jp-RenderedMermaid img {
    max-width: 100%;
  }

  .jp-RenderedMermaid-Details > pre {
    margin-top: 1em;
  }

  .jp-RenderedMermaid-Summary {
    color: var(--jp-warn-color2);
  }

  .jp-RenderedMermaid:not(.jp-mod-warning) pre {
    display: none;
  }

  .jp-RenderedMermaid-Summary > pre {
    display: inline-block;
    white-space: normal;
  }
</style>
<!-- End of mermaid configuration --></head>
<body class="jp-Notebook" data-jp-theme-light="true" data-jp-theme-name="JupyterLab Light">
<main>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h1 id="Extra-Assignment:-Transformers-and-SSMs">Extra Assignment: Transformers and SSMs<a class="anchor-link" href="#Extra-Assignment:-Transformers-and-SSMs">¶</a></h1><p>Connor Blake, 5/23/25</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [20]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">Dataset</span><span class="p">,</span> <span class="n">DataLoader</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.optim</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">optim</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.nn.utils.rnn</span><span class="w"> </span><span class="kn">import</span> <span class="n">pad_sequence</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tokenizers</span><span class="w"> </span><span class="kn">import</span> <span class="n">Tokenizer</span><span class="p">,</span> <span class="n">models</span><span class="p">,</span> <span class="n">pre_tokenizers</span><span class="p">,</span> <span class="n">trainers</span><span class="p">,</span> <span class="n">processors</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">optax</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">rdkit</span><span class="w"> </span><span class="kn">import</span> <span class="n">Chem</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">rdkit.Chem</span><span class="w"> </span><span class="kn">import</span> <span class="n">Draw</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>Is this assignment too long? If you are using AI tools to the maximum extent, not at all. If the internet goes down? Yes.</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="Problem-1:-Transfomer">Problem 1: Transfomer<a class="anchor-link" href="#Problem-1:-Transfomer">¶</a></h2><p>Explain, in as much detail as possible, how a Transformer works from the paper <a href="https://arxiv.org/pdf/1706.03762">Attention is All You Need</a>. Be explicit in the use of function signatures, tensor dimensionalities, function definitions.</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="Answer-1:">Answer 1:<a class="anchor-link" href="#Answer-1:">¶</a></h2>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="1%E2%80%82Notation-and-Shapes">1 Notation and Shapes<a class="anchor-link" href="#1%E2%80%82Notation-and-Shapes">¶</a></h3><ul>
<li>B — batch size</li>
<li>T — source-sequence length</li>
<li>T′ — target-sequence length</li>
<li>H — number of attention heads</li>
<li>$d_{\text{model}}$ — model width</li>
<li>$d_k = d_{\text{model}} ⁄ H$ — key/query sub-dimension</li>
<li>$d_v = d_{\text{model}} ⁄ H$ — value sub-dimension</li>
<li>$d_{FF} ≈ 4 d_{\text{model}}$ — hidden width of the feed-forward layer</li>
</ul>
<p>Indices</p>
<ul>
<li>b ∈ {0,…,B−1} — sequence in batch</li>
<li>t ∈ {0,…,T−1} — source token position</li>
<li>t′ ∈ {0,…,T′−1} — target token position</li>
<li>h ∈ {0,…,H−1} — head index</li>
<li>m ∈ {0,…,d_{\text{model}}−1} — model feature</li>
<li>i ∈ {0,…,d_k−1} — key/query feature</li>
<li>j ∈ {0,…,d_v−1} — value feature</li>
<li>r ∈ {0,…,$d_{\text{FF}}$}-1$ — feed-forward feature</li>
</ul>
<p>A tensor element $X_{b t m}$ contains feature $m$ of token $t$ in sequence $b$.</p>
<h3 id="2%E2%80%82Primitive-Operations">2 Primitive Operations<a class="anchor-link" href="#2%E2%80%82Primitive-Operations">¶</a></h3><h4 id="2.1%E2%80%82Softmax">2.1 Softmax<a class="anchor-link" href="#2.1%E2%80%82Softmax">¶</a></h4><p>$$
\text{softmax}(Z)_{b n} = \frac{e^{Z_{b n}}}{\sum_{n′} e^{Z_{b n′}}}, \quad
Z \in \mathbb R^{B \times N}.
$$</p>
<h4 id="2.2%E2%80%82Layer-Normalization">2.2 Layer Normalization<a class="anchor-link" href="#2.2%E2%80%82Layer-Normalization">¶</a></h4><p>Given $X_{b t m} ∈ ℝ^{B×T×d}  $</p>
<p>$$
\mu_{b t} = \frac{1}{d} \sum_{m} X_{b t m}, \qquad
\sigma_{b t} = \sqrt{\frac{1}{d} \sum_{m} (X_{b t m} - \mu_{b t})^{2} + \varepsilon},
$$
$$
\text{LayerNorm}(X)_{b t m} =
\frac{X_{b t m} - \mu_{b t}}{\sigma_{b t}} \, \gamma_{m} + \beta_{m},
$$</p>
<p>with learned gain $γ_{m}$ and bias $β_{m}$.</p>
<h3 id="3%E2%80%82Scaled-Dot-Product-Attention">3 Scaled Dot-Product Attention<a class="anchor-link" href="#3%E2%80%82Scaled-Dot-Product-Attention">¶</a></h3><h4 id="3.1%E2%80%82Linear-projections">3.1 Linear projections<a class="anchor-link" href="#3.1%E2%80%82Linear-projections">¶</a></h4><p>Learn weight matrices</p>
<ul>
<li>$W^{Q}_{m i} ∈ ℝ^{d_{\text{model}}×d_k}$</li>
<li>$W^{K}_{m i} ∈ ℝ^{d_{\text{model}}×d_k}  $</li>
<li>$W^{V}_{m j} ∈ ℝ^{d_{\text{model}}×d_v}$</li>
</ul>
<p>and form</p>
<p>$$
Q_{b t i} = X_{b t m} \, W^{Q}_{m i}, \quad
K_{b t i} = X_{b t m} \, W^{K}_{m i}, \quad
V_{b t j} = X_{b t m} \, W^{V}_{m j}.
$$</p>
<p>Split the last index into H heads:<br/>
$Q_{b t h i}, K_{b t h i} ∈ ℝ^{B×T×H×d_k}; V_{b t h j} ∈ ℝ^{B×T×H×d_v}$.</p>
<h4 id="3.2%E2%80%82Attention-kernel-and-weights">3.2 Attention kernel and weights<a class="anchor-link" href="#3.2%E2%80%82Attention-kernel-and-weights">¶</a></h4><p>$$
S_{b h t_q t_k} = \frac{1}{\sqrt{d_k}}
\, Q_{b t_q h i} \, K_{b t_k h i}.
$$</p>
<p>For decoder self-attention, entries with $t_k &gt; t_q$ are set to $-\infty$.</p>
<p>$$
\alpha_{b h t_q t_k} = \text{softmax}_{t_k} \bigl( S_{b h t_q t_k} \bigr).
$$</p>
<h4 id="3.3%E2%80%82Head-output-and-combination">3.3 Head output and combination<a class="anchor-link" href="#3.3%E2%80%82Head-output-and-combination">¶</a></h4><p>$$
Z_{b t_q h j} = \alpha_{b h t_q t_k} \, V_{b t_k h j}.
$$</p>
<p>Concatenate heads as $Z_{b t n}$ with $n = h d_v + j$ and project</p>
<p>$$
\tilde Z_{b t m} = Z_{b t n} \, W^{O}_{n m},
\qquad W^{O} \in \mathbb R^{H d_v \times d_{\text{model}}}.
$$</p>
<h3 id="4%E2%80%82Position-wise-Feed-Forward-Network">4 Position-wise Feed-Forward Network<a class="anchor-link" href="#4%E2%80%82Position-wise-Feed-Forward-Network">¶</a></h3><p>$$
\tilde X_{b t r} = \max \bigl( 0, \, X_{b t m} W^{(1)}_{m r} + b^{(1)}_{r} \bigr),
$$
$$
Y_{b t m} = \tilde X_{b t r} \, W^{(2)}_{r m} + b^{(2)}_{m},
\qquad
W^{(1)} \in \mathbb R^{d_{\text{model}} \times d_{ff}},
\; W^{(2)} \in \mathbb R^{d_{ff} \times d_{\text{model}}}.
$$</p>
<h3 id="5%E2%80%82Positional-Encoding">5 Positional Encoding<a class="anchor-link" href="#5%E2%80%82Positional-Encoding">¶</a></h3><p>For position $t$ and feature $m$,</p>
<p>$$
\text{PE}_{t m} =
\begin{cases}
\sin \bigl( t / 10000^{\,2m / d_{\text{model}}} \bigr) &amp; m \text{ even}, \\[6pt]
\cos \bigl( t / 10000^{\,2m / d_{\text{model}}} \bigr) &amp; m \text{ odd}.
\end{cases}
$$</p>
<p>Add $PE_{t m}$ to token embeddings $E_{t m}$.</p>
<h3 id="6%E2%80%82Encoder-Layer">6 Encoder Layer<a class="anchor-link" href="#6%E2%80%82Encoder-Layer">¶</a></h3><p>With input $X^{(l)}_{b t m}$</p>
<ol>
<li>Multi-head self-attention<br/>
$$ \hat Z_{b t m} = \text{MHA} \bigl( \text{LayerNorm}(X^{(l)}) \bigr)_{b t m}. $$</li>
<li>Residual add $Z_{b t m} = X^{(l)}_{b t m} + \hat Z_{b t m}$.</li>
<li>Feed-forward<br/>
$$ \hat Y_{b t m} = \text{FFN} \bigl( \text{LayerNorm}(Z) \bigr)_{b t m}. $$</li>
<li>Residual add $X^{(l+1)}_{b t m} = Z_{b t m} + \hat Y_{b t m}$.</li>
</ol>
<p>Repeat for $l = 0,…,L_E−1$; final output is memory $M_{b t m}$.</p>
<h3 id="7%E2%80%82Decoder-Layer">7 Decoder Layer<a class="anchor-link" href="#7%E2%80%82Decoder-Layer">¶</a></h3><p>With decoder input $Y^{(l)}_{b t′ m}$ and memory $M_{b t m}$</p>
<ol>
<li>Masked self-attention<br/>
$$ \hat U = \text{MHA}_{\text{masked}} \bigl( \text{LayerNorm}(Y^{(l)}) \bigr). $$</li>
<li>$U = Y^{(l)} + \hat U$.</li>
<li>Cross-attention<br/>
$$ \hat V = \text{MHA} \bigl( Q = \text{LayerNorm}(U),\, K = M,\, V = M \bigr). $$</li>
<li>$V = U + \hat V$.</li>
<li>Feed-forward<br/>
$$ \hat Y = \text{FFN} \bigl( \text{LayerNorm}(V) \bigr). $$</li>
<li>$Y^{(l+1)} = V + \hat Y$.</li>
</ol>
<p>Repeat for $l = 0,\ldots,L_D−1$.</p>
<h3 id="8%E2%80%82End-to-End-Forward-Pass">8 End-to-End Forward Pass<a class="anchor-link" href="#8%E2%80%82End-to-End-Forward-Pass">¶</a></h3><ol>
<li>Encode the source to obtain memory $M_{b t m}$.</li>
<li>Decode shifted-right targets with causal masking while attending to $M_{b t m}$.</li>
<li>Project decoder states with $W^{\text{vocab}}_{m v}$ and apply softmax to obtain<br/>
$$ p(y_{t′} \mid y_{&lt;t′}, x). $$</li>
</ol>
<h3 id="9%E2%80%82Training-Objective">9 Training Objective<a class="anchor-link" href="#9%E2%80%82Training-Objective">¶</a></h3><p>$$
\mathcal L = -\sum_{b,\,t′} \log p \bigl( y_{t′}^{(b)} \mid y_{&lt;t′}^{(b)},\, x^{(b)} \bigr),
$$</p>
<p>minimised with Adam using learning-rate warm-up and inverse-square-root decay.</p>
<h3 id="10%E2%80%82Parameter-and-Complexity-Summary">10 Parameter and Complexity Summary<a class="anchor-link" href="#10%E2%80%82Parameter-and-Complexity-Summary">¶</a></h3><table>
<thead>
<tr>
<th>sub-unit</th>
<th>parameters</th>
<th>time per layer</th>
<th>space per layer</th>
</tr>
</thead>
<tbody>
<tr>
<td>multi-head attention</td>
<td>$3 d_{\text{model}} d_k H + d_{\text{model}} d_v H$</td>
<td>$O(B T^{2} d_k)$</td>
<td>$O(B T d_{\text{model}})$</td>
</tr>
<tr>
<td>feed-forward</td>
<td>$2 d_{\text{model}} d_{\text{FF}}$</td>
<td>$O(B T d_{\text{FF}})$</td>
<td>$O(B T d_{\text{FF}})$</td>
</tr>
<tr>
<td>layer norm</td>
<td>$2 d_{\text{model}}$</td>
<td>negligible</td>
<td>negligible</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="Problem-2:-ChemBERTa">Problem 2: ChemBERTa<a class="anchor-link" href="#Problem-2:-ChemBERTa">¶</a></h2>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>This problem is based on the <a href="https://arxiv.org/pdf/2010.09885">ChemBERTa</a> paper.</p>
<h3 id="a)">a)<a class="anchor-link" href="#a)">¶</a></h3><p>Load the file <code>250k_rndm_zinc_drugs_clean_3.csv</code> and set up a word-level tokenizer with a byte-level pre tokenizer. Explain what these mean and why they are needed.</p>
<h3 id="b)">b)<a class="anchor-link" href="#b)">¶</a></h3><p>Using this tokenizer, pick a nontrivial SMILES string. Print out the string, the tokenization, and use rdkit to display it.</p>
<h3 id="c)">c)<a class="anchor-link" href="#c)">¶</a></h3><p>Set up a train/test loader using BERT-style masking. Explain why there must be collation.</p>
<h3 id="d)">d)<a class="anchor-link" href="#d)">¶</a></h3><p>Set up and define a Transformer class, a Masked Transformer class, masking function and optimizers. Explain why a Masked Transformer is needed. Choose a loss function and justify it.</p>
<h3 id="e)">e)<a class="anchor-link" href="#e)">¶</a></h3><p>Train the BERT-style model for a number of epochs until the loss is consistently less than ~3. Use the model to predict a previously-unseen SMILES string, and print out both the model, the masked, and the predicted. Qualitatively describe what's happening.</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="Answer-2:">Answer 2:<a class="anchor-link" href="#Answer-2:">¶</a></h2>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="a)">a)<a class="anchor-link" href="#a)">¶</a></h3>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [3]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">df_full</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">'250k_rndm_zinc_drugs_clean_3.csv'</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df_full</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:</span><span class="mi">10000</span><span class="p">]</span>
<span class="n">smiles</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">'smiles'</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [4]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">(</span><span class="n">models</span><span class="o">.</span><span class="n">WordLevel</span><span class="p">(</span><span class="n">unk_token</span><span class="o">=</span><span class="s1">'[UNK]'</span><span class="p">))</span>
<span class="n">tokenizer</span><span class="o">.</span><span class="n">pre_tokenizer</span> <span class="o">=</span> <span class="n">pre_tokenizers</span><span class="o">.</span><span class="n">ByteLevel</span><span class="p">()</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">trainers</span><span class="o">.</span><span class="n">WordLevelTrainer</span><span class="p">(</span><span class="n">vocab_size</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
    <span class="n">special_tokens</span><span class="o">=</span><span class="p">[</span><span class="s1">'[PAD]'</span><span class="p">,</span><span class="s1">'[UNK]'</span><span class="p">,</span><span class="s1">'[CLS]'</span><span class="p">,</span><span class="s1">'[SEP]'</span><span class="p">,</span><span class="s1">'[MASK]'</span><span class="p">])</span>
<span class="n">tokenizer</span><span class="o">.</span><span class="n">train_from_iterator</span><span class="p">(</span><span class="n">smiles</span><span class="p">,</span> <span class="n">trainer</span><span class="o">=</span><span class="n">trainer</span><span class="p">)</span>
<span class="n">tokenizer</span><span class="o">.</span><span class="n">post_processor</span> <span class="o">=</span> <span class="n">processors</span><span class="o">.</span><span class="n">TemplateProcessing</span><span class="p">(</span>
    <span class="s1">'[CLS] $A [SEP]'</span><span class="p">,</span> <span class="n">special_tokens</span><span class="o">=</span><span class="p">[(</span><span class="s1">'[CLS]'</span><span class="p">,</span><span class="mi">1</span><span class="p">),(</span><span class="s1">'[SEP]'</span><span class="p">,</span><span class="mi">2</span><span class="p">)])</span>
<span class="n">tokenizer</span><span class="o">.</span><span class="n">enable_truncation</span><span class="p">(</span><span class="n">max_length</span><span class="o">=</span><span class="mi">64</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>Byte-level guarantees that every character is representable. Word-level allows the model to parse more complex strings like "Cl","=O" as a single item.</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="b)">b)<a class="anchor-link" href="#b)">¶</a></h3>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [21]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">smiles0</span> <span class="o">=</span> <span class="n">smiles</span><span class="p">[</span><span class="mi">2100</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">smiles0</span><span class="p">)</span>
<span class="n">encoding0</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">smiles0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">encoding0</span><span class="o">.</span><span class="n">tokens</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">encoding0</span><span class="o">.</span><span class="n">ids</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">encoding0</span><span class="o">.</span><span class="n">attention_mask</span><span class="p">)</span>
<span class="n">mol</span><span class="o">=</span><span class="n">Chem</span><span class="o">.</span><span class="n">MolFromSmiles</span><span class="p">(</span><span class="n">smiles0</span><span class="p">)</span>
<span class="n">Draw</span><span class="o">.</span><span class="n">MolToImage</span><span class="p">(</span><span class="n">mol</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Cc1occc1C(=O)NC1CCN(C(=O)C(=O)Nc2ccc(F)cc2F)CC1

['[CLS]', 'ĠCc', '1', 'occc', '1', 'C', '(=', 'O', ')', 'NC', '1', 'CCN', '(', 'C', '(=', 'O', ')', 'C', '(=', 'O', ')', 'Nc', '2', 'ccc', '(', 'F', ')', 'cc', '2', 'F', ')', 'CC', '1', 'Ċ', '[SEP]']
[1, 32, 7, 216, 7, 6, 12, 10, 5, 29, 7, 52, 8, 6, 12, 10, 5, 6, 12, 10, 5, 35, 9, 18, 8, 26, 5, 17, 9, 26, 5, 23, 7, 13, 2]
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
</pre>
</div>
</div>
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[21]:</div>
<div class="jp-RenderedImage jp-OutputArea-output jp-OutputArea-executeResult" tabindex="0">
<img alt="No description has been provided for this image" class="" src="data:image/png;base64,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"/>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="c)">c)<a class="anchor-link" href="#c)">¶</a></h3>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [6]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">enc</span> <span class="o">=</span> <span class="p">{</span><span class="s1">'input_ids'</span><span class="p">:[],</span> <span class="s1">'attention_mask'</span><span class="p">:[]}</span>
<span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">encode_batch</span><span class="p">(</span><span class="n">smiles</span><span class="p">):</span> <span class="c1"># tokenizes each</span>
    <span class="n">enc</span><span class="p">[</span><span class="s1">'input_ids'</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">e</span><span class="o">.</span><span class="n">ids</span><span class="p">)</span>
    <span class="n">enc</span><span class="p">[</span><span class="s1">'attention_mask'</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">e</span><span class="o">.</span><span class="n">attention_mask</span><span class="p">)</span>
<span class="n">ids</span> <span class="o">=</span> <span class="n">enc</span><span class="p">[</span><span class="s1">'input_ids'</span><span class="p">]</span>
<span class="n">masks</span> <span class="o">=</span> <span class="n">enc</span><span class="p">[</span><span class="s1">'attention_mask'</span><span class="p">]</span>
<span class="c1"># train test split</span>
<span class="n">ids_train</span><span class="p">,</span> <span class="n">ids_test</span><span class="p">,</span> <span class="n">masks_train</span><span class="p">,</span> <span class="n">masks_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">ids</span><span class="p">,</span> <span class="n">masks</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>
<span class="p">)</span>
<span class="c1"># packs into dicts</span>
<span class="n">train_enc</span> <span class="o">=</span> <span class="p">{</span><span class="s1">'input_ids'</span><span class="p">:</span> <span class="n">ids_train</span><span class="p">,</span> <span class="s1">'attention_mask'</span><span class="p">:</span> <span class="n">masks_train</span><span class="p">}</span>
<span class="n">test_enc</span>  <span class="o">=</span> <span class="p">{</span><span class="s1">'input_ids'</span><span class="p">:</span> <span class="n">ids_test</span><span class="p">,</span>  <span class="s1">'attention_mask'</span><span class="p">:</span> <span class="n">masks_test</span><span class="p">}</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [7]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1"># dataset custom class</span>
<span class="k">class</span><span class="w"> </span><span class="nc">SMILESDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">enc</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ids</span> <span class="o">=</span> <span class="n">enc</span><span class="p">[</span><span class="s1">'input_ids'</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mask</span> <span class="o">=</span> <span class="n">enc</span><span class="p">[</span><span class="s1">'attention_mask'</span><span class="p">]</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ids</span><span class="p">)</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">i</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">{</span>
            <span class="s1">'input_ids'</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ids</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">),</span>
            <span class="s1">'attention_mask'</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mask</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>
        <span class="p">}</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [8]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">collate_fn</span><span class="p">(</span><span class="n">batch</span><span class="p">):</span>
    <span class="c1"># this must exist to pad them all to the same length so they can be stacked and passed into transfomer</span>
    <span class="n">ids</span> <span class="o">=</span> <span class="p">[</span><span class="n">item</span><span class="p">[</span><span class="s1">'input_ids'</span><span class="p">]</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">]</span>
    <span class="n">masks</span> <span class="o">=</span> <span class="p">[</span><span class="n">item</span><span class="p">[</span><span class="s1">'attention_mask'</span><span class="p">]</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">]</span>
    <span class="n">pad_id</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">token_to_id</span><span class="p">(</span><span class="s1">'[PAD]'</span><span class="p">)</span>
    <span class="n">ids_padded</span> <span class="o">=</span> <span class="n">pad_sequence</span><span class="p">(</span><span class="n">ids</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">padding_value</span><span class="o">=</span><span class="n">pad_id</span><span class="p">)</span>
    <span class="n">masks_padded</span> <span class="o">=</span> <span class="n">pad_sequence</span><span class="p">(</span><span class="n">masks</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">padding_value</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">{</span><span class="s1">'input_ids'</span><span class="p">:</span> <span class="n">ids_padded</span><span class="p">,</span> <span class="s1">'attention_mask'</span><span class="p">:</span> <span class="n">masks_padded</span><span class="p">}</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>Not all SMILES strings are the same length, so they must be padded to use standard uniform size tensor frameworks.</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [9]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span>
    <span class="n">SMILESDataset</span><span class="p">(</span><span class="n">train_enc</span><span class="p">),</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">collate_fn</span><span class="o">=</span><span class="n">collate_fn</span>
<span class="p">)</span>
<span class="n">test_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span>
    <span class="n">SMILESDataset</span><span class="p">(</span><span class="n">test_enc</span><span class="p">),</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>
    <span class="n">collate_fn</span><span class="o">=</span><span class="n">collate_fn</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="d)">d)<a class="anchor-link" href="#d)">¶</a></h3>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [10]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">TransformerBlock</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">mlp_dim</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MultiheadAttention</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ln1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">d_model</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mlp</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">mlp_dim</span><span class="p">),</span>
                                 <span class="n">nn</span><span class="o">.</span><span class="n">GELU</span><span class="p">(),</span>
                                 <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">mlp_dim</span><span class="p">,</span> <span class="n">d_model</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ln2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">d_model</span><span class="p">)</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">mask</span><span class="p">):</span>
        <span class="n">attn_out</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attn</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">key_padding_mask</span><span class="o">=</span><span class="n">mask</span><span class="o">==</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">attn_out</span>
        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ln1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">mlp</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">ln2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [12]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">MaskedTransformer</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">d_model</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">num_heads</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
                 <span class="n">mlp_dim</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">num_layers</span><span class="o">=</span><span class="mi">3</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embed</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">([</span>
            <span class="n">TransformerBlock</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">mlp_dim</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_layers</span><span class="p">)</span>
        <span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">)</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">mask</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embed</span><span class="p">(</span><span class="n">input_ids</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mask</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>The attention mask is a way to tell the Transformer which positions in the input are “real” tokens and which are just padding or otherwise shouldn’t contribute to attention</p>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [13]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">mask_inputs</span><span class="p">(</span><span class="n">ids</span><span class="p">,</span> <span class="n">mask_token_id</span><span class="p">,</span> <span class="n">mask_prob</span><span class="o">=</span><span class="mf">0.15</span><span class="p">):</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="n">ids</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
    <span class="n">rand</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">ids</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">mask_positions</span> <span class="o">=</span> <span class="n">rand</span> <span class="o">&lt;</span> <span class="n">mask_prob</span>
    <span class="n">labels</span><span class="p">[</span><span class="o">~</span><span class="n">mask_positions</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">100</span>
    <span class="n">ids</span><span class="p">[</span><span class="n">mask_positions</span><span class="p">]</span> <span class="o">=</span> <span class="n">mask_token_id</span>
    <span class="k">return</span> <span class="n">ids</span><span class="p">,</span> <span class="n">labels</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [14]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">vocab_size</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">get_vocab_size</span><span class="p">()</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">MaskedTransformer</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">)</span>
<span class="n">opt</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">)</span>
<span class="n">crit</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">(</span><span class="n">ignore_index</span><span class="o">=-</span><span class="mi">100</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>Cross entropy is a good choice for multiclass classification where there are probabilistic predictions. It is always positive and is uniquely minimized when fully confident correct answers are given.</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="e)">e)<a class="anchor-link" href="#e)">¶</a></h3>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [15]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">train_loader</span><span class="p">:</span>
        <span class="n">ids</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">mask_inputs</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="s1">'input_ids'</span><span class="p">],</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">token_to_id</span><span class="p">(</span><span class="s1">'[MASK]'</span><span class="p">))</span>
        <span class="n">masks</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s1">'attention_mask'</span><span class="p">]</span>
        <span class="n">opt</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">ids</span><span class="p">,</span> <span class="n">masks</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">crit</span><span class="p">(</span><span class="n">logits</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">opt</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\t</span><span class="s2"> batch, loss = </span><span class="si">{</span><span class="n">loss</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Epoch = </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>	 batch, loss = 6.604
	 batch, loss = 6.601
	 batch, loss = 6.576
	 batch, loss = 6.525
	 batch, loss = 6.443
	 batch, loss = 6.402
	 batch, loss = 6.405
	 batch, loss = 6.319
	 batch, loss = 6.276
	 batch, loss = 6.280
	 batch, loss = 6.198
	 batch, loss = 6.273
	 batch, loss = 6.195
	 batch, loss = 6.073
	 batch, loss = 6.038
	 batch, loss = 6.067
	 batch, loss = 6.057
	 batch, loss = 5.842
	 batch, loss = 6.023
	 batch, loss = 5.902
	 batch, loss = 5.951
	 batch, loss = 5.935
	 batch, loss = 5.783
	 batch, loss = 5.842
	 batch, loss = 5.779
	 batch, loss = 5.724
	 batch, loss = 5.604
	 batch, loss = 5.780
	 batch, loss = 5.871
	 batch, loss = 5.274
	 batch, loss = 5.747
	 batch, loss = 5.668
	 batch, loss = 5.705
	 batch, loss = 5.406
	 batch, loss = 5.473
	 batch, loss = 5.162
	 batch, loss = 5.528
	 batch, loss = 5.342
	 batch, loss = 5.199
	 batch, loss = 5.176
	 batch, loss = 5.117
	 batch, loss = 5.092
	 batch, loss = 5.262
	 batch, loss = 5.274
	 batch, loss = 4.990
	 batch, loss = 5.146
	 batch, loss = 5.214
	 batch, loss = 5.312
	 batch, loss = 5.056
	 batch, loss = 5.127
	 batch, loss = 5.001
	 batch, loss = 4.616
	 batch, loss = 5.041
	 batch, loss = 5.214
	 batch, loss = 4.577
	 batch, loss = 5.048
	 batch, loss = 4.845
	 batch, loss = 4.953
	 batch, loss = 4.799
	 batch, loss = 4.860
	 batch, loss = 4.992
	 batch, loss = 5.318
	 batch, loss = 4.656
	 batch, loss = 4.630
	 batch, loss = 4.762
	 batch, loss = 5.016
	 batch, loss = 4.624
	 batch, loss = 4.916
	 batch, loss = 4.805
	 batch, loss = 4.709
	 batch, loss = 5.011
	 batch, loss = 4.909
	 batch, loss = 4.870
	 batch, loss = 4.330
	 batch, loss = 4.752
	 batch, loss = 4.655
	 batch, loss = 4.902
	 batch, loss = 4.485
	 batch, loss = 4.549
	 batch, loss = 4.691
	 batch, loss = 4.504
	 batch, loss = 4.165
	 batch, loss = 4.658
	 batch, loss = 4.715
	 batch, loss = 4.733
	 batch, loss = 4.026
	 batch, loss = 4.382
	 batch, loss = 4.648
	 batch, loss = 4.486
	 batch, loss = 4.755
	 batch, loss = 4.630
	 batch, loss = 4.444
	 batch, loss = 4.359
	 batch, loss = 4.754
	 batch, loss = 4.488
	 batch, loss = 4.317
	 batch, loss = 4.205
	 batch, loss = 3.910
	 batch, loss = 4.287
	 batch, loss = 4.274
	 batch, loss = 3.834
	 batch, loss = 4.549
	 batch, loss = 4.787
	 batch, loss = 3.986
	 batch, loss = 4.475
	 batch, loss = 4.234
	 batch, loss = 4.360
	 batch, loss = 4.321
	 batch, loss = 4.073
	 batch, loss = 4.631
	 batch, loss = 4.048
	 batch, loss = 3.811
	 batch, loss = 4.227
	 batch, loss = 3.845
	 batch, loss = 4.297
	 batch, loss = 3.883
	 batch, loss = 4.829
	 batch, loss = 4.476
	 batch, loss = 4.457
	 batch, loss = 4.051
	 batch, loss = 4.268
	 batch, loss = 4.430
	 batch, loss = 4.822
	 batch, loss = 4.004
	 batch, loss = 4.542
	 batch, loss = 4.298
	 batch, loss = 4.391
	 batch, loss = 4.252
	 batch, loss = 3.960
	 batch, loss = 4.033
	 batch, loss = 4.474
	 batch, loss = 4.094
	 batch, loss = 3.729
	 batch, loss = 4.068
	 batch, loss = 4.039
	 batch, loss = 4.323
	 batch, loss = 4.139
	 batch, loss = 4.279
	 batch, loss = 4.067
	 batch, loss = 3.983
	 batch, loss = 4.479
	 batch, loss = 4.141
	 batch, loss = 4.357
	 batch, loss = 4.076
	 batch, loss = 4.072
	 batch, loss = 4.224
	 batch, loss = 4.062
	 batch, loss = 4.330
	 batch, loss = 4.110
	 batch, loss = 3.748
	 batch, loss = 4.145
	 batch, loss = 3.495
	 batch, loss = 3.766
	 batch, loss = 4.099
	 batch, loss = 4.057
	 batch, loss = 4.167
	 batch, loss = 3.787
	 batch, loss = 3.920
	 batch, loss = 4.073
	 batch, loss = 3.835
	 batch, loss = 4.484
	 batch, loss = 3.972
	 batch, loss = 4.266
	 batch, loss = 4.050
	 batch, loss = 4.026
	 batch, loss = 3.670
	 batch, loss = 3.877
	 batch, loss = 3.925
	 batch, loss = 3.723
	 batch, loss = 4.126
	 batch, loss = 3.871
	 batch, loss = 4.215
	 batch, loss = 4.043
	 batch, loss = 4.133
	 batch, loss = 4.179
	 batch, loss = 3.612
	 batch, loss = 4.017
	 batch, loss = 3.404
	 batch, loss = 3.341
	 batch, loss = 3.928
	 batch, loss = 4.322
	 batch, loss = 3.908
	 batch, loss = 4.110
	 batch, loss = 3.832
	 batch, loss = 3.972
	 batch, loss = 3.743
	 batch, loss = 3.628
	 batch, loss = 3.586
	 batch, loss = 3.949
	 batch, loss = 3.602
	 batch, loss = 4.006
	 batch, loss = 3.628
	 batch, loss = 3.890
	 batch, loss = 3.819
	 batch, loss = 3.579
	 batch, loss = 3.760
	 batch, loss = 3.589
	 batch, loss = 3.876
	 batch, loss = 3.792
	 batch, loss = 3.886
	 batch, loss = 3.994
	 batch, loss = 3.961
	 batch, loss = 3.995
	 batch, loss = 4.270
	 batch, loss = 3.681
	 batch, loss = 3.888
	 batch, loss = 3.856
	 batch, loss = 3.703
	 batch, loss = 3.927
	 batch, loss = 3.841
	 batch, loss = 4.036
	 batch, loss = 4.043
	 batch, loss = 3.548
	 batch, loss = 3.761
	 batch, loss = 3.602
	 batch, loss = 3.636
	 batch, loss = 3.862
	 batch, loss = 3.872
	 batch, loss = 3.695
	 batch, loss = 3.977
	 batch, loss = 3.293
	 batch, loss = 4.106
	 batch, loss = 3.497
	 batch, loss = 3.548
	 batch, loss = 3.366
	 batch, loss = 3.917
	 batch, loss = 3.441
	 batch, loss = 3.926
	 batch, loss = 3.326
	 batch, loss = 3.822
	 batch, loss = 3.283
	 batch, loss = 3.372
	 batch, loss = 3.665
	 batch, loss = 3.792
	 batch, loss = 3.882
	 batch, loss = 4.001
	 batch, loss = 3.464
	 batch, loss = 3.853
	 batch, loss = 3.784
	 batch, loss = 3.477
	 batch, loss = 3.523
	 batch, loss = 3.717
	 batch, loss = 3.809
	 batch, loss = 3.571
	 batch, loss = 3.695
	 batch, loss = 3.796
	 batch, loss = 3.401
	 batch, loss = 3.475
	 batch, loss = 3.550
	 batch, loss = 3.387
	 batch, loss = 3.714
	 batch, loss = 3.492
	 batch, loss = 3.598
	 batch, loss = 3.607
	 batch, loss = 3.607
	 batch, loss = 3.683
	 batch, loss = 3.439
	 batch, loss = 3.043
	 batch, loss = 3.303
	 batch, loss = 3.687
	 batch, loss = 3.390
	 batch, loss = 3.669
	 batch, loss = 3.077
	 batch, loss = 3.608
	 batch, loss = 3.750
	 batch, loss = 3.466
	 batch, loss = 3.395
	 batch, loss = 3.795
	 batch, loss = 3.293
	 batch, loss = 3.587
	 batch, loss = 3.707
	 batch, loss = 3.763
	 batch, loss = 3.615
	 batch, loss = 3.904
	 batch, loss = 3.546
	 batch, loss = 3.570
	 batch, loss = 3.216
	 batch, loss = 3.668
	 batch, loss = 3.435
	 batch, loss = 3.613
	 batch, loss = 3.310
	 batch, loss = 3.603
Epoch = 0
	 batch, loss = 3.479
	 batch, loss = 3.473
	 batch, loss = 3.568
	 batch, loss = 3.318
	 batch, loss = 3.149
	 batch, loss = 4.068
	 batch, loss = 3.534
	 batch, loss = 3.147
	 batch, loss = 3.336
	 batch, loss = 3.504
	 batch, loss = 3.542
	 batch, loss = 3.478
	 batch, loss = 3.229
	 batch, loss = 3.586
	 batch, loss = 3.525
	 batch, loss = 3.216
	 batch, loss = 3.169
	 batch, loss = 3.692
	 batch, loss = 3.695
	 batch, loss = 3.428
	 batch, loss = 3.666
	 batch, loss = 3.810
	 batch, loss = 3.483
	 batch, loss = 3.522
	 batch, loss = 3.570
	 batch, loss = 3.019
	 batch, loss = 3.423
	 batch, loss = 3.929
	 batch, loss = 3.256
	 batch, loss = 3.519
	 batch, loss = 3.359
	 batch, loss = 3.035
	 batch, loss = 3.099
	 batch, loss = 2.976
	 batch, loss = 3.626
	 batch, loss = 3.793
	 batch, loss = 3.133
	 batch, loss = 3.149
	 batch, loss = 3.425
	 batch, loss = 3.351
	 batch, loss = 3.558
	 batch, loss = 3.383
	 batch, loss = 3.259
	 batch, loss = 3.653
	 batch, loss = 3.095
	 batch, loss = 3.385
	 batch, loss = 3.555
	 batch, loss = 3.708
	 batch, loss = 3.212
	 batch, loss = 3.601
	 batch, loss = 3.183
	 batch, loss = 3.476
	 batch, loss = 2.922
	 batch, loss = 3.586
	 batch, loss = 3.174
	 batch, loss = 3.808
	 batch, loss = 3.363
	 batch, loss = 3.280
	 batch, loss = 3.013
	 batch, loss = 3.373
	 batch, loss = 3.818
	 batch, loss = 3.159
	 batch, loss = 3.426
	 batch, loss = 3.368
	 batch, loss = 3.224
	 batch, loss = 3.125
	 batch, loss = 3.174
	 batch, loss = 3.287
	 batch, loss = 3.326
	 batch, loss = 3.356
	 batch, loss = 3.380
	 batch, loss = 3.329
	 batch, loss = 3.604
	 batch, loss = 3.611
	 batch, loss = 3.178
	 batch, loss = 3.093
	 batch, loss = 3.513
	 batch, loss = 3.618
	 batch, loss = 3.231
	 batch, loss = 3.586
	 batch, loss = 3.696
	 batch, loss = 3.120
	 batch, loss = 3.244
	 batch, loss = 3.036
	 batch, loss = 3.729
	 batch, loss = 3.310
	 batch, loss = 3.425
	 batch, loss = 2.865
	 batch, loss = 3.442
	 batch, loss = 3.318
	 batch, loss = 3.607
	 batch, loss = 2.966
	 batch, loss = 3.282
	 batch, loss = 3.470
	 batch, loss = 2.996
	 batch, loss = 3.443
	 batch, loss = 3.350
	 batch, loss = 3.278
	 batch, loss = 3.263
	 batch, loss = 3.376
	 batch, loss = 3.293
	 batch, loss = 3.190
	 batch, loss = 3.153
	 batch, loss = 2.976
	 batch, loss = 3.393
	 batch, loss = 3.676
	 batch, loss = 3.581
	 batch, loss = 3.396
	 batch, loss = 3.561
	 batch, loss = 3.384
	 batch, loss = 2.930
	 batch, loss = 3.666
	 batch, loss = 3.268
	 batch, loss = 3.034
	 batch, loss = 3.280
	 batch, loss = 2.953
	 batch, loss = 3.346
	 batch, loss = 3.380
	 batch, loss = 3.531
	 batch, loss = 3.229
	 batch, loss = 3.540
	 batch, loss = 3.332
	 batch, loss = 3.381
	 batch, loss = 3.624
	 batch, loss = 3.085
	 batch, loss = 3.281
	 batch, loss = 2.966
	 batch, loss = 3.432
	 batch, loss = 3.081
	 batch, loss = 3.412
	 batch, loss = 3.267
	 batch, loss = 3.560
	 batch, loss = 3.343
	 batch, loss = 3.458
	 batch, loss = 3.124
	 batch, loss = 3.492
	 batch, loss = 3.385
	 batch, loss = 3.089
	 batch, loss = 2.959
	 batch, loss = 3.124
	 batch, loss = 3.410
	 batch, loss = 3.366
	 batch, loss = 2.755
	 batch, loss = 3.460
	 batch, loss = 3.194
	 batch, loss = 2.884
	 batch, loss = 3.665
	 batch, loss = 3.048
	 batch, loss = 3.501
	 batch, loss = 3.225
	 batch, loss = 3.319
	 batch, loss = 3.215
	 batch, loss = 3.429
	 batch, loss = 3.044
	 batch, loss = 3.172
	 batch, loss = 3.122
	 batch, loss = 3.353
	 batch, loss = 2.841
	 batch, loss = 3.033
	 batch, loss = 3.281
	 batch, loss = 2.958
	 batch, loss = 3.283
	 batch, loss = 2.985
	 batch, loss = 3.098
	 batch, loss = 3.144
	 batch, loss = 3.043
	 batch, loss = 3.234
	 batch, loss = 3.053
	 batch, loss = 3.073
	 batch, loss = 3.144
	 batch, loss = 3.045
	 batch, loss = 2.651
	 batch, loss = 2.995
	 batch, loss = 3.142
	 batch, loss = 3.303
	 batch, loss = 3.259
	 batch, loss = 2.884
	 batch, loss = 3.251
	 batch, loss = 3.101
	 batch, loss = 3.029
	 batch, loss = 3.168
	 batch, loss = 2.884
	 batch, loss = 3.168
	 batch, loss = 3.630
	 batch, loss = 3.306
	 batch, loss = 3.206
	 batch, loss = 3.287
	 batch, loss = 3.057
	 batch, loss = 2.959
	 batch, loss = 3.200
	 batch, loss = 3.530
	 batch, loss = 2.764
	 batch, loss = 2.873
	 batch, loss = 3.286
	 batch, loss = 3.044
	 batch, loss = 2.982
	 batch, loss = 3.671
	 batch, loss = 3.314
	 batch, loss = 3.193
	 batch, loss = 3.301
	 batch, loss = 3.474
	 batch, loss = 3.235
	 batch, loss = 3.248
	 batch, loss = 3.340
	 batch, loss = 3.310
	 batch, loss = 3.034
	 batch, loss = 3.573
	 batch, loss = 2.992
	 batch, loss = 3.159
	 batch, loss = 3.217
	 batch, loss = 3.159
	 batch, loss = 2.862
	 batch, loss = 2.902
	 batch, loss = 3.267
	 batch, loss = 3.140
	 batch, loss = 2.888
	 batch, loss = 3.238
	 batch, loss = 3.610
	 batch, loss = 3.255
	 batch, loss = 2.865
	 batch, loss = 3.065
	 batch, loss = 3.077
	 batch, loss = 3.297
	 batch, loss = 3.606
	 batch, loss = 3.285
	 batch, loss = 3.543
	 batch, loss = 2.960
	 batch, loss = 2.580
	 batch, loss = 3.304
	 batch, loss = 2.831
	 batch, loss = 3.257
	 batch, loss = 3.421
	 batch, loss = 3.083
	 batch, loss = 3.336
	 batch, loss = 3.540
	 batch, loss = 3.250
	 batch, loss = 3.090
	 batch, loss = 3.552
	 batch, loss = 2.994
	 batch, loss = 3.153
	 batch, loss = 3.169
	 batch, loss = 3.229
	 batch, loss = 3.326
	 batch, loss = 3.071
	 batch, loss = 3.335
	 batch, loss = 3.322
	 batch, loss = 3.478
	 batch, loss = 2.777
	 batch, loss = 3.011
	 batch, loss = 3.342
	 batch, loss = 3.286
	 batch, loss = 2.902
	 batch, loss = 2.631
	 batch, loss = 2.978
	 batch, loss = 3.251
	 batch, loss = 3.203
	 batch, loss = 3.095
	 batch, loss = 3.278
	 batch, loss = 3.397
	 batch, loss = 3.270
	 batch, loss = 3.157
	 batch, loss = 3.081
	 batch, loss = 2.999
	 batch, loss = 3.040
	 batch, loss = 3.281
	 batch, loss = 3.145
	 batch, loss = 2.996
	 batch, loss = 2.913
	 batch, loss = 3.039
	 batch, loss = 3.122
	 batch, loss = 3.147
	 batch, loss = 3.508
	 batch, loss = 3.118
	 batch, loss = 2.950
	 batch, loss = 3.246
	 batch, loss = 3.009
	 batch, loss = 2.995
	 batch, loss = 3.146
	 batch, loss = 3.132
	 batch, loss = 3.190
	 batch, loss = 3.149
	 batch, loss = 3.427
Epoch = 1
	 batch, loss = 2.704
	 batch, loss = 3.318
	 batch, loss = 3.049
	 batch, loss = 3.244
	 batch, loss = 3.248
	 batch, loss = 3.237
	 batch, loss = 3.273
	 batch, loss = 3.112
	 batch, loss = 3.444
	 batch, loss = 3.237
	 batch, loss = 3.421
	 batch, loss = 3.219
	 batch, loss = 3.099
	 batch, loss = 3.245
	 batch, loss = 3.210
	 batch, loss = 2.949
	 batch, loss = 3.115
	 batch, loss = 3.107
	 batch, loss = 3.343
	 batch, loss = 3.307
	 batch, loss = 3.217
	 batch, loss = 3.198
	 batch, loss = 2.991
	 batch, loss = 3.046
	 batch, loss = 3.254
	 batch, loss = 2.822
	 batch, loss = 3.448
	 batch, loss = 3.273
	 batch, loss = 2.709
	 batch, loss = 3.155
	 batch, loss = 3.039
	 batch, loss = 3.213
	 batch, loss = 3.145
	 batch, loss = 3.057
	 batch, loss = 3.027
	 batch, loss = 3.119
	 batch, loss = 3.318
	 batch, loss = 3.285
	 batch, loss = 3.011
	 batch, loss = 3.290
	 batch, loss = 3.190
	 batch, loss = 3.219
	 batch, loss = 3.039
	 batch, loss = 3.207
	 batch, loss = 3.093
	 batch, loss = 3.068
	 batch, loss = 2.918
	 batch, loss = 2.961
	 batch, loss = 3.078
	 batch, loss = 3.036
	 batch, loss = 3.182
	 batch, loss = 3.142
	 batch, loss = 2.811
	 batch, loss = 2.908
	 batch, loss = 3.446
	 batch, loss = 2.947
	 batch, loss = 2.860
	 batch, loss = 3.107
	 batch, loss = 3.336
	 batch, loss = 3.500
	 batch, loss = 3.400
	 batch, loss = 3.199
	 batch, loss = 3.187
	 batch, loss = 3.197
	 batch, loss = 2.686
	 batch, loss = 3.282
	 batch, loss = 3.626
	 batch, loss = 3.505
	 batch, loss = 2.572
	 batch, loss = 2.753
	 batch, loss = 3.051
	 batch, loss = 3.489
	 batch, loss = 3.198
	 batch, loss = 2.813
	 batch, loss = 2.942
	 batch, loss = 3.312
	 batch, loss = 2.824
	 batch, loss = 3.254
	 batch, loss = 3.242
	 batch, loss = 3.427
	 batch, loss = 3.232
	 batch, loss = 2.891
	 batch, loss = 3.168
	 batch, loss = 2.919
	 batch, loss = 3.286
	 batch, loss = 2.989
	 batch, loss = 2.976
	 batch, loss = 3.140
	 batch, loss = 3.059
	 batch, loss = 2.903
	 batch, loss = 2.906
	 batch, loss = 3.282
	 batch, loss = 3.521
	 batch, loss = 3.413
	 batch, loss = 3.142
	 batch, loss = 3.424
	 batch, loss = 3.149
	 batch, loss = 3.020
	 batch, loss = 2.939
	 batch, loss = 3.253
	 batch, loss = 3.001
	 batch, loss = 2.921
	 batch, loss = 2.993
	 batch, loss = 3.379
	 batch, loss = 3.037
	 batch, loss = 3.042
	 batch, loss = 2.902
	 batch, loss = 3.108
	 batch, loss = 3.105
	 batch, loss = 3.294
	 batch, loss = 2.932
	 batch, loss = 3.204
	 batch, loss = 2.986
	 batch, loss = 3.100
	 batch, loss = 3.200
	 batch, loss = 2.815
	 batch, loss = 2.855
	 batch, loss = 2.826
	 batch, loss = 3.179
	 batch, loss = 3.010
	 batch, loss = 2.770
	 batch, loss = 2.862
	 batch, loss = 3.075
	 batch, loss = 3.051
	 batch, loss = 3.142
	 batch, loss = 3.015
	 batch, loss = 2.975
	 batch, loss = 3.133
	 batch, loss = 3.040
	 batch, loss = 3.359
	 batch, loss = 3.294
	 batch, loss = 2.989
	 batch, loss = 3.036
	 batch, loss = 2.690
	 batch, loss = 3.505
	 batch, loss = 3.445
	 batch, loss = 3.431
	 batch, loss = 2.708
	 batch, loss = 3.195
	 batch, loss = 3.171
	 batch, loss = 2.987
	 batch, loss = 3.058
	 batch, loss = 3.221
	 batch, loss = 3.115
	 batch, loss = 3.270
	 batch, loss = 3.343
	 batch, loss = 3.082
	 batch, loss = 3.240
	 batch, loss = 3.117
	 batch, loss = 2.963
	 batch, loss = 2.765
	 batch, loss = 2.822
	 batch, loss = 2.980
	 batch, loss = 3.300
	 batch, loss = 3.182
	 batch, loss = 3.243
	 batch, loss = 3.301
	 batch, loss = 3.199
	 batch, loss = 2.894
	 batch, loss = 3.154
	 batch, loss = 2.784
	 batch, loss = 2.782
	 batch, loss = 3.268
	 batch, loss = 3.205
	 batch, loss = 3.213
	 batch, loss = 2.644
	 batch, loss = 3.073
	 batch, loss = 3.384
	 batch, loss = 3.351
	 batch, loss = 3.480
	 batch, loss = 2.900
	 batch, loss = 3.217
	 batch, loss = 2.915
	 batch, loss = 3.092
	 batch, loss = 3.433
	 batch, loss = 2.724
	 batch, loss = 2.982
	 batch, loss = 2.800
	 batch, loss = 3.157
	 batch, loss = 3.345
	 batch, loss = 3.066
	 batch, loss = 2.943
	 batch, loss = 3.380
	 batch, loss = 3.046
	 batch, loss = 2.731
	 batch, loss = 2.950
	 batch, loss = 2.818
	 batch, loss = 3.242
	 batch, loss = 2.815
	 batch, loss = 3.145
	 batch, loss = 2.839
	 batch, loss = 3.025
	 batch, loss = 3.056
	 batch, loss = 3.107
	 batch, loss = 2.685
	 batch, loss = 3.102
	 batch, loss = 3.043
	 batch, loss = 3.255
	 batch, loss = 3.146
	 batch, loss = 3.079
	 batch, loss = 3.193
	 batch, loss = 3.095
	 batch, loss = 3.150
	 batch, loss = 2.610
	 batch, loss = 2.919
	 batch, loss = 2.940
	 batch, loss = 2.793
	 batch, loss = 3.032
	 batch, loss = 3.167
	 batch, loss = 3.293
	 batch, loss = 3.144
	 batch, loss = 3.041
	 batch, loss = 3.089
	 batch, loss = 3.455
	 batch, loss = 3.086
	 batch, loss = 3.040
	 batch, loss = 2.788
	 batch, loss = 3.277
	 batch, loss = 3.117
	 batch, loss = 3.114
	 batch, loss = 2.983
	 batch, loss = 2.912
	 batch, loss = 2.955
	 batch, loss = 2.927
	 batch, loss = 3.321
	 batch, loss = 2.776
	 batch, loss = 3.381
	 batch, loss = 2.983
	 batch, loss = 3.130
	 batch, loss = 2.726
	 batch, loss = 2.759
	 batch, loss = 3.203
	 batch, loss = 2.813
	 batch, loss = 3.264
	 batch, loss = 3.168
	 batch, loss = 3.496
	 batch, loss = 3.134
	 batch, loss = 2.888
	 batch, loss = 3.148
	 batch, loss = 2.620
	 batch, loss = 2.612
	 batch, loss = 3.390
	 batch, loss = 3.194
	 batch, loss = 3.039
	 batch, loss = 2.544
	 batch, loss = 3.037
	 batch, loss = 2.963
	 batch, loss = 3.309
	 batch, loss = 3.305
	 batch, loss = 2.834
	 batch, loss = 3.014
	 batch, loss = 3.366
	 batch, loss = 3.062
	 batch, loss = 3.179
	 batch, loss = 3.155
	 batch, loss = 2.745
	 batch, loss = 3.372
	 batch, loss = 3.012
	 batch, loss = 3.248
	 batch, loss = 3.201
	 batch, loss = 3.156
	 batch, loss = 3.162
	 batch, loss = 3.090
	 batch, loss = 3.044
	 batch, loss = 2.887
	 batch, loss = 2.741
	 batch, loss = 3.198
	 batch, loss = 2.943
	 batch, loss = 3.095
	 batch, loss = 2.916
	 batch, loss = 2.994
	 batch, loss = 3.177
	 batch, loss = 2.789
	 batch, loss = 3.003
	 batch, loss = 2.670
	 batch, loss = 2.539
	 batch, loss = 3.193
	 batch, loss = 2.768
	 batch, loss = 2.990
	 batch, loss = 3.231
	 batch, loss = 3.015
	 batch, loss = 3.688
Epoch = 2
	 batch, loss = 2.808
	 batch, loss = 3.073
	 batch, loss = 3.242
	 batch, loss = 3.356
	 batch, loss = 3.123
	 batch, loss = 2.918
	 batch, loss = 3.324
	 batch, loss = 3.511
	 batch, loss = 2.959
	 batch, loss = 3.238
	 batch, loss = 2.882
	 batch, loss = 3.136
	 batch, loss = 3.089
	 batch, loss = 2.931
	 batch, loss = 3.122
	 batch, loss = 3.198
	 batch, loss = 2.903
	 batch, loss = 3.412
	 batch, loss = 2.877
	 batch, loss = 2.719
	 batch, loss = 3.175
	 batch, loss = 2.872
	 batch, loss = 3.038
	 batch, loss = 2.579
	 batch, loss = 2.924
	 batch, loss = 3.129
	 batch, loss = 2.974
	 batch, loss = 3.367
	 batch, loss = 2.952
	 batch, loss = 3.180
	 batch, loss = 2.976
	 batch, loss = 2.970
	 batch, loss = 2.833
	 batch, loss = 2.562
	 batch, loss = 2.891
	 batch, loss = 2.900
	 batch, loss = 2.922
	 batch, loss = 3.194
	 batch, loss = 2.966
	 batch, loss = 3.117
	 batch, loss = 2.928
	 batch, loss = 3.025
	 batch, loss = 2.993
	 batch, loss = 3.244
	 batch, loss = 3.191
	 batch, loss = 2.921
	 batch, loss = 3.352
	 batch, loss = 2.982
	 batch, loss = 3.449
	 batch, loss = 3.199
	 batch, loss = 2.829
	 batch, loss = 2.770
	 batch, loss = 3.140
	 batch, loss = 3.212
	 batch, loss = 2.937
	 batch, loss = 3.121
	 batch, loss = 2.967
	 batch, loss = 3.088
	 batch, loss = 3.186
	 batch, loss = 3.243
	 batch, loss = 3.137
	 batch, loss = 3.026
	 batch, loss = 2.905
	 batch, loss = 2.624
	 batch, loss = 3.203
	 batch, loss = 2.768
	 batch, loss = 3.298
	 batch, loss = 2.998
	 batch, loss = 2.854
	 batch, loss = 2.805
	 batch, loss = 2.899
	 batch, loss = 2.961
	 batch, loss = 3.051
	 batch, loss = 3.513
	 batch, loss = 3.018
	 batch, loss = 3.075
	 batch, loss = 3.102
	 batch, loss = 2.845
	 batch, loss = 3.181
	 batch, loss = 2.840
	 batch, loss = 2.848
	 batch, loss = 3.215
	 batch, loss = 3.119
	 batch, loss = 2.547
	 batch, loss = 2.964
	 batch, loss = 3.020
	 batch, loss = 2.594
	 batch, loss = 2.715
	 batch, loss = 2.856
	 batch, loss = 3.544
	 batch, loss = 3.049
	 batch, loss = 2.803
	 batch, loss = 3.171
	 batch, loss = 3.075
	 batch, loss = 2.937
	 batch, loss = 3.067
	 batch, loss = 2.838
	 batch, loss = 3.160
	 batch, loss = 2.879
	 batch, loss = 3.099
	 batch, loss = 2.963
	 batch, loss = 2.933
	 batch, loss = 2.968
	 batch, loss = 2.953
	 batch, loss = 3.153
	 batch, loss = 3.089
	 batch, loss = 3.182
	 batch, loss = 3.031
	 batch, loss = 3.015
	 batch, loss = 3.356
	 batch, loss = 2.633
	 batch, loss = 3.419
	 batch, loss = 2.954
	 batch, loss = 2.795
	 batch, loss = 3.287
	 batch, loss = 3.135
	 batch, loss = 2.569
	 batch, loss = 3.315
	 batch, loss = 2.864
	 batch, loss = 3.146
	 batch, loss = 2.649
	 batch, loss = 2.949
	 batch, loss = 2.965
	 batch, loss = 3.160
	 batch, loss = 2.900
	 batch, loss = 3.158
	 batch, loss = 3.106
	 batch, loss = 3.186
	 batch, loss = 2.951
	 batch, loss = 3.271
	 batch, loss = 3.441
	 batch, loss = 2.615
	 batch, loss = 2.819
	 batch, loss = 3.345
	 batch, loss = 2.793
	 batch, loss = 2.814
	 batch, loss = 3.046
	 batch, loss = 3.098
	 batch, loss = 3.227
	 batch, loss = 3.221
	 batch, loss = 3.072
	 batch, loss = 3.146
	 batch, loss = 3.349
	 batch, loss = 2.807
	 batch, loss = 3.166
	 batch, loss = 3.134
	 batch, loss = 2.672
	 batch, loss = 2.935
	 batch, loss = 3.088
	 batch, loss = 2.953
	 batch, loss = 2.790
	 batch, loss = 2.962
	 batch, loss = 2.821
	 batch, loss = 3.347
	 batch, loss = 2.689
	 batch, loss = 2.792
	 batch, loss = 3.340
	 batch, loss = 3.263
	 batch, loss = 2.772
	 batch, loss = 3.133
	 batch, loss = 3.171
	 batch, loss = 3.120
	 batch, loss = 2.892
	 batch, loss = 3.258
	 batch, loss = 2.867
	 batch, loss = 3.101
	 batch, loss = 3.294
	 batch, loss = 2.715
	 batch, loss = 2.856
	 batch, loss = 2.869
	 batch, loss = 3.372
	 batch, loss = 2.855
	 batch, loss = 2.852
	 batch, loss = 2.746
	 batch, loss = 2.560
	 batch, loss = 3.062
	 batch, loss = 3.262
	 batch, loss = 3.352
	 batch, loss = 3.110
	 batch, loss = 3.180
	 batch, loss = 2.502
	 batch, loss = 2.928
	 batch, loss = 3.177
	 batch, loss = 2.980
	 batch, loss = 2.837
	 batch, loss = 3.271
	 batch, loss = 2.818
	 batch, loss = 3.287
	 batch, loss = 3.041
	 batch, loss = 2.884
	 batch, loss = 2.581
	 batch, loss = 3.046
	 batch, loss = 2.702
	 batch, loss = 3.051
	 batch, loss = 3.114
	 batch, loss = 2.973
	 batch, loss = 3.080
	 batch, loss = 3.070
	 batch, loss = 3.232
	 batch, loss = 3.321
	 batch, loss = 3.227
	 batch, loss = 2.944
	 batch, loss = 3.118
	 batch, loss = 3.335
	 batch, loss = 2.900
	 batch, loss = 3.192
	 batch, loss = 2.551
	 batch, loss = 2.870
	 batch, loss = 2.805
	 batch, loss = 2.945
	 batch, loss = 3.237
	 batch, loss = 3.607
	 batch, loss = 3.063
	 batch, loss = 3.003
	 batch, loss = 2.721
	 batch, loss = 3.167
	 batch, loss = 2.907
	 batch, loss = 3.008
	 batch, loss = 3.138
	 batch, loss = 3.493
	 batch, loss = 2.884
	 batch, loss = 2.954
	 batch, loss = 3.182
	 batch, loss = 3.036
	 batch, loss = 2.791
	 batch, loss = 3.215
	 batch, loss = 3.067
	 batch, loss = 3.059
	 batch, loss = 2.668
	 batch, loss = 2.855
	 batch, loss = 2.906
	 batch, loss = 3.019
	 batch, loss = 2.826
	 batch, loss = 3.097
	 batch, loss = 2.779
	 batch, loss = 3.188
	 batch, loss = 3.092
	 batch, loss = 2.930
	 batch, loss = 2.811
	 batch, loss = 3.532
	 batch, loss = 3.064
	 batch, loss = 2.945
	 batch, loss = 3.037
	 batch, loss = 3.085
	 batch, loss = 3.078
	 batch, loss = 3.030
	 batch, loss = 3.061
	 batch, loss = 3.046
	 batch, loss = 2.911
	 batch, loss = 3.028
	 batch, loss = 2.334
	 batch, loss = 3.136
	 batch, loss = 2.752
	 batch, loss = 3.211
	 batch, loss = 2.508
	 batch, loss = 2.816
	 batch, loss = 2.884
	 batch, loss = 3.068
	 batch, loss = 2.845
	 batch, loss = 3.157
	 batch, loss = 3.015
	 batch, loss = 3.035
	 batch, loss = 3.407
	 batch, loss = 2.852
	 batch, loss = 3.227
	 batch, loss = 3.156
	 batch, loss = 3.030
	 batch, loss = 3.147
	 batch, loss = 2.701
	 batch, loss = 3.177
	 batch, loss = 2.944
	 batch, loss = 3.123
	 batch, loss = 2.867
	 batch, loss = 2.689
	 batch, loss = 3.292
	 batch, loss = 2.853
	 batch, loss = 3.075
	 batch, loss = 2.779
	 batch, loss = 2.674
	 batch, loss = 2.697
	 batch, loss = 3.254
	 batch, loss = 3.291
Epoch = 3
	 batch, loss = 3.365
	 batch, loss = 3.194
	 batch, loss = 3.138
	 batch, loss = 2.829
	 batch, loss = 3.036
	 batch, loss = 2.909
	 batch, loss = 3.296
	 batch, loss = 2.974
	 batch, loss = 3.172
	 batch, loss = 3.122
	 batch, loss = 2.952
	 batch, loss = 3.002
	 batch, loss = 3.134
	 batch, loss = 3.322
	 batch, loss = 2.893
	 batch, loss = 2.946
	 batch, loss = 2.920
	 batch, loss = 3.089
	 batch, loss = 3.098
	 batch, loss = 2.891
	 batch, loss = 3.108
	 batch, loss = 3.032
	 batch, loss = 3.303
	 batch, loss = 3.177
	 batch, loss = 2.901
	 batch, loss = 2.785
	 batch, loss = 2.773
	 batch, loss = 3.163
	 batch, loss = 3.168
	 batch, loss = 2.816
	 batch, loss = 2.995
	 batch, loss = 2.874
	 batch, loss = 3.014
	 batch, loss = 3.009
	 batch, loss = 3.176
	 batch, loss = 3.073
	 batch, loss = 3.116
	 batch, loss = 2.647
	 batch, loss = 2.791
	 batch, loss = 3.060
	 batch, loss = 2.981
	 batch, loss = 2.872
	 batch, loss = 2.966
	 batch, loss = 3.263
	 batch, loss = 2.859
	 batch, loss = 3.399
	 batch, loss = 2.928
	 batch, loss = 3.032
	 batch, loss = 2.916
	 batch, loss = 2.733
	 batch, loss = 3.213
	 batch, loss = 2.639
	 batch, loss = 3.193
	 batch, loss = 2.731
	 batch, loss = 2.898
	 batch, loss = 2.976
	 batch, loss = 3.061
	 batch, loss = 3.167
	 batch, loss = 2.987
	 batch, loss = 2.984
	 batch, loss = 2.754
	 batch, loss = 3.319
	 batch, loss = 3.050
	 batch, loss = 3.078
	 batch, loss = 2.875
	 batch, loss = 3.066
	 batch, loss = 3.152
	 batch, loss = 2.894
	 batch, loss = 2.875
	 batch, loss = 3.219
	 batch, loss = 2.607
	 batch, loss = 2.847
	 batch, loss = 2.999
	 batch, loss = 2.964
	 batch, loss = 3.042
	 batch, loss = 3.300
	 batch, loss = 3.143
	 batch, loss = 2.813
	 batch, loss = 2.790
	 batch, loss = 2.931
	 batch, loss = 3.123
	 batch, loss = 2.840
	 batch, loss = 3.232
	 batch, loss = 3.026
	 batch, loss = 2.996
	 batch, loss = 3.189
	 batch, loss = 2.751
	 batch, loss = 3.187
	 batch, loss = 2.685
	 batch, loss = 3.020
	 batch, loss = 2.809
	 batch, loss = 2.980
	 batch, loss = 2.847
	 batch, loss = 3.172
	 batch, loss = 3.270
	 batch, loss = 2.904
	 batch, loss = 3.011
	 batch, loss = 2.926
	 batch, loss = 2.808
	 batch, loss = 3.262
	 batch, loss = 2.744
	 batch, loss = 3.276
	 batch, loss = 2.682
	 batch, loss = 2.878
	 batch, loss = 2.917
	 batch, loss = 2.927
	 batch, loss = 3.178
	 batch, loss = 2.989
	 batch, loss = 3.066
	 batch, loss = 2.971
	 batch, loss = 3.078
	 batch, loss = 3.055
	 batch, loss = 3.129
	 batch, loss = 3.279
	 batch, loss = 3.250
	 batch, loss = 2.919
	 batch, loss = 3.060
	 batch, loss = 3.158
	 batch, loss = 2.878
	 batch, loss = 3.246
	 batch, loss = 3.031
	 batch, loss = 2.981
	 batch, loss = 3.271
	 batch, loss = 3.209
	 batch, loss = 2.943
	 batch, loss = 2.991
	 batch, loss = 3.140
	 batch, loss = 2.901
	 batch, loss = 3.153
	 batch, loss = 3.039
	 batch, loss = 3.098
	 batch, loss = 2.739
	 batch, loss = 2.942
	 batch, loss = 2.954
	 batch, loss = 2.906
	 batch, loss = 2.724
	 batch, loss = 2.948
	 batch, loss = 2.927
	 batch, loss = 2.600
	 batch, loss = 3.303
	 batch, loss = 2.862
	 batch, loss = 2.774
	 batch, loss = 3.076
	 batch, loss = 3.221
	 batch, loss = 2.812
	 batch, loss = 2.853
	 batch, loss = 3.011
	 batch, loss = 2.848
	 batch, loss = 3.094
	 batch, loss = 3.063
	 batch, loss = 3.084
	 batch, loss = 2.842
	 batch, loss = 2.727
	 batch, loss = 2.974
	 batch, loss = 3.212
	 batch, loss = 3.245
	 batch, loss = 3.086
	 batch, loss = 2.778
	 batch, loss = 2.982
	 batch, loss = 2.884
	 batch, loss = 3.338
	 batch, loss = 2.993
	 batch, loss = 3.018
	 batch, loss = 3.025
	 batch, loss = 2.988
	 batch, loss = 2.892
	 batch, loss = 3.082
	 batch, loss = 2.946
	 batch, loss = 2.759
	 batch, loss = 3.119
	 batch, loss = 3.029
	 batch, loss = 3.358
	 batch, loss = 2.824
	 batch, loss = 3.084
	 batch, loss = 2.870
	 batch, loss = 2.735
	 batch, loss = 3.187
	 batch, loss = 3.374
	 batch, loss = 3.382
	 batch, loss = 2.789
	 batch, loss = 2.795
	 batch, loss = 3.052
	 batch, loss = 2.699
	 batch, loss = 2.994
	 batch, loss = 3.286
	 batch, loss = 2.528
	 batch, loss = 3.104
	 batch, loss = 3.211
	 batch, loss = 3.069
	 batch, loss = 3.070
	 batch, loss = 3.308
	 batch, loss = 2.809
	 batch, loss = 2.751
	 batch, loss = 3.069
	 batch, loss = 3.292
	 batch, loss = 2.892
	 batch, loss = 2.940
	 batch, loss = 2.781
	 batch, loss = 3.078
	 batch, loss = 3.015
	 batch, loss = 2.993
	 batch, loss = 3.143
	 batch, loss = 2.786
	 batch, loss = 3.072
	 batch, loss = 2.832
	 batch, loss = 3.005
	 batch, loss = 2.537
	 batch, loss = 3.034
	 batch, loss = 3.037
	 batch, loss = 3.177
	 batch, loss = 2.906
	 batch, loss = 2.744
	 batch, loss = 3.174
	 batch, loss = 2.905
	 batch, loss = 3.066
	 batch, loss = 2.944
	 batch, loss = 3.259
	 batch, loss = 2.767
	 batch, loss = 2.904
	 batch, loss = 2.771
	 batch, loss = 3.136
	 batch, loss = 3.240
	 batch, loss = 2.593
	 batch, loss = 2.936
	 batch, loss = 3.215
	 batch, loss = 3.171
	 batch, loss = 2.968
	 batch, loss = 3.085
	 batch, loss = 2.608
	 batch, loss = 2.915
	 batch, loss = 2.839
	 batch, loss = 3.359
	 batch, loss = 2.613
	 batch, loss = 2.980
	 batch, loss = 2.915
	 batch, loss = 2.612
	 batch, loss = 3.084
	 batch, loss = 2.893
	 batch, loss = 2.920
	 batch, loss = 3.090
	 batch, loss = 2.561
	 batch, loss = 3.133
	 batch, loss = 2.856
	 batch, loss = 2.915
	 batch, loss = 3.391
	 batch, loss = 2.928
	 batch, loss = 3.057
	 batch, loss = 2.738
	 batch, loss = 2.843
	 batch, loss = 2.828
	 batch, loss = 2.846
	 batch, loss = 3.068
	 batch, loss = 3.121
	 batch, loss = 2.961
	 batch, loss = 3.247
	 batch, loss = 3.100
	 batch, loss = 2.821
	 batch, loss = 2.961
	 batch, loss = 2.706
	 batch, loss = 2.602
	 batch, loss = 2.677
	 batch, loss = 3.247
	 batch, loss = 2.884
	 batch, loss = 2.669
	 batch, loss = 3.021
	 batch, loss = 2.853
	 batch, loss = 2.862
	 batch, loss = 2.721
	 batch, loss = 2.863
	 batch, loss = 2.790
	 batch, loss = 2.613
	 batch, loss = 2.897
	 batch, loss = 2.466
	 batch, loss = 2.769
	 batch, loss = 3.245
	 batch, loss = 3.071
	 batch, loss = 2.619
	 batch, loss = 2.526
	 batch, loss = 3.211
	 batch, loss = 2.462
	 batch, loss = 2.454
	 batch, loss = 3.258
Epoch = 4
	 batch, loss = 3.014
	 batch, loss = 2.744
	 batch, loss = 3.168
	 batch, loss = 3.260
	 batch, loss = 2.770
	 batch, loss = 2.720
	 batch, loss = 2.717
	 batch, loss = 2.906
	 batch, loss = 2.830
	 batch, loss = 3.021
	 batch, loss = 3.203
	 batch, loss = 2.839
	 batch, loss = 3.163
	 batch, loss = 2.476
	 batch, loss = 3.331
	 batch, loss = 2.906
	 batch, loss = 2.821
	 batch, loss = 3.176
	 batch, loss = 3.152
	 batch, loss = 2.958
	 batch, loss = 3.428
	 batch, loss = 2.665
	 batch, loss = 2.986
	 batch, loss = 2.821
	 batch, loss = 3.073
	 batch, loss = 2.889
	 batch, loss = 2.430
	 batch, loss = 2.327
	 batch, loss = 3.245
	 batch, loss = 2.914
	 batch, loss = 2.832
	 batch, loss = 2.825
	 batch, loss = 3.366
	 batch, loss = 2.796
	 batch, loss = 3.228
	 batch, loss = 3.194
	 batch, loss = 3.135
	 batch, loss = 2.998
	 batch, loss = 2.903
	 batch, loss = 3.174
	 batch, loss = 2.954
	 batch, loss = 2.755
	 batch, loss = 2.967
	 batch, loss = 3.029
	 batch, loss = 3.259
	 batch, loss = 3.030
	 batch, loss = 3.063
	 batch, loss = 2.931
	 batch, loss = 3.164
	 batch, loss = 2.794
	 batch, loss = 2.335
	 batch, loss = 3.059
	 batch, loss = 2.959
	 batch, loss = 2.849
	 batch, loss = 2.663
	 batch, loss = 2.860
	 batch, loss = 2.932
	 batch, loss = 2.545
	 batch, loss = 2.941
	 batch, loss = 2.498
	 batch, loss = 2.880
	 batch, loss = 2.991
	 batch, loss = 3.273
	 batch, loss = 3.033
	 batch, loss = 3.261
	 batch, loss = 3.190
	 batch, loss = 3.025
	 batch, loss = 2.944
	 batch, loss = 2.852
	 batch, loss = 2.902
	 batch, loss = 2.823
	 batch, loss = 2.972
	 batch, loss = 3.138
	 batch, loss = 2.540
	 batch, loss = 3.007
	 batch, loss = 3.128
	 batch, loss = 2.939
	 batch, loss = 3.051
	 batch, loss = 2.756
	 batch, loss = 2.921
	 batch, loss = 3.354
	 batch, loss = 3.048
	 batch, loss = 3.020
	 batch, loss = 3.081
	 batch, loss = 3.210
	 batch, loss = 2.949
	 batch, loss = 3.006
	 batch, loss = 2.885
	 batch, loss = 2.949
	 batch, loss = 3.136
	 batch, loss = 2.940
	 batch, loss = 3.176
	 batch, loss = 3.238
	 batch, loss = 2.937
	 batch, loss = 2.835
	 batch, loss = 2.839
	 batch, loss = 2.844
	 batch, loss = 2.839
	 batch, loss = 2.541
	 batch, loss = 2.976
	 batch, loss = 2.824
	 batch, loss = 2.964
	 batch, loss = 2.958
	 batch, loss = 2.670
	 batch, loss = 3.006
	 batch, loss = 3.103
	 batch, loss = 2.756
	 batch, loss = 2.944
	 batch, loss = 2.743
	 batch, loss = 2.988
	 batch, loss = 2.331
	 batch, loss = 2.656
	 batch, loss = 2.981
	 batch, loss = 3.005
	 batch, loss = 2.613
	 batch, loss = 3.233
	 batch, loss = 3.010
	 batch, loss = 2.816
	 batch, loss = 2.617
	 batch, loss = 2.996
	 batch, loss = 3.145
	 batch, loss = 2.372
	 batch, loss = 2.600
	 batch, loss = 2.965
	 batch, loss = 2.671
	 batch, loss = 3.527
	 batch, loss = 2.834
	 batch, loss = 2.932
	 batch, loss = 3.150
	 batch, loss = 2.786
	 batch, loss = 2.859
	 batch, loss = 3.127
	 batch, loss = 2.557
	 batch, loss = 2.573
	 batch, loss = 2.916
	 batch, loss = 2.926
	 batch, loss = 2.388
	 batch, loss = 2.880
	 batch, loss = 2.559
	 batch, loss = 3.027
	 batch, loss = 2.935
	 batch, loss = 3.048
	 batch, loss = 3.039
	 batch, loss = 3.168
	 batch, loss = 3.072
	 batch, loss = 2.951
	 batch, loss = 2.756
	 batch, loss = 2.989
	 batch, loss = 3.276
	 batch, loss = 2.765
	 batch, loss = 3.381
	 batch, loss = 3.048
	 batch, loss = 2.878
	 batch, loss = 2.848
	 batch, loss = 3.084
	 batch, loss = 2.625
	 batch, loss = 3.178
	 batch, loss = 3.115
	 batch, loss = 3.060
	 batch, loss = 2.455
	 batch, loss = 2.748
	 batch, loss = 3.138
	 batch, loss = 2.950
	 batch, loss = 3.101
	 batch, loss = 3.015
	 batch, loss = 3.123
	 batch, loss = 3.103
	 batch, loss = 2.939
	 batch, loss = 2.867
	 batch, loss = 3.290
	 batch, loss = 2.921
	 batch, loss = 3.094
	 batch, loss = 3.062
	 batch, loss = 2.921
	 batch, loss = 2.744
	 batch, loss = 2.628
	 batch, loss = 2.722
	 batch, loss = 2.999
	 batch, loss = 3.289
	 batch, loss = 2.997
	 batch, loss = 2.824
	 batch, loss = 2.710
	 batch, loss = 2.661
	 batch, loss = 3.086
	 batch, loss = 2.712
	 batch, loss = 2.877
	 batch, loss = 2.980
	 batch, loss = 3.344
	 batch, loss = 2.866
	 batch, loss = 2.646
	 batch, loss = 3.107
	 batch, loss = 2.927
	 batch, loss = 2.936
	 batch, loss = 3.041
	 batch, loss = 2.619
	 batch, loss = 2.851
	 batch, loss = 2.692
	 batch, loss = 3.134
	 batch, loss = 2.691
	 batch, loss = 2.573
	 batch, loss = 2.839
	 batch, loss = 3.074
	 batch, loss = 2.914
	 batch, loss = 3.001
	 batch, loss = 3.100
	 batch, loss = 3.144
	 batch, loss = 2.820
	 batch, loss = 3.379
	 batch, loss = 2.838
	 batch, loss = 2.832
	 batch, loss = 3.267
	 batch, loss = 2.790
	 batch, loss = 3.030
	 batch, loss = 2.885
	 batch, loss = 3.031
	 batch, loss = 3.089
	 batch, loss = 2.958
	 batch, loss = 3.172
	 batch, loss = 3.011
	 batch, loss = 2.933
	 batch, loss = 2.731
	 batch, loss = 3.054
	 batch, loss = 2.743
	 batch, loss = 3.002
	 batch, loss = 3.188
	 batch, loss = 2.906
	 batch, loss = 2.883
	 batch, loss = 3.163
	 batch, loss = 2.998
	 batch, loss = 3.043
	 batch, loss = 2.784
	 batch, loss = 2.797
	 batch, loss = 3.018
	 batch, loss = 2.554
	 batch, loss = 2.823
	 batch, loss = 2.792
	 batch, loss = 2.780
	 batch, loss = 3.092
	 batch, loss = 2.850
	 batch, loss = 2.718
	 batch, loss = 3.074
	 batch, loss = 2.809
	 batch, loss = 2.849
	 batch, loss = 2.727
	 batch, loss = 3.178
	 batch, loss = 2.972
	 batch, loss = 2.992
	 batch, loss = 2.775
	 batch, loss = 3.090
	 batch, loss = 2.988
	 batch, loss = 3.114
	 batch, loss = 2.973
	 batch, loss = 2.739
	 batch, loss = 2.943
	 batch, loss = 3.043
	 batch, loss = 3.029
	 batch, loss = 3.190
	 batch, loss = 3.204
	 batch, loss = 2.929
	 batch, loss = 2.531
	 batch, loss = 2.246
	 batch, loss = 3.150
	 batch, loss = 3.150
	 batch, loss = 2.658
	 batch, loss = 2.804
	 batch, loss = 3.001
	 batch, loss = 2.498
	 batch, loss = 2.760
	 batch, loss = 2.960
	 batch, loss = 2.668
	 batch, loss = 2.905
	 batch, loss = 2.998
	 batch, loss = 2.923
	 batch, loss = 2.691
	 batch, loss = 3.184
	 batch, loss = 2.909
	 batch, loss = 2.726
	 batch, loss = 2.830
	 batch, loss = 2.826
	 batch, loss = 2.693
	 batch, loss = 2.531
	 batch, loss = 3.063
Epoch = 5
	 batch, loss = 2.703
	 batch, loss = 2.770
	 batch, loss = 3.210
	 batch, loss = 2.706
	 batch, loss = 3.052
	 batch, loss = 2.610
	 batch, loss = 2.790
	 batch, loss = 3.003
	 batch, loss = 2.933
	 batch, loss = 3.185
	 batch, loss = 3.060
	 batch, loss = 2.767
	 batch, loss = 2.413
	 batch, loss = 3.169
	 batch, loss = 2.624
	 batch, loss = 2.995
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0">
<pre>
<span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">KeyboardInterrupt</span>                         Traceback (most recent call last)
Cell <span class="ansi-green-fg">In[15], line 6</span>
<span class="ansi-green-intense-fg ansi-bold">      4</span> masks <span style="color: rgb(98,98,98)">=</span> batch[<span style="color: rgb(175,0,0)">'</span><span style="color: rgb(175,0,0)">attention_mask</span><span style="color: rgb(175,0,0)">'</span>]
<span class="ansi-green-intense-fg ansi-bold">      5</span> opt<span style="color: rgb(98,98,98)">.</span>zero_grad()
<span class="ansi-green-fg">----&gt; 6</span> logits <span style="color: rgb(98,98,98)">=</span> <span class="ansi-yellow-bg">model</span><span class="ansi-yellow-bg">(</span><span class="ansi-yellow-bg">ids</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg">masks</span><span class="ansi-yellow-bg">)</span>
<span class="ansi-green-intense-fg ansi-bold">      7</span> loss <span style="color: rgb(98,98,98)">=</span> crit(logits<span style="color: rgb(98,98,98)">.</span>reshape(<span style="color: rgb(98,98,98)">-</span><span style="color: rgb(98,98,98)">1</span>, vocab_size), labels<span style="color: rgb(98,98,98)">.</span>reshape(<span style="color: rgb(98,98,98)">-</span><span style="color: rgb(98,98,98)">1</span>))
<span class="ansi-green-intense-fg ansi-bold">      8</span> loss<span style="color: rgb(98,98,98)">.</span>backward()

File <span class="ansi-green-fg">~/miniconda3/envs/md_sims/lib/python3.9/site-packages/torch/nn/modules/module.py:1739</span>, in <span class="ansi-cyan-fg">Module._wrapped_call_impl</span><span class="ansi-blue-fg">(self, *args, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">   1737</span>     <span class="ansi-bold" style="color: rgb(0,135,0)">return</span> <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>_compiled_call_impl(<span style="color: rgb(98,98,98)">*</span>args, <span style="color: rgb(98,98,98)">*</span><span style="color: rgb(98,98,98)">*</span>kwargs)  <span style="color: rgb(95,135,135)"># type: ignore[misc]</span>
<span class="ansi-green-intense-fg ansi-bold">   1738</span> <span class="ansi-bold" style="color: rgb(0,135,0)">else</span>:
<span class="ansi-green-fg">-&gt; 1739</span>     <span class="ansi-bold" style="color: rgb(0,135,0)">return</span> <span class="ansi-yellow-bg" style="color: rgb(0,135,0)">self</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">_call_impl</span><span class="ansi-yellow-bg">(</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">*</span><span class="ansi-yellow-bg">args</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">*</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">*</span><span class="ansi-yellow-bg">kwargs</span><span class="ansi-yellow-bg">)</span>

File <span class="ansi-green-fg">~/miniconda3/envs/md_sims/lib/python3.9/site-packages/torch/nn/modules/module.py:1750</span>, in <span class="ansi-cyan-fg">Module._call_impl</span><span class="ansi-blue-fg">(self, *args, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">   1745</span> <span style="color: rgb(95,135,135)"># If we don't have any hooks, we want to skip the rest of the logic in</span>
<span class="ansi-green-intense-fg ansi-bold">   1746</span> <span style="color: rgb(95,135,135)"># this function, and just call forward.</span>
<span class="ansi-green-intense-fg ansi-bold">   1747</span> <span class="ansi-bold" style="color: rgb(0,135,0)">if</span> <span class="ansi-bold" style="color: rgb(175,0,255)">not</span> (<span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>_backward_hooks <span class="ansi-bold" style="color: rgb(175,0,255)">or</span> <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>_backward_pre_hooks <span class="ansi-bold" style="color: rgb(175,0,255)">or</span> <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>_forward_hooks <span class="ansi-bold" style="color: rgb(175,0,255)">or</span> <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>_forward_pre_hooks
<span class="ansi-green-intense-fg ansi-bold">   1748</span>         <span class="ansi-bold" style="color: rgb(175,0,255)">or</span> _global_backward_pre_hooks <span class="ansi-bold" style="color: rgb(175,0,255)">or</span> _global_backward_hooks
<span class="ansi-green-intense-fg ansi-bold">   1749</span>         <span class="ansi-bold" style="color: rgb(175,0,255)">or</span> _global_forward_hooks <span class="ansi-bold" style="color: rgb(175,0,255)">or</span> _global_forward_pre_hooks):
<span class="ansi-green-fg">-&gt; 1750</span>     <span class="ansi-bold" style="color: rgb(0,135,0)">return</span> <span class="ansi-yellow-bg">forward_call</span><span class="ansi-yellow-bg">(</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">*</span><span class="ansi-yellow-bg">args</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">*</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">*</span><span class="ansi-yellow-bg">kwargs</span><span class="ansi-yellow-bg">)</span>
<span class="ansi-green-intense-fg ansi-bold">   1752</span> result <span style="color: rgb(98,98,98)">=</span> <span class="ansi-bold" style="color: rgb(0,135,0)">None</span>
<span class="ansi-green-intense-fg ansi-bold">   1753</span> called_always_called_hooks <span style="color: rgb(98,98,98)">=</span> <span style="color: rgb(0,135,0)">set</span>()

Cell <span class="ansi-green-fg">In[12], line 14</span>, in <span class="ansi-cyan-fg">MaskedTransformer.forward</span><span class="ansi-blue-fg">(self, input_ids, mask)</span>
<span class="ansi-green-intense-fg ansi-bold">     12</span> x <span style="color: rgb(98,98,98)">=</span> <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>embed(input_ids)<span style="color: rgb(98,98,98)">.</span>transpose(<span style="color: rgb(98,98,98)">0</span>, <span style="color: rgb(98,98,98)">1</span>)
<span class="ansi-green-intense-fg ansi-bold">     13</span> <span class="ansi-bold" style="color: rgb(0,135,0)">for</span> layer <span class="ansi-bold" style="color: rgb(175,0,255)">in</span> <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>layers:
<span class="ansi-green-fg">---&gt; 14</span>     x <span style="color: rgb(98,98,98)">=</span> <span class="ansi-yellow-bg">layer</span><span class="ansi-yellow-bg">(</span><span class="ansi-yellow-bg">x</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg">mask</span><span class="ansi-yellow-bg">)</span>
<span class="ansi-green-intense-fg ansi-bold">     15</span> <span class="ansi-bold" style="color: rgb(0,135,0)">return</span> <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>fc(x)<span style="color: rgb(98,98,98)">.</span>transpose(<span style="color: rgb(98,98,98)">0</span>, <span style="color: rgb(98,98,98)">1</span>)

File <span class="ansi-green-fg">~/miniconda3/envs/md_sims/lib/python3.9/site-packages/torch/nn/modules/module.py:1739</span>, in <span class="ansi-cyan-fg">Module._wrapped_call_impl</span><span class="ansi-blue-fg">(self, *args, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">   1737</span>     <span class="ansi-bold" style="color: rgb(0,135,0)">return</span> <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>_compiled_call_impl(<span style="color: rgb(98,98,98)">*</span>args, <span style="color: rgb(98,98,98)">*</span><span style="color: rgb(98,98,98)">*</span>kwargs)  <span style="color: rgb(95,135,135)"># type: ignore[misc]</span>
<span class="ansi-green-intense-fg ansi-bold">   1738</span> <span class="ansi-bold" style="color: rgb(0,135,0)">else</span>:
<span class="ansi-green-fg">-&gt; 1739</span>     <span class="ansi-bold" style="color: rgb(0,135,0)">return</span> <span class="ansi-yellow-bg" style="color: rgb(0,135,0)">self</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">_call_impl</span><span class="ansi-yellow-bg">(</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">*</span><span class="ansi-yellow-bg">args</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">*</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">*</span><span class="ansi-yellow-bg">kwargs</span><span class="ansi-yellow-bg">)</span>

File <span class="ansi-green-fg">~/miniconda3/envs/md_sims/lib/python3.9/site-packages/torch/nn/modules/module.py:1750</span>, in <span class="ansi-cyan-fg">Module._call_impl</span><span class="ansi-blue-fg">(self, *args, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">   1745</span> <span style="color: rgb(95,135,135)"># If we don't have any hooks, we want to skip the rest of the logic in</span>
<span class="ansi-green-intense-fg ansi-bold">   1746</span> <span style="color: rgb(95,135,135)"># this function, and just call forward.</span>
<span class="ansi-green-intense-fg ansi-bold">   1747</span> <span class="ansi-bold" style="color: rgb(0,135,0)">if</span> <span class="ansi-bold" style="color: rgb(175,0,255)">not</span> (<span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>_backward_hooks <span class="ansi-bold" style="color: rgb(175,0,255)">or</span> <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>_backward_pre_hooks <span class="ansi-bold" style="color: rgb(175,0,255)">or</span> <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>_forward_hooks <span class="ansi-bold" style="color: rgb(175,0,255)">or</span> <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>_forward_pre_hooks
<span class="ansi-green-intense-fg ansi-bold">   1748</span>         <span class="ansi-bold" style="color: rgb(175,0,255)">or</span> _global_backward_pre_hooks <span class="ansi-bold" style="color: rgb(175,0,255)">or</span> _global_backward_hooks
<span class="ansi-green-intense-fg ansi-bold">   1749</span>         <span class="ansi-bold" style="color: rgb(175,0,255)">or</span> _global_forward_hooks <span class="ansi-bold" style="color: rgb(175,0,255)">or</span> _global_forward_pre_hooks):
<span class="ansi-green-fg">-&gt; 1750</span>     <span class="ansi-bold" style="color: rgb(0,135,0)">return</span> <span class="ansi-yellow-bg">forward_call</span><span class="ansi-yellow-bg">(</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">*</span><span class="ansi-yellow-bg">args</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">*</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">*</span><span class="ansi-yellow-bg">kwargs</span><span class="ansi-yellow-bg">)</span>
<span class="ansi-green-intense-fg ansi-bold">   1752</span> result <span style="color: rgb(98,98,98)">=</span> <span class="ansi-bold" style="color: rgb(0,135,0)">None</span>
<span class="ansi-green-intense-fg ansi-bold">   1753</span> called_always_called_hooks <span style="color: rgb(98,98,98)">=</span> <span style="color: rgb(0,135,0)">set</span>()

Cell <span class="ansi-green-fg">In[10], line 11</span>, in <span class="ansi-cyan-fg">TransformerBlock.forward</span><span class="ansi-blue-fg">(self, x, mask)</span>
<span class="ansi-green-intense-fg ansi-bold">     10</span> <span class="ansi-bold" style="color: rgb(0,135,0)">def</span><span style="color: rgb(188,188,188)"> </span><span style="color: rgb(0,0,255)">forward</span>(<span style="color: rgb(0,135,0)">self</span>, x, mask):
<span class="ansi-green-fg">---&gt; 11</span>     attn_out, _ <span style="color: rgb(98,98,98)">=</span> <span class="ansi-yellow-bg" style="color: rgb(0,135,0)">self</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">attn</span><span class="ansi-yellow-bg">(</span><span class="ansi-yellow-bg">x</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg">x</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg">x</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg">key_padding_mask</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">=</span><span class="ansi-yellow-bg">mask</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">==</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">0</span><span class="ansi-yellow-bg">)</span>
<span class="ansi-green-intense-fg ansi-bold">     12</span>     x <span style="color: rgb(98,98,98)">=</span> x <span style="color: rgb(98,98,98)">+</span> attn_out
<span class="ansi-green-intense-fg ansi-bold">     13</span>     y <span style="color: rgb(98,98,98)">=</span> <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>ln1(x)

File <span class="ansi-green-fg">~/miniconda3/envs/md_sims/lib/python3.9/site-packages/torch/nn/modules/module.py:1739</span>, in <span class="ansi-cyan-fg">Module._wrapped_call_impl</span><span class="ansi-blue-fg">(self, *args, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">   1737</span>     <span class="ansi-bold" style="color: rgb(0,135,0)">return</span> <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>_compiled_call_impl(<span style="color: rgb(98,98,98)">*</span>args, <span style="color: rgb(98,98,98)">*</span><span style="color: rgb(98,98,98)">*</span>kwargs)  <span style="color: rgb(95,135,135)"># type: ignore[misc]</span>
<span class="ansi-green-intense-fg ansi-bold">   1738</span> <span class="ansi-bold" style="color: rgb(0,135,0)">else</span>:
<span class="ansi-green-fg">-&gt; 1739</span>     <span class="ansi-bold" style="color: rgb(0,135,0)">return</span> <span class="ansi-yellow-bg" style="color: rgb(0,135,0)">self</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">_call_impl</span><span class="ansi-yellow-bg">(</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">*</span><span class="ansi-yellow-bg">args</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">*</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">*</span><span class="ansi-yellow-bg">kwargs</span><span class="ansi-yellow-bg">)</span>

File <span class="ansi-green-fg">~/miniconda3/envs/md_sims/lib/python3.9/site-packages/torch/nn/modules/module.py:1750</span>, in <span class="ansi-cyan-fg">Module._call_impl</span><span class="ansi-blue-fg">(self, *args, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">   1745</span> <span style="color: rgb(95,135,135)"># If we don't have any hooks, we want to skip the rest of the logic in</span>
<span class="ansi-green-intense-fg ansi-bold">   1746</span> <span style="color: rgb(95,135,135)"># this function, and just call forward.</span>
<span class="ansi-green-intense-fg ansi-bold">   1747</span> <span class="ansi-bold" style="color: rgb(0,135,0)">if</span> <span class="ansi-bold" style="color: rgb(175,0,255)">not</span> (<span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>_backward_hooks <span class="ansi-bold" style="color: rgb(175,0,255)">or</span> <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>_backward_pre_hooks <span class="ansi-bold" style="color: rgb(175,0,255)">or</span> <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>_forward_hooks <span class="ansi-bold" style="color: rgb(175,0,255)">or</span> <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>_forward_pre_hooks
<span class="ansi-green-intense-fg ansi-bold">   1748</span>         <span class="ansi-bold" style="color: rgb(175,0,255)">or</span> _global_backward_pre_hooks <span class="ansi-bold" style="color: rgb(175,0,255)">or</span> _global_backward_hooks
<span class="ansi-green-intense-fg ansi-bold">   1749</span>         <span class="ansi-bold" style="color: rgb(175,0,255)">or</span> _global_forward_hooks <span class="ansi-bold" style="color: rgb(175,0,255)">or</span> _global_forward_pre_hooks):
<span class="ansi-green-fg">-&gt; 1750</span>     <span class="ansi-bold" style="color: rgb(0,135,0)">return</span> <span class="ansi-yellow-bg">forward_call</span><span class="ansi-yellow-bg">(</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">*</span><span class="ansi-yellow-bg">args</span><span class="ansi-yellow-bg">,</span><span class="ansi-yellow-bg"> </span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">*</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">*</span><span class="ansi-yellow-bg">kwargs</span><span class="ansi-yellow-bg">)</span>
<span class="ansi-green-intense-fg ansi-bold">   1752</span> result <span style="color: rgb(98,98,98)">=</span> <span class="ansi-bold" style="color: rgb(0,135,0)">None</span>
<span class="ansi-green-intense-fg ansi-bold">   1753</span> called_always_called_hooks <span style="color: rgb(98,98,98)">=</span> <span style="color: rgb(0,135,0)">set</span>()

File <span class="ansi-green-fg">~/miniconda3/envs/md_sims/lib/python3.9/site-packages/torch/nn/modules/activation.py:1373</span>, in <span class="ansi-cyan-fg">MultiheadAttention.forward</span><span class="ansi-blue-fg">(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)</span>
<span class="ansi-green-intense-fg ansi-bold">   1347</span>     attn_output, attn_output_weights <span style="color: rgb(98,98,98)">=</span> F<span style="color: rgb(98,98,98)">.</span>multi_head_attention_forward(
<span class="ansi-green-intense-fg ansi-bold">   1348</span>         query,
<span class="ansi-green-intense-fg ansi-bold">   1349</span>         key,
<span class="ansi-green-fg">   (...)</span>
<span class="ansi-green-intense-fg ansi-bold">   1370</span>         is_causal<span style="color: rgb(98,98,98)">=</span>is_causal,
<span class="ansi-green-intense-fg ansi-bold">   1371</span>     )
<span class="ansi-green-intense-fg ansi-bold">   1372</span> <span class="ansi-bold" style="color: rgb(0,135,0)">else</span>:
<span class="ansi-green-fg">-&gt; 1373</span>     attn_output, attn_output_weights <span style="color: rgb(98,98,98)">=</span> <span class="ansi-yellow-bg">F</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">multi_head_attention_forward</span><span class="ansi-yellow-bg">(</span>
<span class="ansi-green-intense-fg ansi-bold">   1374</span> <span class="ansi-yellow-bg">        </span><span class="ansi-yellow-bg">query</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">   1375</span> <span class="ansi-yellow-bg">        </span><span class="ansi-yellow-bg">key</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">   1376</span> <span class="ansi-yellow-bg">        </span><span class="ansi-yellow-bg">value</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">   1377</span> <span class="ansi-yellow-bg">        </span><span class="ansi-yellow-bg" style="color: rgb(0,135,0)">self</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">embed_dim</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">   1378</span> <span class="ansi-yellow-bg">        </span><span class="ansi-yellow-bg" style="color: rgb(0,135,0)">self</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">num_heads</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">   1379</span> <span class="ansi-yellow-bg">        </span><span class="ansi-yellow-bg" style="color: rgb(0,135,0)">self</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">in_proj_weight</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">   1380</span> <span class="ansi-yellow-bg">        </span><span class="ansi-yellow-bg" style="color: rgb(0,135,0)">self</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">in_proj_bias</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">   1381</span> <span class="ansi-yellow-bg">        </span><span class="ansi-yellow-bg" style="color: rgb(0,135,0)">self</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">bias_k</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">   1382</span> <span class="ansi-yellow-bg">        </span><span class="ansi-yellow-bg" style="color: rgb(0,135,0)">self</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">bias_v</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">   1383</span> <span class="ansi-yellow-bg">        </span><span class="ansi-yellow-bg" style="color: rgb(0,135,0)">self</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">add_zero_attn</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">   1384</span> <span class="ansi-yellow-bg">        </span><span class="ansi-yellow-bg" style="color: rgb(0,135,0)">self</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">dropout</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">   1385</span> <span class="ansi-yellow-bg">        </span><span class="ansi-yellow-bg" style="color: rgb(0,135,0)">self</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">out_proj</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">weight</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">   1386</span> <span class="ansi-yellow-bg">        </span><span class="ansi-yellow-bg" style="color: rgb(0,135,0)">self</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">out_proj</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">bias</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">   1387</span> <span class="ansi-yellow-bg">        </span><span class="ansi-yellow-bg">training</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">=</span><span class="ansi-yellow-bg" style="color: rgb(0,135,0)">self</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">training</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">   1388</span> <span class="ansi-yellow-bg">        </span><span class="ansi-yellow-bg">key_padding_mask</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">=</span><span class="ansi-yellow-bg">key_padding_mask</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">   1389</span> <span class="ansi-yellow-bg">        </span><span class="ansi-yellow-bg">need_weights</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">=</span><span class="ansi-yellow-bg">need_weights</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">   1390</span> <span class="ansi-yellow-bg">        </span><span class="ansi-yellow-bg">attn_mask</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">=</span><span class="ansi-yellow-bg">attn_mask</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">   1391</span> <span class="ansi-yellow-bg">        </span><span class="ansi-yellow-bg">average_attn_weights</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">=</span><span class="ansi-yellow-bg">average_attn_weights</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">   1392</span> <span class="ansi-yellow-bg">        </span><span class="ansi-yellow-bg">is_causal</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">=</span><span class="ansi-yellow-bg">is_causal</span><span class="ansi-yellow-bg">,</span>
<span class="ansi-green-intense-fg ansi-bold">   1393</span> <span class="ansi-yellow-bg">    </span><span class="ansi-yellow-bg">)</span>
<span class="ansi-green-intense-fg ansi-bold">   1394</span> <span class="ansi-bold" style="color: rgb(0,135,0)">if</span> <span style="color: rgb(0,135,0)">self</span><span style="color: rgb(98,98,98)">.</span>batch_first <span class="ansi-bold" style="color: rgb(175,0,255)">and</span> is_batched:
<span class="ansi-green-intense-fg ansi-bold">   1395</span>     <span class="ansi-bold" style="color: rgb(0,135,0)">return</span> attn_output<span style="color: rgb(98,98,98)">.</span>transpose(<span style="color: rgb(98,98,98)">1</span>, <span style="color: rgb(98,98,98)">0</span>), attn_output_weights

File <span class="ansi-green-fg">~/miniconda3/envs/md_sims/lib/python3.9/site-packages/torch/nn/functional.py:6389</span>, in <span class="ansi-cyan-fg">multi_head_attention_forward</span><span class="ansi-blue-fg">(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)</span>
<span class="ansi-green-intense-fg ansi-bold">   6387</span> attn_output_weights <span style="color: rgb(98,98,98)">=</span> attn_output_weights<span style="color: rgb(98,98,98)">.</span>view(bsz, num_heads, tgt_len, src_len)
<span class="ansi-green-intense-fg ansi-bold">   6388</span> <span class="ansi-bold" style="color: rgb(0,135,0)">if</span> average_attn_weights:
<span class="ansi-green-fg">-&gt; 6389</span>     attn_output_weights <span style="color: rgb(98,98,98)">=</span> <span class="ansi-yellow-bg">attn_output_weights</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">.</span><span class="ansi-yellow-bg">mean</span><span class="ansi-yellow-bg">(</span><span class="ansi-yellow-bg">dim</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">=</span><span class="ansi-yellow-bg" style="color: rgb(98,98,98)">1</span><span class="ansi-yellow-bg">)</span>
<span class="ansi-green-intense-fg ansi-bold">   6391</span> <span class="ansi-bold" style="color: rgb(0,135,0)">if</span> <span class="ansi-bold" style="color: rgb(175,0,255)">not</span> is_batched:
<span class="ansi-green-intense-fg ansi-bold">   6392</span>     <span style="color: rgb(95,135,135)"># squeeze the output if input was unbatched</span>
<span class="ansi-green-intense-fg ansi-bold">   6393</span>     attn_output <span style="color: rgb(98,98,98)">=</span> attn_output<span style="color: rgb(98,98,98)">.</span>squeeze(<span style="color: rgb(98,98,98)">1</span>)

<span class="ansi-red-fg">KeyboardInterrupt</span>: </pre>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [67]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="s1">'masked_transformer_weights.pth'</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">MaskedTransformer</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">'masked_transformer_weights.pth'</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child jp-OutputArea-executeResult">
<div class="jp-OutputPrompt jp-OutputArea-prompt">Out[67]:</div>
<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0">
<pre>MaskedTransformer(
  (embed): Embedding(517, 64)
  (layers): ModuleList(
    (0-2): 3 x TransformerBlock(
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
      )
      (ln1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (0): Linear(in_features=64, out_features=128, bias=True)
        (1): GELU(approximate='none')
        (2): Linear(in_features=128, out_features=64, bias=True)
      )
      (ln2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    )
  )
  (fc): Linear(in_features=64, out_features=517, bias=True)
)</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h4 id="Mini-Example">Mini Example<a class="anchor-link" href="#Mini-Example">¶</a></h4>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [71]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>

<span class="c1"># 1. Load the 10 000th SMILES</span>
<span class="n">df_full</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">'250k_rndm_zinc_drugs_clean_3.csv'</span><span class="p">)</span>
<span class="n">smiles_orig</span> <span class="o">=</span> <span class="n">df_full</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">10001</span><span class="p">][</span><span class="s1">'smiles'</span><span class="p">]</span>  <span class="c1"># zero-based index</span>

<span class="c1"># 2. Encode and build batch</span>
<span class="n">encoding</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">smiles_orig</span><span class="p">)</span>
<span class="n">input_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">encoding</span><span class="o">.</span><span class="n">ids</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>           <span class="c1"># shape [1, L]</span>
<span class="n">attention_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">encoding</span><span class="o">.</span><span class="n">attention_mask</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># 3. Apply masking</span>
<span class="n">mask_id</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">token_to_id</span><span class="p">(</span><span class="s1">'[MASK]'</span><span class="p">)</span>
<span class="n">ids_masked</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">mask_inputs</span><span class="p">(</span><span class="n">input_ids</span><span class="o">.</span><span class="n">clone</span><span class="p">(),</span> <span class="n">mask_id</span><span class="p">,</span> <span class="n">mask_prob</span><span class="o">=</span><span class="mf">0.15</span><span class="p">)</span>

<span class="c1"># 4. Forward pass</span>
<span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">logits</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">ids_masked</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">)</span>               <span class="c1"># [1, L, V]</span>
    <span class="n">preds</span> <span class="o">=</span> <span class="n">logits</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>         <span class="c1"># [L]</span>

<span class="c1"># 5. Decode back to tokens → SMILES</span>
<span class="n">tokens_pred</span> <span class="o">=</span> <span class="p">[</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">id_to_token</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">preds</span><span class="p">]</span>
<span class="c1"># strip off [CLS]/[SEP] and join</span>
<span class="n">smiles_pred</span> <span class="o">=</span> <span class="s1">''</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">tok</span> <span class="k">for</span> <span class="n">tok</span> <span class="ow">in</span> <span class="n">tokens_pred</span> <span class="k">if</span> <span class="n">tok</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span><span class="s1">'[CLS]'</span><span class="p">,</span><span class="s1">'[SEP]'</span><span class="p">,</span><span class="s1">'[PAD]'</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"Original: "</span><span class="p">,</span> <span class="n">smiles_orig</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Masked  : "</span><span class="p">,</span> <span class="s1">''</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
    <span class="n">tokenizer</span><span class="o">.</span><span class="n">id_to_token</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">if</span> <span class="n">i</span><span class="o">!=</span><span class="n">mask_id</span> <span class="k">else</span> <span class="s1">'[MASK]'</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">ids_masked</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">tolist</span><span class="p">()))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Predicted:"</span><span class="p">,</span> <span class="n">smiles_pred</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>Original:  CC(C)c1cc(C(=O)Nc2ccc(C[NH+]3CCCC3)cc2)n[nH]1

Masked  :  [UNK]ĠCC(C[MASK]c1[MASK](C(=[MASK])Nc2ccc[MASK]C[NH+]3CCCC3)cc2)n[[MASK][MASK]1[MASK][CLS]
Predicted: ĠCCĊ)ĊĊn)()OO)sĠOn1(nCSCCOOOĊ)
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>While it's mostly predicting garbage, it has understood some common features like starting the chain with 2 carbons etc. This poor performance is mostly to be expected for such a small dataset and ~5 epochs with shallow nets and small batches, but I can see the shape of the structure starting form.</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="Problem-3:-Lyra">Problem 3: Lyra<a class="anchor-link" href="#Problem-3:-Lyra">¶</a></h2>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>As discussed briefly in class and in presentations, the new SOTA <a href="https://arxiv.org/abs/2503.16351">Lyra</a> architecture is a subquadratic sequence modeling architecture built on two units, projected gated convolution (PGC), and S4D (a state space model). See page 23 for details. It has shown SOTA performance on various protein modeling tasks.</p>
<h3 id="a)">a)<a class="anchor-link" href="#a)">¶</a></h3><p>Implement the PGC, and explain the intuition for what is happening. Describe the complexity of one application of the unit.</p>
<h3 id="b)">b)<a class="anchor-link" href="#b)">¶</a></h3><p>Lyra uses <a href="https://arxiv.org/pdf/2206.11893">S4D</a>. Find a copy of the model, understand it (<a href="https://srush.github.io/annotated-s4/">Annotated S4</a>), and give an overview of how the model works. Then make a short example of using S4D to predict sequences, e.g. a simple wave.</p>
<h3 id="c)">c)<a class="anchor-link" href="#c)">¶</a></h3><p>Write a torch module that combines the above to generate the Lyra model using the model spec from page 23.</p>
<h3 id="d)">d)<a class="anchor-link" href="#d)">¶</a></h3><p>Train the LYRA model to predict 1 dimensional data for the function $f(x) = \cos(x) + .5\sin(2x)$. Hint: It may make more sense to define a "LyraMini" so it trains faster.</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h2 id="Answer-3:">Answer 3:<a class="anchor-link" href="#Answer-3:">¶</a></h2>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="a)">a)<a class="anchor-link" href="#a)">¶</a></h3>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [74]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>

<span class="k">class</span><span class="w"> </span><span class="nc">RMSNorm</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-8</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eps</span> <span class="o">=</span> <span class="n">eps</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">dim</span><span class="p">))</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">rms</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">eps</span><span class="p">)</span><span class="o">.</span><span class="n">sqrt</span><span class="p">()</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">*</span> <span class="p">(</span><span class="n">x</span> <span class="o">/</span> <span class="n">rms</span><span class="p">)</span>

<span class="k">class</span><span class="w"> </span><span class="nc">ProjectedGatedConv</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">features</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">project_in</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">norm1</span> <span class="o">=</span> <span class="n">RMSNorm</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv1d</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span>
                              <span class="n">padding</span><span class="o">=</span><span class="n">kernel_size</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="n">hidden_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gate_lin</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">project_out</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">features</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">norm2</span> <span class="o">=</span> <span class="n">RMSNorm</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">h</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">project_in</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="n">h</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm1</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>

        <span class="n">h_t</span> <span class="o">=</span> <span class="n">h</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">conv_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv</span><span class="p">(</span><span class="n">h_t</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

        <span class="n">gate</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gate_lin</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>

        <span class="n">gated</span> <span class="o">=</span> <span class="n">conv_out</span> <span class="o">*</span> <span class="n">gate</span>

        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">project_out</span><span class="p">(</span><span class="n">gated</span><span class="p">)</span>

        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm2</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">out</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>Intuition</p>
<ol>
<li><p>Projection + RMSNorm<br/>
We map the original features into a lower (or higher) dimensional space <code>hidden_dim</code> and apply RMS normalization to stabilize activations and gradients.</p>
</li>
<li><p>Parallel paths</p>
<ul>
<li>Local path: a depthwise 1D convolution of kernel size $K$ learns position‐local motifs of length $K$.</li>
<li>Global path: a dense layer computes a gating signal at each position based on the entire receptive field.</li>
</ul>
</li>
<li><p>Gating<br/>
Element‐wise multiplication of the convolution output and the gate lets global context modulate local feature extraction, amplifying or suppressing motifs depending on broader sequence context.</p>
</li>
<li><p>Projection back + RMSNorm
We project the gated features back to the original feature dimension and apply RMS normalization again, ensuring a consistent scale for downstream layers.</p>
</li>
</ol>
<p>Computational complexity (per sequence of length $L$, input features $F$, hidden size $H$)</p>
<ul>
<li>Two projections: each $O(LFH)$</li>
<li>Depthwise convolution: $O(LHK)$</li>
<li>Final projection: $O(LHF)$</li>
<li>Two RMSNorms: $O(LH) + O(LF)$</li>
</ul>
<p>Overall cost:<br/>
$$
O\bigl(L\,(2FH + HK + FH)\bigr) \;=\; O\bigl(L\,H\,(3F + K)\bigr).
$$</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="b)">b)<a class="anchor-link" href="#b)">¶</a></h3>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [75]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="sd">"""Minimal version of S4D with extra options and features stripped out, for pedagogical purposes."""</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">math</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn.functional</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">F</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">einops</span><span class="w"> </span><span class="kn">import</span> <span class="n">rearrange</span><span class="p">,</span> <span class="n">repeat</span>

<span class="c1"># https://github.com/state-spaces/s4/blob/main/src/models/nn/dropout.py</span>
<span class="k">class</span><span class="w"> </span><span class="nc">DropoutNd</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">p</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">tie</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">transposed</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        tie: tie dropout mask across sequence lengths (Dropout1d/2d/3d)</span>
<span class="sd">        """</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">p</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">p</span> <span class="o">&gt;=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">"dropout probability has to be in [0, 1), "</span> <span class="s2">"but got </span><span class="si">{}</span><span class="s2">"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">p</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">p</span> <span class="o">=</span> <span class="n">p</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tie</span> <span class="o">=</span> <span class="n">tie</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">transposed</span> <span class="o">=</span> <span class="n">transposed</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">binomial</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributions</span><span class="o">.</span><span class="n">binomial</span><span class="o">.</span><span class="n">Binomial</span><span class="p">(</span><span class="n">probs</span><span class="o">=</span><span class="mi">1</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""X: (batch, dim, lengths...)."""</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">transposed</span><span class="p">:</span> <span class="n">X</span> <span class="o">=</span> <span class="n">rearrange</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="s1">'b ... d -&gt; b d ...'</span><span class="p">)</span>
            <span class="c1"># binomial = torch.distributions.binomial.Binomial(probs=1-self.p) # This is incredibly slow because of CPU -&gt; GPU copying</span>
            <span class="n">mask_shape</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="mi">2</span><span class="p">]</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span><span class="p">,)</span><span class="o">*</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">ndim</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">tie</span> <span class="k">else</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
            <span class="c1"># mask = self.binomial.sample(mask_shape)</span>
            <span class="n">mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="o">*</span><span class="n">mask_shape</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mf">1.</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">p</span>
            <span class="n">X</span> <span class="o">=</span> <span class="n">X</span> <span class="o">*</span> <span class="n">mask</span> <span class="o">*</span> <span class="p">(</span><span class="mf">1.0</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="p">))</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">transposed</span><span class="p">:</span> <span class="n">X</span> <span class="o">=</span> <span class="n">rearrange</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="s1">'b d ... -&gt; b ... d'</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">X</span>
        <span class="k">return</span> <span class="n">X</span>
    
<span class="c1"># https://github.com/state-spaces/s4/blob/main/models/s4/s4d.py</span>
<span class="k">class</span><span class="w"> </span><span class="nc">S4DKernel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Generate convolution kernel from diagonal SSM parameters."""</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">N</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">dt_min</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">dt_max</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="c1"># Generate dt</span>
        <span class="n">H</span> <span class="o">=</span> <span class="n">d_model</span>
        <span class="n">log_dt</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">H</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span>
            <span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">dt_max</span><span class="p">)</span> <span class="o">-</span> <span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">dt_min</span><span class="p">)</span>
        <span class="p">)</span> <span class="o">+</span> <span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">dt_min</span><span class="p">)</span>

        <span class="n">C</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">H</span><span class="p">,</span> <span class="n">N</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">cfloat</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">C</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">view_as_real</span><span class="p">(</span><span class="n">C</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register</span><span class="p">(</span><span class="s2">"log_dt"</span><span class="p">,</span> <span class="n">log_dt</span><span class="p">,</span> <span class="n">lr</span><span class="p">)</span>

        <span class="n">log_A_real</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">H</span><span class="p">,</span> <span class="n">N</span><span class="o">//</span><span class="mi">2</span><span class="p">))</span>
        <span class="n">A_imag</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="n">repeat</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">N</span><span class="o">//</span><span class="mi">2</span><span class="p">),</span> <span class="s1">'n -&gt; h n'</span><span class="p">,</span> <span class="n">h</span><span class="o">=</span><span class="n">H</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register</span><span class="p">(</span><span class="s2">"log_A_real"</span><span class="p">,</span> <span class="n">log_A_real</span><span class="p">,</span> <span class="n">lr</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register</span><span class="p">(</span><span class="s2">"A_imag"</span><span class="p">,</span> <span class="n">A_imag</span><span class="p">,</span> <span class="n">lr</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">L</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        returns: (..., c, L) where c is number of channels (default 1)</span>
<span class="sd">        """</span>

        <span class="c1"># Materialize parameters</span>
        <span class="n">dt</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_dt</span><span class="p">)</span> <span class="c1"># (H)</span>
        <span class="n">C</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">view_as_complex</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">C</span><span class="p">)</span> <span class="c1"># (H N)</span>
        <span class="n">A</span> <span class="o">=</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_A_real</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="n">j</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">A_imag</span> <span class="c1"># (H N)</span>

        <span class="c1"># Vandermonde multiplication</span>
        <span class="n">dtA</span> <span class="o">=</span> <span class="n">A</span> <span class="o">*</span> <span class="n">dt</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># (H N)</span>
        <span class="n">K</span> <span class="o">=</span> <span class="n">dtA</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">L</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">A</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="c1"># (H N L)</span>
        <span class="n">C</span> <span class="o">=</span> <span class="n">C</span> <span class="o">*</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">dtA</span><span class="p">)</span><span class="o">-</span><span class="mf">1.</span><span class="p">)</span> <span class="o">/</span> <span class="n">A</span>
        <span class="n">K</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s1">'hn, hnl -&gt; hl'</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">K</span><span class="p">))</span><span class="o">.</span><span class="n">real</span>

        <span class="k">return</span> <span class="n">K</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">register</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">tensor</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""Register a tensor with a configurable learning rate and 0 weight decay"""</span>

        <span class="k">if</span> <span class="n">lr</span> <span class="o">==</span> <span class="mf">0.0</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">tensor</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register_parameter</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">tensor</span><span class="p">))</span>

            <span class="n">optim</span> <span class="o">=</span> <span class="p">{</span><span class="s2">"weight_decay"</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">}</span>
            <span class="k">if</span> <span class="n">lr</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span> <span class="n">optim</span><span class="p">[</span><span class="s2">"lr"</span><span class="p">]</span> <span class="o">=</span> <span class="n">lr</span>
            <span class="nb">setattr</span><span class="p">(</span><span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">),</span> <span class="s2">"_optim"</span><span class="p">,</span> <span class="n">optim</span><span class="p">)</span>


<span class="k">class</span><span class="w"> </span><span class="nc">S4D</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">d_state</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">transposed</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kernel_args</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">h</span> <span class="o">=</span> <span class="n">d_model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n</span> <span class="o">=</span> <span class="n">d_state</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">d_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">h</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">transposed</span> <span class="o">=</span> <span class="n">transposed</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">D</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">h</span><span class="p">))</span>

        <span class="c1"># SSM Kernel</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span> <span class="o">=</span> <span class="n">S4DKernel</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">h</span><span class="p">,</span> <span class="n">N</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="p">,</span> <span class="o">**</span><span class="n">kernel_args</span><span class="p">)</span>

        <span class="c1"># Pointwise</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GELU</span><span class="p">()</span>
        <span class="c1"># dropout_fn = nn.Dropout2d # NOTE: bugged in PyTorch 1.11</span>
        <span class="n">dropout_fn</span> <span class="o">=</span> <span class="n">DropoutNd</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">dropout_fn</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span> <span class="k">if</span> <span class="n">dropout</span> <span class="o">&gt;</span> <span class="mf">0.0</span> <span class="k">else</span> <span class="n">nn</span><span class="o">.</span><span class="n">Identity</span><span class="p">()</span>

        <span class="c1"># position-wise output transform to mix features</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_linear</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv1d</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">h</span><span class="p">,</span> <span class="mi">2</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">h</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">GLU</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">2</span><span class="p">),</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span> <span class="c1"># absorbs return_output and transformer src mask</span>
<span class="w">        </span><span class="sd">""" Input and output shape (B, H, L) """</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">transposed</span><span class="p">:</span> <span class="n">u</span> <span class="o">=</span> <span class="n">u</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">L</span> <span class="o">=</span> <span class="n">u</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># Compute SSM Kernel</span>
        <span class="n">k</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span><span class="p">(</span><span class="n">L</span><span class="o">=</span><span class="n">L</span><span class="p">)</span> <span class="c1"># (H L)</span>

        <span class="c1"># Convolution</span>
        <span class="n">k_f</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">fft</span><span class="o">.</span><span class="n">rfft</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">2</span><span class="o">*</span><span class="n">L</span><span class="p">)</span> <span class="c1"># (H L)</span>
        <span class="n">u_f</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">fft</span><span class="o">.</span><span class="n">rfft</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">2</span><span class="o">*</span><span class="n">L</span><span class="p">)</span> <span class="c1"># (B H L)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">fft</span><span class="o">.</span><span class="n">irfft</span><span class="p">(</span><span class="n">u_f</span><span class="o">*</span><span class="n">k_f</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">2</span><span class="o">*</span><span class="n">L</span><span class="p">)[</span><span class="o">...</span><span class="p">,</span> <span class="p">:</span><span class="n">L</span><span class="p">]</span> <span class="c1"># (B H L)</span>

        <span class="c1"># Compute D term in state space equation - essentially a skip connection</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">y</span> <span class="o">+</span> <span class="n">u</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">D</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>
        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_linear</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">transposed</span><span class="p">:</span> <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">y</span><span class="p">,</span> <span class="kc">None</span> <span class="c1"># Return a dummy state to satisfy this repo's interface, but this can be modified</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [76]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [77]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">'cuda'</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s1">'cpu'</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">S4D</span><span class="p">(</span><span class="n">d_model</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">d_state</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.0</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">opt</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>
<span class="n">loss_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>

<span class="k">def</span><span class="w"> </span><span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">seq_len</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">steps</span> <span class="o">=</span> <span class="mi">2000</span>

<span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">steps</span><span class="p">):</span>
    <span class="n">phi</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span> <span class="o">*</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">math</span><span class="o">.</span><span class="n">pi</span>
    <span class="n">t</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="o">*</span><span class="n">math</span><span class="o">.</span><span class="n">pi</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="o">+</span> <span class="n">phi</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="o">+</span> <span class="n">phi</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">pred</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
    <span class="n">opt</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="n">opt</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

<span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="n">phi_test</span> <span class="o">=</span> <span class="mf">1.0</span>
<span class="n">t</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="o">*</span><span class="n">math</span><span class="o">.</span><span class="n">pi</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">)</span>
<span class="n">x_test</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">t</span> <span class="o">+</span> <span class="n">phi_test</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">y_true</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">t</span> <span class="o">+</span> <span class="n">phi_test</span><span class="p">)</span>
<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">y_pred</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">y_pred</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">y_true</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">label</span><span class="o">=</span><span class="s1">'true'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">y_pred</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">label</span><span class="o">=</span><span class="s1">'pred'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>tensor(0.5461, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.5472, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.5457, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.5452, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.5414, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.5412, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.5443, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.5395, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.5414, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.5386, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.5371, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.5346, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.5395, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.5359, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.5359, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.5341, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.5314, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.5309, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.5307, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.5346, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.5278, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.5289, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.5223, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.5286, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.5239, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.5233, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.5255, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.5193, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.5209, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.5231, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.5218, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.5233, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.5184, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.5218, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.5164, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.5159, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.5160, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.5157, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.5117, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.5147, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.5116, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.5147, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.5122, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.5145, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.5100, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.5098, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.5109, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.5071, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.5079, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.5079, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.5054, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.5040, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.5017, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.5051, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.5044, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.5012, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.5016, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.5023, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.5021, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.5010, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.5018, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.4950, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.4983, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.4961, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.4971, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.4945, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.4970, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.4982, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.4920, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.4949, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.4888, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.4892, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.4893, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.4901, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.4895, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.4884, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.4869, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.4841, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.4842, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.4826, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.4820, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.4856, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.4818, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.4819, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.4791, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.4801, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.4764, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.4789, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.4802, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.4790, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.4703, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.4712, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.4720, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.4736, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.4739, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.4706, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.4705, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.4720, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.4665, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.4681, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.4689, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.4696, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.4629, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.4620, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.4618, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.4610, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.4635, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.4592, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.4571, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.4610, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.4560, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.4573, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.4525, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.4595, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.4527, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.4517, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.4542, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.4526, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.4510, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.4471, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.4494, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.4486, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.4423, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.4491, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.4439, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.4431, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.4415, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.4342, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.4384, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.4399, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.4389, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.4462, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.4378, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.4407, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.4306, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.4299, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.4420, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.4284, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.4262, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.4229, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.4290, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.4286, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.4287, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.4285, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.4167, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.4170, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.4288, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.4229, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.4029, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.4192, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.4186, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.4140, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.4180, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.4083, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.4258, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.4068, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.4013, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.4142, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.4010, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.3945, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.4125, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.3989, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.3949, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.3997, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.3939, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.3972, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.4031, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.4018, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.3884, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.3885, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.3876, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.3910, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.3876, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.3943, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.3784, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.3736, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.3878, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.3817, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.3732, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.3897, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.3583, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.3690, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.3829, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.3726, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.3672, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.3849, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.3713, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.3792, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.3817, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.3764, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.3600, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.3785, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.3562, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.3567, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.3469, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.3666, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.3722, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.3670, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.3594, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.3464, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.3374, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.3367, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.3451, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.3358, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.3400, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.3528, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.3485, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.3471, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.3452, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.3321, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.3480, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.3245, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.3286, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.3474, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.3279, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.3395, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.3146, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.3447, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.3367, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.3231, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.3203, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.3304, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.3121, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.3296, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.3300, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.3324, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.3107, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.3045, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2933, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.3146, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2945, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.3166, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.3059, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2916, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.3026, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.3076, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2993, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.3005, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.3103, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.3146, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.3058, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.3073, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2885, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2991, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2774, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2967, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2887, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2983, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2984, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.3112, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2983, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.3049, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2818, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2954, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2887, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2911, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2884, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2886, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2807, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2804, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2834, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2766, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2688, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2869, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2749, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2564, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2671, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2649, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2649, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2616, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2601, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2491, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2671, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2756, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2532, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2829, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2780, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2911, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2780, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2511, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2609, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2481, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2594, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2380, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2558, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2692, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2572, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2612, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2609, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2638, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2400, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2385, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2400, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2556, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2482, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2426, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2399, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2354, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2362, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2396, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2447, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2487, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2464, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2520, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2613, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2494, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2481, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2421, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2463, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2351, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2441, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2510, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2426, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2340, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2361, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2422, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2138, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2325, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2305, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2192, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2153, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2178, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2158, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2147, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1942, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2079, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2220, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2121, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2212, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2141, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2216, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2185, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2119, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2357, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2152, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2008, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2070, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2071, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2048, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1974, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1959, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2164, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2257, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2027, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1943, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2186, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2006, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2010, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2131, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1964, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1962, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2151, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2071, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1992, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2187, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2057, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2167, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2028, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2061, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1810, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2149, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2196, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1816, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1996, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1959, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1839, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1895, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2042, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1782, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2011, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2045, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1979, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1858, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1814, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1885, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1989, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1891, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1910, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1884, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1826, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1818, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1803, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1887, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1855, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1703, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2029, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1659, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1922, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1678, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1854, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1736, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1795, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1925, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1873, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1832, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1853, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1882, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1844, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1841, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1727, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1792, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1727, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1672, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1617, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1829, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1725, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1761, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1688, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1670, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1692, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1809, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1648, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1853, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1676, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1779, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1766, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1772, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1848, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1624, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1714, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1710, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1616, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1728, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1709, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1634, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1612, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1553, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1493, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1534, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1634, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1502, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1568, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1621, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1612, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1659, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1698, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1683, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1741, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1534, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1489, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1641, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1543, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1726, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1514, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1699, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1564, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1579, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1620, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1561, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1500, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1562, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1496, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1499, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1491, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1499, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1474, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1504, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1585, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1552, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1527, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1395, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1398, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1488, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1505, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1443, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1498, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1441, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1380, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1555, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1510, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1522, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1546, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1478, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1456, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1442, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1383, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1487, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1526, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1376, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1483, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1372, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1498, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1427, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1400, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1462, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1400, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1389, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1511, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1407, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1498, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1282, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1362, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1380, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1487, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1408, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1429, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1373, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1329, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1396, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1366, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1409, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1341, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1317, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1372, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1366, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1329, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1228, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1486, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1340, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1325, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1308, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1375, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1343, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1384, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1310, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1372, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1344, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1324, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1286, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1315, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1269, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1315, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1308, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1310, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1244, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1276, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1272, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1308, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1288, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1394, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1244, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1205, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1312, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1331, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1237, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1292, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1213, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1234, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1299, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1268, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1328, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1227, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1307, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1283, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1250, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1279, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1293, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1240, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1305, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1363, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1252, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1177, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1286, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1206, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1233, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1159, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1244, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1225, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1308, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1263, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1261, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1255, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1335, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1270, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1226, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1298, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1236, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1218, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1227, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1220, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1080, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1183, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1112, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1153, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1220, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1292, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1209, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1195, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1175, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1218, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1171, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1139, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1194, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1182, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1159, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1209, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1187, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1182, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1142, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1252, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1256, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1206, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1180, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1083, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1226, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1165, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1156, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1184, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1265, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1079, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1193, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1184, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1144, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1153, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1086, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1147, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1103, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1190, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1254, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1130, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1123, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1082, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1202, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1092, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1207, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1177, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1083, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1162, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1091, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1138, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1122, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1148, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1185, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1066, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1095, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1080, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1171, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1188, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1140, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1163, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1168, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1139, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1197, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1200, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1203, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1180, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1118, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1176, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1161, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1065, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1117, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1230, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1106, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1065, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1118, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1199, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1167, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1081, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1071, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1120, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1125, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1133, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1121, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1220, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1157, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1164, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1119, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1037, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1083, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1151, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1093, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1139, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1117, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1103, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1097, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1186, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1186, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1148, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1112, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1030, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1142, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1071, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1086, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1169, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1138, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1128, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1073, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1005, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1112, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1142, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1107, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1093, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1126, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1127, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1085, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1119, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1085, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1094, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1091, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1098, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1050, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1067, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1098, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1097, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1039, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1094, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1095, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1096, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1095, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1147, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1055, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1096, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1079, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1026, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1038, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1054, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1123, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1122, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1072, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1030, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1010, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1045, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1023, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1043, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1038, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1046, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1083, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1080, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1036, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1017, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1094, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1128, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1065, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1047, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1087, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1055, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1139, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1046, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1049, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0991, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1073, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1121, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1004, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1032, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1096, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1067, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1020, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1105, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1009, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1050, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1112, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1115, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1001, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1048, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1013, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1042, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0991, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1063, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1063, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0986, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1065, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1064, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0987, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0977, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0951, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1003, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1042, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1083, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1052, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0972, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1062, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1056, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1017, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1040, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1013, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1081, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0970, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1045, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1012, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1053, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1063, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1089, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1024, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1075, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1079, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1024, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0965, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0953, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1024, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0992, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1050, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0991, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1030, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0969, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1024, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1034, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1049, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1037, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1031, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1039, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1040, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1011, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0995, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0985, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1074, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1062, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0991, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1045, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1018, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1054, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1034, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1040, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0995, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1003, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1074, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1010, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0961, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0971, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0910, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1003, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0978, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1011, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1028, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1025, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0989, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1000, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1036, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0991, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1026, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1017, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1003, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1059, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0979, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0976, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1009, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1027, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1036, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0996, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1052, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1054, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0996, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1023, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0973, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0973, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1030, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0981, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0965, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0979, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0926, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0988, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1000, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0930, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1004, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1059, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1040, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0986, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0979, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1016, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1037, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0985, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0930, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1060, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0984, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1007, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0991, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0985, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1021, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1024, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0984, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0914, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1034, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0981, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0970, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0991, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0993, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0959, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0973, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0973, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1006, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0979, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0988, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0962, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0970, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0990, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1010, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0997, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0984, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1018, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1010, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0983, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1026, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0971, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0979, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0975, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1026, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1015, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1001, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1008, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0934, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0986, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0911, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1002, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0953, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0972, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0991, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0971, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0975, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0962, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0911, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0971, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0959, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0974, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0969, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0940, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0950, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0944, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0974, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1000, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1025, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0991, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0968, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0989, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0966, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0929, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0936, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0961, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0964, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0984, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0978, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0932, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0991, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0899, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0946, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0997, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0937, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0991, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0990, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0966, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0966, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0914, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0990, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0985, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0983, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0967, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0982, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1012, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0956, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1014, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0901, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0948, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0973, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0956, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0993, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0936, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1005, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0923, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0954, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0938, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0953, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0937, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0941, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0931, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0947, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0982, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0920, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0959, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0948, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0958, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0997, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0959, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0949, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0957, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0954, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0978, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0969, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0970, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0982, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0939, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0971, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0953, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0959, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0961, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0920, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0903, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0921, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0968, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0933, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0982, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0888, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0953, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0928, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0942, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0963, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0951, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0961, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0946, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0968, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0922, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0908, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1005, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0942, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0937, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0925, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0926, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0895, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0925, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0972, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0937, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0972, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0920, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0919, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0948, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0974, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0965, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0915, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0931, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0934, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0919, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0922, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0908, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0915, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0940, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0919, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0958, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0930, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0893, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0980, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0931, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0923, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0906, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0918, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0952, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0958, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0933, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0945, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0920, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0957, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0941, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0916, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0956, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0938, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0939, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0908, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0920, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0913, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0920, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0892, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0903, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0957, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0899, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0932, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0853, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0933, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0884, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0943, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0923, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0943, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0946, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0919, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0910, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0933, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0914, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0942, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0962, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0918, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0922, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0912, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0892, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0954, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0933, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0918, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0937, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0911, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0899, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0910, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0898, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0900, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0925, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0945, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0931, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0865, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0911, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0929, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0922, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0966, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0899, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0900, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0893, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0872, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0920, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0876, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0919, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0902, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0916, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0903, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0935, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0919, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0873, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0905, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0890, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0936, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0879, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0907, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0900, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0875, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0892, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0930, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0894, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0896, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0893, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0929, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0878, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0903, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0950, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0919, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0892, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0904, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0899, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0913, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0907, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0890, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0934, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0920, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0868, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0952, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0888, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0910, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0897, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0881, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0881, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0918, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0930, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0892, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0903, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0936, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0900, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0883, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0908, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0894, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0916, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0913, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0899, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0903, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0898, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0910, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0876, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0896, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0902, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0881, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0872, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0896, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0893, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0901, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0899, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0904, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0873, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0894, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0887, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0909, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0918, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0903, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0895, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0912, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0869, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0901, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0875, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0866, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0887, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0856, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0879, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0918, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0881, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0868, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0895, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0897, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0884, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0842, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0886, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0883, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0885, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0878, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0908, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0915, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0892, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0894, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0895, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0889, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0862, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0892, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0893, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0893, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0910, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0869, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0895, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0854, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0881, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0864, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0872, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0889, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0878, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0892, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0879, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0853, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0853, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0847, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0909, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0883, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0884, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0878, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0870, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0877, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0869, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0859, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0865, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0889, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0853, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0884, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0874, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0851, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0901, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0862, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0878, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0870, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0863, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0876, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0891, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0879, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0853, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0864, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0845, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0846, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0877, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0861, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0886, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0866, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0869, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0875, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0843, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0877, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0869, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0890, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0877, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0878, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0826, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0850, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0837, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0867, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0862, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0884, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0894, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0877, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0873, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0868, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0871, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0860, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0857, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0891, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0860, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0849, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0869, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0843, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0870, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0863, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0860, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0835, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0866, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0877, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0861, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0862, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0841, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0869, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0836, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0866, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0884, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0852, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0854, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0835, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0838, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0837, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0858, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0853, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0868, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0841, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0872, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0860, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0881, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0845, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0861, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0846, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0848, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0835, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0849, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0858, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0861, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0864, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0857, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0867, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0856, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0813, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0873, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0830, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0849, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0830, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0859, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0859, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0837, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0822, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0863, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0859, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0833, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0833, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0846, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0813, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0856, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0840, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0850, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0830, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0845, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0835, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0840, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0838, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0855, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0861, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0844, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0836, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0867, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0836, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0854, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0852, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0819, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0839, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0837, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0828, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0840, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0854, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0844, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0821, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0858, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0835, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0834, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0858, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0831, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0839, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0844, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0823, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0851, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0837, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0825, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0848, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0835, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0848, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0831, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0856, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0850, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0848, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0849, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0853, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0845, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0832, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0830, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0820, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0835, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0827, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0856, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0831, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0836, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0838, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0846, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0830, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0829, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0824, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0833, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0837, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0840, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0855, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0836, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0845, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0839, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0826, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0838, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0830, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0813, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0828, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0824, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0818, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0840, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0836, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0838, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0806, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0824, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0829, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0803, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0810, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0836, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0826, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0830, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0833, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0840, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0826, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0846, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0828, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0812, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0807, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0835, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0819, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0824, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0819, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0829, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0821, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0833, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0818, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0831, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0836, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0844, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0815, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0803, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0830, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0803, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0830, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0826, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0823, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0807, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0815, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0829, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0807, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0827, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0823, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0821, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0806, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0831, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0832, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0824, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0794, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0806, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0825, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0818, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0815, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0797, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0824, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0825, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0804, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0815, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0815, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0815, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0810, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0812, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0824, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0823, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0811, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0794, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0824, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0815, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0826, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0816, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0809, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0814, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0811, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0817, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0815, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0812, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0792, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0819, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0801, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0811, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0796, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0797, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0829, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0810, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0811, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0813, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0800, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0824, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0803, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0808, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0786, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0819, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0792, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0804, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0815, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0805, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0805, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0797, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0796, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0785, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0806, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0804, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0803, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0818, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0806, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0792, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0813, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0800, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0803, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0801, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0798, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0800, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0793, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0811, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0782, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0805, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0813, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0810, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0805, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0796, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0798, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0794, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0787, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0794, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0805, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0801, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0800, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0795, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0805, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0796, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0800, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0811, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0775, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0800, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0804, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0794, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0792, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0796, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0783, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0799, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0783, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0792, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0789, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0799, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0789, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0795, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0797, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0800, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0791, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0811, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0793, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0792, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0808, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0791, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0781, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0788, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0796, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0787, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0785, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0798, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0774, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0804, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0786, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0792, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0786, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0778, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0781, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0796, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0786, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0792, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0788, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0793, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0777, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0791, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0790, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0783, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0801, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0779, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0789, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0781, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0805, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0790, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0783, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0789, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0777, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0764, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0786, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0775, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0776, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0785, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0798, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0787, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0786, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0787, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0792, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0786, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0800, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0792, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0781, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0780, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0783, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0788, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0785, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0774, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0770, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0782, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0782, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0774, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0778, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0789, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0780, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0785, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0780, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0773, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0775, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0781, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0780, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0781, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0780, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0786, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0768, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0775, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0771, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0773, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0782, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0786, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0772, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0780, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0778, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0774, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0784, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0773, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0778, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0777, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0767, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0760, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0776, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0776, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0777, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0782, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0775, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0777, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0777, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0772, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0776, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0764, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0775, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0767, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0769, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0778, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0775, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0768, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0766, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0777, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0765, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0765, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0769, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0768, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0764, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0765, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0770, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0764, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0768, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0768, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0773, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0773, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0770, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0769, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0757, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0765, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0768, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0762, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0777, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0757, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0765, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0773, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0758, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0766, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0764, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0750, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0765, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0767, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0750, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0770, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0771, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0755, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0758, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0759, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0765, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0774, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0762, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0776, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0771, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0755, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0766, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0748, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0756, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0765, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0765, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0757, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0758, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0761, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0768, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0758, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0754, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0754, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0757, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0754, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0747, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0758, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0760, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0756, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0752, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0758, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0759, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0756, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0751, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0734, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0758, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0759, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0750, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0755, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0759, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0753, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0756, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0759, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0756, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0747, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0747, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0757, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0754, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0748, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0759, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0760, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0750, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0749, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0754, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0756, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0758, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0752, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0745, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0743, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0754, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0751, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0754, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0742, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0753, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0749, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0756, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0749, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0746, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0745, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0752, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0745, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0744, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0749, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0754, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0744, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0748, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0751, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0736, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0742, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0750, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0750, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0750, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0739, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0746, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0744, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0750, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0753, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0743, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0741, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0755, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0737, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0750, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0742, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0742, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0746, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0741, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0741, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0733, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0754, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0740, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0742, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0742, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0742, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0733, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0745, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0740, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0739, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0745, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0742, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0737, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0743, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0743, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0741, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0732, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0734, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0735, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0739, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0736, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0735, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0734, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0742, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0737, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0734, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0731, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0741, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0734, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0735, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0733, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0737, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0733, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0737, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0734, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0736, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0739, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0730, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0723, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0729, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0730, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0737, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0728, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0731, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0723, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0724, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0732, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0730, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0732, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0735, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0726, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0726, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0732, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0730, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0731, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0731, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0730, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0729, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0726, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0726, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0726, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0728, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0729, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0731, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0725, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0730, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0724, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0729, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0726, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0726, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0730, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0725, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0723, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0721, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0719, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0724, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0726, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0721, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0725, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0721, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0719, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0725, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0718, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0722, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0717, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0721, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0721, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0717, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0722, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0720, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0721, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0724, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0717, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0719, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0723, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0716, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0715, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0718, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0716, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0724, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0715, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0715, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0718, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0720, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0712, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0717, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0717, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0718, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0714, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0714, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0709, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0718, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0714, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0712, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0710, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0708, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0717, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0715, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0709, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0708, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0713, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0713, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0711, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0707, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0708, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0711, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0711, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0708, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0712, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0711, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0711, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0707, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0707, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0711, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0712, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0706, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0705, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0708, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0706, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0705, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0701, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0704, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0709, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0705, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0708, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0699, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0703, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0700, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0707, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0709, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0703, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0702, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0700, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0702, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0698, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0707, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0708, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0703, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0701, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0701, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0700, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0700, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0698, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0697, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0702, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0698, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0706, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0702, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0704, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0707, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0699, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0705, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0700, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0700, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0698, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0698, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0693, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0699, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0701, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0695, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0695, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0699, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0696, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0696, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0696, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0696, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0696, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0691, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0694, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0697, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0694, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0691, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0695, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0692, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0692, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0695, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0696, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0689, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0692, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0690, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0694, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0692, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0692, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0685, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0687, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0692, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0689, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0685, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0689, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0688, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0690, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0690, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0684, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0688, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0688, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0685, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0685, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0687, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0685, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0684, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0686, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0686, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0683, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0689, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0684, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0686, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0685, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0688, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0683, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0681, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0684, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0684, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0684, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0679, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0682, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0683, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0687, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0687, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0682, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0680, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0678, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0681, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0679, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0678, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0683, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0678, grad_fn=&lt;MseLossBackward0&gt;)
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedImage jp-OutputArea-output" tabindex="0">
<img alt="No description has been provided for this image" class="" src="data:image/png;base64,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"/>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>S4D is complexity $\mathcal{O}(L \log L)$ where $L$ is the sequence length because this is the complexity of the inverse fast fourier transform used to recover the filter. On the other hand attention is $\mathcal{O}(L^2)$ for a similar task.</p>
<p>S4D approximates a continuous-time state space model. Unlike S4, it is diagonal (D), and the learned parameters are the decay and oscillation of the A matrix in a standard SSM and the readout C of each channel. Then the convolution kernel K's FFT is used to produce the output, along with the inputs to the model.</p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="c)">c)<a class="anchor-link" href="#c)">¶</a></h3>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [78]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>

<span class="k">class</span><span class="w"> </span><span class="nc">Lyra</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">features</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pgc1</span> <span class="o">=</span> <span class="n">ProjectedGatedConv</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pgc2</span> <span class="o">=</span> <span class="n">ProjectedGatedConv</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="o">=</span><span class="mi">128</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prenorm</span> <span class="o">=</span> <span class="n">RMSNorm</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">s4d</span> <span class="o">=</span> <span class="n">S4D</span><span class="p">(</span><span class="n">d_model</span><span class="o">=</span><span class="n">features</span><span class="p">,</span> <span class="n">d_state</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">transposed</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pgc1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pgc2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">residual</span> <span class="o">=</span> <span class="n">x</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prenorm</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x_s4d</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">s4d</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
        <span class="n">x_s4d</span> <span class="o">=</span> <span class="n">x_s4d</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x_s4d</span> <span class="o">+</span> <span class="n">residual</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<p>"Lyra comprises two core components: the Projected Gated Convolution (PGC) block[43], followed by a state-space layer with depthwise convolution (S4D). In the standard implementation, which consists of approximately 55,000 parameters, Lyra includes two PGC blocks. The first PGC block operates
with a hidden dimension of 16, while the second uses a hidden dimension of 128. These are followed
by an S4D layer[38], which has a hidden dimension of 64 and is equipped with a residual connection
and sequence prenormalization using Root Mean Square Layer Normalization (RMSNorm). The
PGC blocks are designed to capture contextualized local dependencies in the input sequence, while the
S4D layer parameterizes a long convolution to model long-range dependencies."</p>
<p><a href="https://arxiv.org/pdf/2503.16351">https://arxiv.org/pdf/2503.16351</a></p>
</div>
</div>
</div>
</div>
<div class="jp-Cell jp-MarkdownCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown">
<h3 id="d)">d)<a class="anchor-link" href="#d)">¶</a></h3>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [79]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">LyraMini</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">features</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pgc1</span> <span class="o">=</span> <span class="n">ProjectedGatedConv</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pgc2</span> <span class="o">=</span> <span class="n">ProjectedGatedConv</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prenorm</span> <span class="o">=</span> <span class="n">RMSNorm</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">s4d</span> <span class="o">=</span> <span class="n">S4D</span><span class="p">(</span><span class="n">d_model</span><span class="o">=</span><span class="n">features</span><span class="p">,</span> <span class="n">d_state</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">transposed</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pgc1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pgc2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">residual</span> <span class="o">=</span> <span class="n">x</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prenorm</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x_s4d</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">s4d</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
        <span class="n">x_s4d</span> <span class="o">=</span> <span class="n">x_s4d</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x_s4d</span> <span class="o">+</span> <span class="n">residual</span>
</pre></div>
</div>
</div>
</div>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell">
<div class="jp-Cell-inputWrapper" tabindex="0">
<div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser">
</div>
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In [80]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
<div class="cm-editor cm-s-jupyter">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">'cuda'</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s1">'cpu'</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">LyraMini</span><span class="p">(</span><span class="n">features</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">opt</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>
<span class="n">loss_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>

<span class="k">def</span><span class="w"> </span><span class="nf">f2</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="mf">.5</span><span class="o">*</span><span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">x</span><span class="p">)</span>

<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">seq_len</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">steps</span> <span class="o">=</span> <span class="mi">300</span>

<span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">steps</span><span class="p">):</span>
    <span class="n">phi</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span> <span class="o">*</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">math</span><span class="o">.</span><span class="n">pi</span>
    <span class="n">t</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="o">*</span><span class="n">math</span><span class="o">.</span><span class="n">pi</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">f2</span><span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="o">+</span> <span class="n">phi</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">f2</span><span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="o">+</span> <span class="n">phi</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
    <span class="n">opt</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="n">opt</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

<span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="n">phi_test</span> <span class="o">=</span> <span class="mf">1.0</span>
<span class="n">t</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="o">*</span><span class="n">math</span><span class="o">.</span><span class="n">pi</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">)</span>
<span class="n">x_test</span> <span class="o">=</span> <span class="n">f2</span><span class="p">(</span><span class="n">t</span> <span class="o">+</span> <span class="n">phi_test</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">y_true</span> <span class="o">=</span> <span class="n">f2</span><span class="p">(</span><span class="n">t</span> <span class="o">+</span> <span class="n">phi_test</span><span class="p">)</span>
<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">y_pred</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">y_true</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">label</span><span class="o">=</span><span class="s1">'true'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">y_pred</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">label</span><span class="o">=</span><span class="s1">'pred'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="jp-Cell-outputWrapper">
<div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser">
</div>
<div class="jp-OutputArea jp-Cell-outputArea">
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0">
<pre>tensor(1.6084, grad_fn=&lt;MseLossBackward0&gt;)
tensor(1.5591, grad_fn=&lt;MseLossBackward0&gt;)
tensor(1.5148, grad_fn=&lt;MseLossBackward0&gt;)
tensor(1.4459, grad_fn=&lt;MseLossBackward0&gt;)
tensor(1.3574, grad_fn=&lt;MseLossBackward0&gt;)
tensor(1.3569, grad_fn=&lt;MseLossBackward0&gt;)
tensor(1.2198, grad_fn=&lt;MseLossBackward0&gt;)
tensor(1.1737, grad_fn=&lt;MseLossBackward0&gt;)
tensor(1.1646, grad_fn=&lt;MseLossBackward0&gt;)
tensor(1.1464, grad_fn=&lt;MseLossBackward0&gt;)
tensor(1.0768, grad_fn=&lt;MseLossBackward0&gt;)
tensor(1.0378, grad_fn=&lt;MseLossBackward0&gt;)
tensor(1.0625, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.9224, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.9412, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.9190, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.8634, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.8424, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.7731, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.7746, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.7095, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.7099, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.6905, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.6393, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.6011, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.6029, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.5692, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.5548, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.5320, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.4898, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.4720, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.4479, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.4280, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.3826, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.3719, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.3593, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.3250, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.3125, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.3024, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2719, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2750, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2485, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2259, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.2211, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1970, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1942, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1771, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1625, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1710, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1628, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1425, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1406, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1266, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1212, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1240, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1200, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1126, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1048, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1068, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0943, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.1062, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0967, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0849, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0866, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0841, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0752, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0771, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0713, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0710, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0722, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0664, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0599, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0627, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0584, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0551, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0571, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0611, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0504, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0475, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0501, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0458, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0486, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0444, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0457, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0434, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0393, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0417, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0338, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0367, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0319, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0317, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0314, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0298, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0310, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0264, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0284, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0261, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0253, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0249, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0230, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0236, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0202, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0207, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0192, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0178, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0188, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0176, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0155, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0166, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0153, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0154, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0137, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0132, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0126, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0131, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0109, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0112, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0127, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0107, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0112, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0108, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0094, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0088, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0090, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0095, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0079, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0076, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0078, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0075, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0066, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0065, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0069, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0067, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0064, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0062, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0058, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0057, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0049, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0053, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0052, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0047, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0048, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0044, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0044, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0040, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0043, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0042, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0039, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0039, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0036, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0036, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0037, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0035, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0038, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0033, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0035, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0032, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0030, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0031, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0028, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0028, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0029, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0026, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0026, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0025, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0025, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0025, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0024, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0024, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0023, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0022, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0022, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0021, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0022, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0019, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0021, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0020, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0022, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0020, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0020, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0018, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0019, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0018, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0017, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0017, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0018, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0017, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0019, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0016, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0016, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0015, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0016, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0016, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0015, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0015, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0015, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0015, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0014, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0015, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0014, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0014, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0015, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0015, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0014, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0013, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0013, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0014, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0012, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0013, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0011, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0013, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0012, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0012, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0013, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0012, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0012, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0012, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0011, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0012, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0011, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0011, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0010, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0012, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0011, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0010, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0011, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0010, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0009, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0010, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0011, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0010, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0010, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0009, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0010, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0010, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0010, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0009, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0010, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0009, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0009, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0009, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0009, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0009, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0009, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0009, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0009, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0009, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0008, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0009, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0008, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0009, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0009, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0008, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0008, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0008, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0008, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0008, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0008, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0008, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0008, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0007, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0008, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0007, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0007, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0007, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0007, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0007, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0007, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0007, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0007, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0007, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0007, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0007, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0007, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0007, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0007, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0007, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0006, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0007, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0007, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0007, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0007, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0006, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0007, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0006, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0006, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0006, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0006, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0006, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0006, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0006, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0006, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0006, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0006, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0006, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0006, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0006, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0006, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0006, grad_fn=&lt;MseLossBackward0&gt;)
tensor(0.0006, grad_fn=&lt;MseLossBackward0&gt;)
</pre>
</div>
</div>
<div class="jp-OutputArea-child">
<div class="jp-OutputPrompt jp-OutputArea-prompt"></div>
<div class="jp-RenderedImage jp-OutputArea-output" tabindex="0">
<img alt="No description has been provided for this image" class="" src="data:image/png;base64,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"/>
</div>
</div>
</div>
</div>
</div>
</main>
</body>
</html>
